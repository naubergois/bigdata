<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Chris Albon</title>
    <link>https://chrisalbon.com/</link>
    <description></description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 01 Feb 2020 00:00:00 -0700</lastBuildDate>
    
        <atom:link href="https://chrisalbon.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Check If PyTorch Is Using The GPU</title>
      <link>https://chrisalbon.com/deep_learning/pytorch/basics/check_if_pytorch_is_using_gpu/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/pytorch/basics/check_if_pytorch_is_using_gpu/</guid>
      <description>I find this is always the first thing I want to run when setting up a deep learning environment, whether a desktop machine or on AWS. These commands simply load PyTorch and check to make sure PyTorch can use the GPU.
Preliminaries # Import PyTorch import torch Check If There Are Multiple Devices (i.e. GPU cards) # How many GPUs are there? print(torch.cuda.device_count()) 1  Check Which Is The Current GPU?</description>
    </item>
    
    <item>
      <title>Prevent Ubuntu 18.06 And Nvidia Drivers From Updating</title>
      <link>https://chrisalbon.com/deep_learning/setup/prevent_nvidia_drivers_from_upgrading/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/setup/prevent_nvidia_drivers_from_upgrading/</guid>
      <description>Ubuntu and NVIDIA&amp;rsquo;s drivers are continually being developed. Normally this is a good thing, however an update from either can break a working deep learning environment and by default these updates are automatic.
After successfully setting up your deep learning system and testing that it works, it is recommended to freeze the system in place by preventing automatic updates of both the NVIDIA drivers and Ubuntu.
Check NVIDIA Driver Version nvidia-smi</description>
    </item>
    
    <item>
      <title>Stop Git From Asking For Password Every Push And Pull From GitHub</title>
      <link>https://chrisalbon.com/git_and_github/basics/stop_git_from_asking_for_password_every_command/</link>
      <pubDate>Sat, 01 Feb 2020 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/git_and_github/basics/stop_git_from_asking_for_password_every_command/</guid>
      <description>If you cloned your GitHub repository using HTTPS, every time you push or pull a repository from GitHub Git will prompt you for your GitHub username and password. This becomes particularly frustrating if you use multi-factor authentication because you cannot use your regular password but instead use a generated token. You can read more instructions on how to set up that token here.
To fix this:
 Enter the directory containing your repo.</description>
    </item>
    
    <item>
      <title>Add Column</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/add_column/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/add_column/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Add Comment To Column</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/add_comment_to_column/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/add_comment_to_column/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); Describe Table (To See Comments) -- Describe table DESCRIBE TABLE SUPERHEROES;   name type kind null?</description>
    </item>
    
    <item>
      <title>Convert Columns Into Rows</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/convert_columns_into_rows/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/convert_columns_into_rows/</guid>
      <description>UNPIVOT converts a table&amp;rsquo;s columns into rows.
Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE of integers  &amp;#34;AGE&amp;#34; INT, -- Column called 2015 of integers  &amp;#34;2015&amp;#34; INT, -- Column called 2016 of integers  &amp;#34;2016&amp;#34; INT, -- Column called 2017 of integers  &amp;#34;2017&amp;#34; INT, -- Column called 2018 of integers  &amp;#34;2018&amp;#34; INT, -- Column called 2019 of integers  &amp;#34;2019&amp;#34; INT ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, 45, 1, 5, 7, 8, 0), (&amp;#39;Mr.</description>
    </item>
    
    <item>
      <title>Convert Data Types</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/convert_data_types/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/convert_data_types/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2), -- Column called AGE allowing 3 digits with 0 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Create Dummy Columns</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/create_dummy_columns/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/create_dummy_columns/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;AGE&amp;#34; INT, -- Column called STATE allowing up to 100 characters  &amp;#34;STATE&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, &amp;#39;24&amp;#39;, &amp;#39;Maine&amp;#39;), (&amp;#39;Mr.</description>
    </item>
    
    <item>
      <title>Create Or Replace Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_or_replace_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_or_replace_table/</guid>
      <description> Create Table This CREATE OR REPLACE method will create a table and if a table with the same name does already exists, will replace that existing table with the new table.
-- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); </description>
    </item>
    
    <item>
      <title>Create Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_table/</guid>
      <description> Create Table -- Create a table called SUPERHEROES. CREATE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); </description>
    </item>
    
    <item>
      <title>Create Table From Query</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_table_from_query/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_table_from_query/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;Diamond Ninja&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Create Table If It Doesn&#39;t Already Exist</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_table_if_does_not_already_exist/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_table_if_does_not_already_exist/</guid>
      <description> Create Table IF NOT EXISTS tells Snowflake to only create the table if another table with the same name does not already exist. This can be useful if you don&amp;rsquo;t want to run an expensive operation if the data is already there.
-- Create a table called SUPERHEROES. CREATE TABLE IF NOT EXISTS SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); </description>
    </item>
    
    <item>
      <title>Create Table With Column And Table Comments</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_table_with_column_and_table_comments/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_table_with_column_and_table_comments/</guid>
      <description>Create Table Of Superheroes With Comments Column comments concern a particular column, while table comments are about the entire table.
-- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters with a comment.  &amp;#34;ID&amp;#34; VARCHAR (5) COMMENT &amp;#39;A unique ID for each superhero.&amp;#39;, -- Column called ALTER_EGO allowing up to 100 characters with a comment.</description>
    </item>
    
    <item>
      <title>Create Temporary Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/create_temporary_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/create_temporary_table/</guid>
      <description> Create Temporary Table The temporary table will last until the session ends.
-- Create a table called SUPERHEROES. CREATE OR REPLACE TEMP TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); </description>
    </item>
    
    <item>
      <title>Delete A Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/delete_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/delete_table/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Describe A Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/describe_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/describe_table/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Drop Column</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/drop_column/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/drop_column/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Get Absolute Values</title>
      <link>https://chrisalbon.com/snowflake/sql/numeric/get_absolute_values/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/numeric/get_absolute_values/</guid>
      <description>Create Temporary Table CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); Add Rows, One For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;Diamond Ninja&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Get Rows Meetings Multiple Conditions</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/get_rows_meeting_multiple_conditions/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/get_rows_meeting_multiple_conditions/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2), -- Column called AGE allowing 3 digits with 0 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Give Column An Alias</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/give_column_alias/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/give_column_alias/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2), -- Column called AGE allowing 3 digits with 0 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Give Table An Alias</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/give_table_alias/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/give_table_alias/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2), -- Column called AGE allowing 3 digits with 0 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Left Join</title>
      <link>https://chrisalbon.com/snowflake/sql/merge_and_join/left_join/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/merge_and_join/left_join/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Query A Table</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/query_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/query_table/</guid>
      <description>Create A Table For Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR (5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2), -- Column called AGE allowing 3 digits with 0 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert One Row Per Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Query DESCRIBE TABLE like a table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/query_describe_statement/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/query_describe_statement/</guid>
      <description>DESCRIBE TABLE is a powerful tool for understanding the structure of a table. However, in Snowflake the output of DESCRIBE TABLE is not treated like a regular table (i.e. can be manipulated using SELECT). To query DESCRIBE TABLE as a regular table we have to first run it, then run a SELECT query on the last query run which will be DESCRIBE TABLE.
Create Table Of Superheroes -- Create a table called SUPERHEROES.</description>
    </item>
    
    <item>
      <title>Rename Column</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/rename_column/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/rename_column/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Rename Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/rename_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/rename_table/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;BANK_BALANCE&amp;#34; NUMBER(38, 2) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;, &amp;#39;-100.</description>
    </item>
    
    <item>
      <title>Return First Few Rows</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/return_first_few_rows/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/return_first_few_rows/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;AGE&amp;#34; INT, -- Column called STATE allowing up to 100 characters  &amp;#34;STATE&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, &amp;#39;24&amp;#39;, &amp;#39;Maine&amp;#39;), (&amp;#39;Mr.</description>
    </item>
    
    <item>
      <title>Return N Rows After Skipping First K Rows</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/return_n_rows_after_skipping_k_rows/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/return_n_rows_after_skipping_k_rows/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;AGE&amp;#34; INT, -- Column called STATE allowing up to 100 characters  &amp;#34;STATE&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, &amp;#39;24&amp;#39;, &amp;#39;Maine&amp;#39;), (&amp;#39;Mr.</description>
    </item>
    
    <item>
      <title>Sample Random Rows From A Table</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/sample_rows_from_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/sample_rows_from_table/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;AGE&amp;#34; NUMBER(3, 0) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, &amp;#39;24&amp;#39;), (&amp;#39;Mr. Money&amp;#39;, &amp;#39;12&amp;#39;), (&amp;#39;Nuke Miner&amp;#39;, &amp;#39;59&amp;#39;), (&amp;#39;The Knife&amp;#39;, &amp;#39;43&amp;#39;), (&amp;#39;Ninka Baker&amp;#39;, &amp;#39;32&amp;#39;), (&amp;#39;Banana Bomber&amp;#39;, &amp;#39;34&amp;#39;), (&amp;#39;Augustine&amp;#39;, &amp;#39;12&amp;#39;), (&amp;#39;The Kid&amp;#39;, &amp;#39;21&amp;#39;), (&amp;#39;The Viking&amp;#39;, &amp;#39;291&amp;#39;), (&amp;#39;Skull Hustle&amp;#39;, &amp;#39;10&amp;#39;); Sample Where Reach Row Has Chance Of Inclusion -- Select all columns SELECT * -- From the SUPERHEROES table FROM SUPERHEROES -- Sample a subset of rows, where each row has a 25% chance of being selected SAMPLE ROW (25);   ALTER_EGO AGE     The Bomber 24   Nuke Miner 59</description>
    </item>
    
    <item>
      <title>Sort Rows By A Column&#39;s Values</title>
      <link>https://chrisalbon.com/snowflake/sql/basics/sort_rows/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/basics/sort_rows/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100), -- Column called BANK_BALANCE allowing 38 digits with 2 after the decimal point  &amp;#34;AGE&amp;#34; INT, -- Column called STATE allowing up to 100 characters  &amp;#34;STATE&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;The Bomber&amp;#39;, &amp;#39;24&amp;#39;, &amp;#39;Maine&amp;#39;), (&amp;#39;Mr.</description>
    </item>
    
    <item>
      <title>Swap Two Tables</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/swap_two_tables/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/swap_two_tables/</guid>
      <description>SWAP will swap all contents, metadata, and access permissions between two tables. This can be useful by allowing you to build a new version of the table over time and then when you are ready, swapping out the old verison for the new version.
Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>Undelete A Table</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/undelete_table/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/undelete_table/</guid>
      <description>Create Table Of Superheroes -- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters  &amp;#34;ID&amp;#34; VARCHAR(5), -- Column called NAME allowing up to 100 characters  &amp;#34;NAME&amp;#34; VARCHAR(100), -- Column called ALTER_EGO allowing up to 100 characters  &amp;#34;ALTER_EGO&amp;#34; VARCHAR(100) ); Insert Rows For Each Superhero -- Insert rows into SUPERHEROES INSERT INTO SUPERHEROES -- With the values  VALUES (&amp;#39;XF6K4&amp;#39;, &amp;#39;Chris Maki&amp;#39;, &amp;#39;The Bomber&amp;#39;), (&amp;#39;KD5SK&amp;#39;, &amp;#39;Donny Mav&amp;#39;, &amp;#39;Nuke Miner&amp;#39;); View Table Of Superheroes -- View the SUPERHEROES table SELECT * FROM SUPERHEROES;   ID NAME ALTER_EGO     XF6K4 Chris Maki The Bomber   KD5SK Donny Mav Nuke Miner</description>
    </item>
    
    <item>
      <title>View A Column&#39;s Comments</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/view_column_comments/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/view_column_comments/</guid>
      <description>Create Table Of Superheroes With Comments Column comments concern a particular column, while table comments are about the entire table.
-- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters with a comment.  &amp;#34;ID&amp;#34; VARCHAR (5) COMMENT &amp;#39;A unique ID for each superhero.&amp;#39;, -- Column called ALTER_EGO allowing up to 100 characters with a comment.</description>
    </item>
    
    <item>
      <title>View A Table&#39;s Comments</title>
      <link>https://chrisalbon.com/snowflake/sql/tables/view_table_comments/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/snowflake/sql/tables/view_table_comments/</guid>
      <description>Create Table Of Superheroes With Comments Column comments concern a particular column, while table comments are about the entire table.
-- Create a table called SUPERHEROES. If it already exists, replace it. CREATE OR REPLACE TABLE SUPERHEROES ( -- Column called ID allowing up to five characters with a comment.  &amp;#34;ID&amp;#34; VARCHAR (5) COMMENT &amp;#39;A unique ID for each superhero.&amp;#39;, -- Column called ALTER_EGO allowing up to 100 characters with a comment.</description>
    </item>
    
    <item>
      <title>Create A Class</title>
      <link>https://chrisalbon.com/python/object_oriented/create_a_class/</link>
      <pubDate>Sun, 16 Dec 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/object_oriented/create_a_class/</guid>
      <description> Create Simple Class class Soldier: pass Create Instance Of Class jason = Soldier()</description>
    </item>
    
    <item>
      <title>Create Attributes</title>
      <link>https://chrisalbon.com/python/object_oriented/create_attributes/</link>
      <pubDate>Sun, 16 Dec 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/object_oriented/create_attributes/</guid>
      <description> Create Simple Class class Soldier: pass Create Instance Of Class jason = Soldier() Create Attribute jason.age = 36 jason.height = 124 View Attributes # Display a dictionary of attributes jason.__dict__ {&#39;age&#39;: 36, &#39;height&#39;: 124}  </description>
    </item>
    
    <item>
      <title>Create Methods</title>
      <link>https://chrisalbon.com/python/object_oriented/create_methods/</link>
      <pubDate>Sun, 16 Dec 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/object_oriented/create_methods/</guid>
      <description>Create Simple Class # Create a class called Soldier class Soldier: &amp;#34;&amp;#34;&amp;#34;Creates a class representing a soldier.&amp;#34;&amp;#34;&amp;#34; # Whenever an object is created from this class, # assign the name and initial rank. def __init__(self, name, rank): self.name = name self.rank = 1 # Promote soldier to a higher rank def promote(self): # Set rank to current rank plus one self.rank = self.rank + 1 Create Soldier Named Jason # Create an instance of Soldier class called &amp;#39;jason&amp;#39; jason = Soldier(&amp;#39;Jason Miller&amp;#39;, 1) View Jason&amp;rsquo;s Attributes # Display a dictionary of attributes jason.</description>
    </item>
    
    <item>
      <title>List All Files Of Certain Type In A Directory</title>
      <link>https://chrisalbon.com/python/basics/list_all_files_of_particular_type_in_directory/</link>
      <pubDate>Tue, 20 Nov 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/list_all_files_of_particular_type_in_directory/</guid>
      <description>Preliminaries import os List All .ipynb Files In Directory [x for x in os.listdir() if x.endswith(&amp;#34;.ipynb&amp;#34;)] [&#39;create_a_new_file_and_the_write_to_it.ipynb&#39;, &#39;unpacking_a_tuple.ipynb&#39;, &#39;unpacking_function_arguments.ipynb&#39;, &#39;convert_html_symbols_to_strings.ipynb&#39;, &#39;arithmetic_basics.ipynb&#39;, &#39;cleaning_text.ipynb&#39;, &#39;applying_functions_to_list_items.ipynb&#39;, &#39;while_statements.ipynb&#39;, &#39;continue_and_break_loops.ipynb&#39;, &#39;queues_and_stacks.ipynb&#39;, &#39;numpy_array_basics.ipynb&#39;, &#39;schedule_run_in_the_future.ipynb&#39;, &#39;Untitled.ipynb&#39;, &#39;repr_vs_str.ipynb&#39;, &#39;using_named_tuples_to_store_data.ipynb&#39;, &#39;hard_wrapping_text.ipynb&#39;, &#39;string_formatting.ipynb&#39;, &#39;functions_vs_generators.ipynb&#39;, &#39;nesting_lists.ipynb&#39;, &#39;sort_a_list_of_strings_by_length.ipynb&#39;, &#39;filter_items_in_list_with_filter.ipynb&#39;, &#39;swapping_variable_values.ipynb&#39;, &#39;iterating_over_dictionary_keys.ipynb&#39;, &#39;iterate_ifelse_over_list.ipynb&#39;, &#39;recursive_functions.ipynb&#39;, &#39;for_loops.ipynb&#39;, &#39;use_command_line_arguments_in_a_function.ipynb&#39;, &#39;logical_operations.ipynb&#39;, &#39;strings_to_datetime.ipynb&#39;, &#39;flatten_list_of_lists.ipynb&#39;, &#39;nested_for_loops_using_list_comprehension.ipynb&#39;, &#39;Untitled1.ipynb&#39;, &#39;function_basics.ipynb&#39;, &#39;find_the_max_value_in_a_dictionary.ipynb&#39;, &#39;any_all_max_min_sum.ipynb&#39;, &#39;display_json.ipynb&#39;, &#39;exiting_a_loop.ipynb&#39;, &#39;date_and_time_basics.ipynb&#39;, &#39;add_padding_around_string.ipynb&#39;, &#39;iterate_over_multiple_lists_simultaneously.ipynb&#39;, &#39;breaking_up_string_variables.ipynb&#39;, &#39;mocking_functions.ipynb&#39;, &#39;compare_two_dictionaries.ipynb&#39;, &#39;chain_together_lists.ipynb&#39;, &#39;function_annotation_examples.ipynb&#39;, &#39;brute_force_d20_simulator.ipynb&#39;, &#39;string_operations.ipynb&#39;, &#39;data_structure_basics.ipynb&#39;, &#39;string_indexing.ipynb&#39;, &#39;math_operations.ipynb&#39;, &#39;numpy_array_basic_operations.ipynb&#39;, &#39;ifelse_on_any_or_all_elements.ipynb&#39;, &#39;sort_a_list_by_last_name.ipynb&#39;, &#39;apply_operations_over_items_in_lists.</description>
    </item>
    
    <item>
      <title>Add Columns To Text</title>
      <link>https://chrisalbon.com/linux/text/add_columns_to_text/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/add_columns_to_text/</guid>
      <description>Create A File With Comma Separated Text echo &amp;#34;chris, 34, male&amp;#34; &amp;gt;&amp;gt; staff.txtecho &amp;#34;sarah, 22, female&amp;#34; &amp;gt;&amp;gt; staff.txtecho &amp;#34;Bob, 59, male&amp;#34; &amp;gt;&amp;gt; staff.txt View File cat staff.txt chris, 34, male sarah, 22, female Bob, 59, male  Extract Text By Breaking Into Columns And Save To File cut the text in staff.txt that is separated by commas (-d &#39;,&#39;) into columns, then take the second (-f 2) column, and finally save to ages.</description>
    </item>
    
    <item>
      <title>Copy Files And Directories</title>
      <link>https://chrisalbon.com/linux/basics/copy_files_and_directories/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/copy_files_and_directories/</guid>
      <description>The cp command copy-pastes the file to a destination directory. The mv command moves a file (deleting it from the original directory).
Make File touch file.txt Make Directory mkdir example View Directory Contents Directory ls -l total 4 drwxrwxr-x 2 chris chris 4096 Jul 24 08:49 example -rw-rw-r-- 1 chris chris 0 Jul 24 08:49 file.txt  Copy File To Directory cp file.txt example Change To Directory cd example View Directory Contents Directory ls -l total 0 -rw-rw-r-- 1 chris chris 0 Jul 24 08:49 file.</description>
    </item>
    
    <item>
      <title>Count Unique Rows</title>
      <link>https://chrisalbon.com/linux/text/count_unique_rows/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/count_unique_rows/</guid>
      <description>Create Example File With List Of Names Notice that we have duplicated rows
echo &amp;#39;Luca Gartside&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Reule Smyth&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Uli Pinetotem&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Uli Pinetotem&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Uli Pinetotem&amp;#39; &amp;gt;&amp;gt; adventurers.txt View File cat adventurers.txt Luca Gartside Reule Smyth Spencer Smit Spencer Smit Spencer Smit Uli Pinetotem Uli Pinetotem Uli Pinetotem  Get Unique Rows cat adventurers.</description>
    </item>
    
    <item>
      <title>Delete Files And Directories</title>
      <link>https://chrisalbon.com/linux/basics/delete_files_and_directories/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/delete_files_and_directories/</guid>
      <description>The rm (remove) command is used to delete files and folders in Linux.
Create Files touch sales.csvtouch config.jsontouch README.mdtouch documentation.htmltouch sales.html Create Subdirectory mkdir sales_reports Create File In Subdirectory touch sales_reports/report.html View Current Directory ls -l total 4 -rw-rw-r-- 1 chris chris 0 Jul 24 17:01 config.json -rw-rw-r-- 1 chris chris 0 Jul 24 17:01 documentation.html -rw-rw-r-- 1 chris chris 0 Jul 24 17:01 README.md -rw-rw-r-- 1 chris chris 0 Jul 24 17:01 sales.</description>
    </item>
    
    <item>
      <title>Delete Files And Directories In Current Directory</title>
      <link>https://chrisalbon.com/linux/basics/delete_files_and_subdirectories_in_current_directory/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/delete_files_and_subdirectories_in_current_directory/</guid>
      <description>The rm (remove) command is used to delete files and folders in Linux.
Create Example Files touch devops.txt hr.txt marketing.txt operations.txt procurement.txt sales.txt Create Example Subdirectories mkdir devops sales marketing Show Directory Contents ls -l total 12 drwxrwxr-x 2 chris chris 4096 Jul 28 09:05 devops -rw-rw-r-- 1 chris chris 0 Jul 28 09:05 devops.txt -rw-rw-r-- 1 chris chris 0 Jul 28 09:05 hr.txt drwxrwxr-x 2 chris chris 4096 Jul 28 09:05 marketing -rw-rw-r-- 1 chris chris 0 Jul 28 09:05 marketing.</description>
    </item>
    
    <item>
      <title>Extract Text</title>
      <link>https://chrisalbon.com/linux/text/extract_text/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/extract_text/</guid>
      <description>cut is a good cool to extract text that follows some schema such as tab or comma delimited.
Create A File With Comma Separated Text echo &amp;#34;chris, 34, male&amp;#34; &amp;gt;&amp;gt; staff.txtecho &amp;#34;sarah, 22, female&amp;#34; &amp;gt;&amp;gt; staff.txtecho &amp;#34;Bob, 59, male&amp;#34; &amp;gt;&amp;gt; staff.txt View File cat staff.txt chris, 34, male sarah, 22, female Bob, 59, male  Extract Text By Breaking Into Columns cut the text in staff.txt that is separated by commas (-d &#39;,&#39;) into columns, then take the second (-f 2) column.</description>
    </item>
    
    <item>
      <title>Find And Replace</title>
      <link>https://chrisalbon.com/linux/text/find_and_replace/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/find_and_replace/</guid>
      <description> Create Example File With List Of Adventurers echo &amp;#39;Luca Gartside&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Reule Smyth&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txt View Original File $ cat adventurers.txt Luca Gartside Reule Smyth Spencer Smit  Search And Replace Here we use the streaming edit (sed) command to replace Spencer Smit with Matthew Aldworth in the file adventurers.txt
$ sed &amp;#34;s/Spencer Smit/Matthew Aldworth/&amp;#34; adventurers.txt Luca Gartside Reule Smyth Matthew Aldworth  </description>
    </item>
    
    <item>
      <title>Move Files And Directories</title>
      <link>https://chrisalbon.com/linux/basics/move_files_and_directories/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/move_files_and_directories/</guid>
      <description>The mv command moves a file (deleting it from the original directory). The cp command copy-pastes the file to a destination directory.
Make File touch file.txt Make Directory mkdir example_folder View Directory Contents Directory ls -l total 8 drwxrwxr-x 2 chris chris 4096 Jul 24 13:23 example_folder -rw-rw-r-- 1 chris chris 0 Jul 24 13:22 file.txt  Move File To Directory mv file.txt example_folder View Directory Contents Directory ls -l total 8 drwxrwxr-x 2 chris chris 4096 Jul 24 13:23 example_folder  Change To Directory cd example_folder View Directory Contents Directory ls -l total 0 -rw-rw-r-- 1 chris chris 0 Jul 24 13:22 file.</description>
    </item>
    
    <item>
      <title>Rename File</title>
      <link>https://chrisalbon.com/linux/basics/rename_file/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/rename_file/</guid>
      <description> The mv (move) command is used to rename files To rename a file, &amp;ldquo;move&amp;rdquo; it from one filename to another.
Make File touch untitled.txt View Directory Contents Directory ls -l total 0 -rw-rw-r-- 1 chris chris 0 Jul 24 13:22 untitled.txt  Make File mv untitled.txt august_records.txt View Directory Contents Directory ls -l total 0 -rw-rw-r-- 1 chris chris 0 Jul 24 13:22 august_records.txt  mv Options:  -u Copy only files that don&amp;rsquo;t exist or are newer than files with the same names in the destination directory -v Show verbose description of copy -i Prompt if copy would override file  </description>
    </item>
    
    <item>
      <title>See Disk Drive Space</title>
      <link>https://chrisalbon.com/linux/basics/see_disk_drive_space/</link>
      <pubDate>Mon, 16 Jul 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/see_disk_drive_space/</guid>
      <description> To view the amount of used and free memory on a system, we can use the df command.
View Disk Drive Space df Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk1s1 975221040 415404896 554253656 43% 2387799 9223372036852388008 0% / devfs 382 382 0 100% 662 0 100% /dev /dev/disk1s4 975221040 4194384 554253656 1% 2 9223372036854775805 0% /private/var/vm map -hosts 0 0 0 100% 0 0 100% /net map auto_home 0 0 0 100% 0 0 100% /home  </description>
    </item>
    
    <item>
      <title>Create PostgreSQL Database With Python</title>
      <link>https://chrisalbon.com/postgresql/basics/create_postgresql_database_with_python/</link>
      <pubDate>Mon, 18 Jun 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/create_postgresql_database_with_python/</guid>
      <description>Preliminaries # Load libraries from sqlalchemy import create_engine from sqlalchemy_utils import create_database, database_exists, drop_database # Create PostgreSQL connection engine = create_engine(&amp;#34;postgres://localhost/notes_db&amp;#34;) # Load sql_magic so we can write SQL in Jupyter Notebooks %load_ext sql_magic # Setup SQL connection to the postgreSQL engine we created %config SQL.conn_name = &amp;#39;engine&amp;#39; Create Database # If a PostgreSQL database with this name exists if database_exists(engine.url): # Delete PostgreSQL database  drop_database(engine.url) # Create empty PostgreSQL database create_database(engine.</description>
    </item>
    
    <item>
      <title>Add Column</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/add_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/add_column/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Add Column -- Alter the table called adventurers ALTER TABLE adventurers -- Add a column called armor that is a 255 -- character string field with the default value of null ADD COLUMN armor varchar(255) NULL View Table -- Retrieve all rows SELECT * FROM adventurers nameageraceweaponarmor Fjoak Doom-Wife28HumanAxeNULL Alooneric Cortte29ElfBowNULL Piperel Ramsay35ElfSwordNULL Casimir Yardley14ElfMagicNULL</description>
    </item>
    
    <item>
      <title>Adding Line Numbers</title>
      <link>https://chrisalbon.com/linux/text/adding_line_numbers/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/adding_line_numbers/</guid>
      <description> Make File With Some Content echo &amp;#34;Jan&amp;#34; &amp;gt;&amp;gt; sales.txt; echo &amp;#34;Feb&amp;#34; &amp;gt;&amp;gt; sales.txt; echo &amp;#34;Mar&amp;#34; &amp;gt;&amp;gt; sales.txt Make File Contents cat sales.txt Jan Feb Mar  Make File Contents With Line Numbers cat -n sales.txt  1	Jan 2	Feb 3	Mar  </description>
    </item>
    
    <item>
      <title>Adding Or Substracting Time</title>
      <link>https://chrisalbon.com/postgresql/dates/adding_or_substracting_time/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/dates/adding_or_substracting_time/</guid>
      <description>Create Table -- Create table called dead_adventurers CREATE TABLE dead_adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255), -- date variable  died date ) Insert Rows -- Insert into the table dead_adventurers INSERT INTO dead_adventurers (name, age, race, weapon, died) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;, &amp;#39;09-Nov-2017&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;, &amp;#39;10-JAN-2017&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;, &amp;#39;12-APR-2016&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;, &amp;#39;06-MAY-2017&amp;#39;) Create New Column Three Days Later -- Create a column called three_days_laters that takes the value -- of died and adds three days to it SELECT died + INTERVAL &amp;#39;3 day&amp;#39; AS three_days_later -- From adventurers table FROM dead_adventurers three_days_later 2017-11-12 00:00:00.</description>
    </item>
    
    <item>
      <title>All Unique Values In Two Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/all_unique_values_in_two_tables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/all_unique_values_in_two_tables/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Find The Combined Unique Values In Two Tables -- Retrieve all weapons from elves SELECT weapon FROM elves -- Combine unique values with.</description>
    </item>
    
    <item>
      <title>Append Error To File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/append_error_to_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/append_error_to_file/</guid>
      <description>We can append the errors of a program to a file by using the 2&amp;gt;&amp;gt; operator.
Run Error Producing Code To See Error pwd -thiswillproduceerror -bash: pwd: -t: invalid option pwd: usage: pwd [-LP]  Create File touch errors.txt Append The Standard Error To File Note that we run pwd -thiswillproduceerror three times, each time appending the results to errors.txt.
pwd -thiswillproduceerror 2&amp;gt;&amp;gt; errors.txt; pwd -thiswillproduceerror 2&amp;gt;&amp;gt; errors.txt; pwd -thiswillproduceerror 2&amp;gt;&amp;gt; errors.</description>
    </item>
    
    <item>
      <title>Append File Contents To Another File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/append_file_contents_to_another_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/append_file_contents_to_another_file/</guid>
      <description> Create A File With A Record Of A Sale echo &amp;#39;Bob Jones bought an apple for $2&amp;#39; &amp;gt; sales_monday.txt Create A File With A Record Of A Sale echo &amp;#39;Sarah Miller bought an orange for $2&amp;#39; &amp;gt; sales_tuesday.txt Create An Empty File For All Sales touch sales.txt Append Contents Of Both Files To All Sales File cat sales_monday.txt sales_tuesday.txt &amp;gt;&amp;gt; sales.txt View Contents Of All Sales File cat sales.txt Bob Jones bought an apple for $2 Sarah Miller bought an orange for $2  </description>
    </item>
    
    <item>
      <title>Append Output To File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/append_outputs_to_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/append_outputs_to_file/</guid>
      <description>We can append the outputs of a program to a file by using the &amp;gt;&amp;gt; operator.
Run date To See Standard Output Note +&amp;quot;%T.%N&amp;quot; gives the current time with nanseconds
date +&amp;#34;%T.%N&amp;#34; 21:19:26.291589981  Create File touch records.txt Append The Standard Output To File Note that we run date +%s%N four times, each time appending the results to records.txt.
date +&amp;#34;%T.%N&amp;#34; &amp;gt;&amp;gt; records.txt; date +&amp;#34;%T.%N&amp;#34; &amp;gt;&amp;gt; records.txt; date +&amp;#34;%T.%N&amp;#34; &amp;gt;&amp;gt; records.</description>
    </item>
    
    <item>
      <title>Append Outputs And Errors To File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/append_output_and_errors_to_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/append_output_and_errors_to_file/</guid>
      <description>To write both the output and the errors of a program to a file, we can use the &amp;amp;&amp;gt;&amp;gt; on newer versions of bash to append (not write over) either standard outputs or standard errors to a file.
Create Code That Will Produce An Output pwd /home/chris/example_directory  Create Code That Will Produce An Error pwd -thisisafakeargumenttoproduceerror -bash: pwd: -t: invalid option pwd: usage: pwd [-LP]  Create File To Hold Output And Errors touch log.</description>
    </item>
    
    <item>
      <title>Apply Operation To Column</title>
      <link>https://chrisalbon.com/postgresql/basics/apply_operation_to_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/apply_operation_to_column/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;) Apply Operation To Column -- Update the age column, multiplying all age values by 10 UPDATE adventurers SET age = age * 10 Apply Operation To Column With Conditions -- Update the name column where the race column is &amp;#39;Elf&amp;#39; UPDATE adventurers SET name = &amp;#39;Some Elf&amp;#39; WHERE race = &amp;#39;Elf&amp;#39; View Table -- Retrieve data SELECT * FROM adventurers nameagerace Fjoak Doom-Wife280Human Some Elf290Elf Some Elf350Elf Some Elf140Elf</description>
    </item>
    
    <item>
      <title>Archive And Unarchive Files</title>
      <link>https://chrisalbon.com/linux/basics/archive_and_unarchive_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/archive_and_unarchive_files/</guid>
      <description>Make Directory mkdir regiment_data Make Files In Directory touch regiment_data/battles.txt regiment_data/regiment.txt Compress Directory Here we create (c) an archive file from the directory regiment_data called file (f) called regiment.tar.
tar cf regiment.tar regiment_data View Contents Of Directory ls -l total 24 drwxrwxr-x 2 chris chris 4096 Jul 31 13:23 regiment_data -rw-rw-r-- 1 chris chris 10240 Jul 31 13:25 regiment.tar  Uncompress Directory Here we unarchive (x) the archived file (f) called regiment.</description>
    </item>
    
    <item>
      <title>Calculate Max, Min, Or Average Of Column</title>
      <link>https://chrisalbon.com/postgresql/numeric/max_min_and_average_of_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/numeric/max_min_and_average_of_column/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Calculate Max -- Return maximum value of of age in adventurers SELECT MAX(age) FROM adventurers max 35</description>
    </item>
    
    <item>
      <title>Calculate Running Total</title>
      <link>https://chrisalbon.com/postgresql/numeric/calculate_running_total/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/numeric/calculate_running_total/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- integer variable  id int, -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (id, name, age, race, weapon) VALUES (1, &amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (2, &amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (3, &amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (4, &amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create Running Total -- Get name, age, and.</description>
    </item>
    
    <item>
      <title>Calculate Sum Of Column</title>
      <link>https://chrisalbon.com/postgresql/numeric/calculate_sum_of_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/numeric/calculate_sum_of_column/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Calculate Sum -- Return total value of of age in adventurers SELECT SUM(age) FROM adventurers sum 106</description>
    </item>
    
    <item>
      <title>Calculate Time Duration</title>
      <link>https://chrisalbon.com/postgresql/dates/calculate_time_duration/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/dates/calculate_time_duration/</guid>
      <description>Create Table -- Create table called dead_adventurers CREATE TABLE dead_adventurers ( -- string variable  name varchar(255), -- string variable  race varchar(255), -- string variable  weapon varchar(255), -- date variable  started_adventure date, -- date variable  died date ) Insert Rows -- Insert into the table dead_adventurers INSERT INTO dead_adventurers (name, race, weapon, started_adventure, died) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;, &amp;#39;09-JAN-2017&amp;#39;, &amp;#39;10-Nov-2017&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;, &amp;#39;10-JAN-2017&amp;#39;, &amp;#39;11-JAN-2017&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;, &amp;#39;11-JAN-2017&amp;#39;, &amp;#39;12-APR-2017&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;, &amp;#39;23-JAN-2017&amp;#39;, &amp;#39;06-MAY-2017&amp;#39;) Calculate Duration Between Two Date Values -- Get all the columns, and add a new column called days_on_adventure -- that is the number of days between the start of the adventurer and when they died SELECT *, died - started_adventure AS days_on_adventure FROM dead_adventurers nameraceweaponstarted_adventuredieddays_on_adventure Fjoak Doom-WifeHumanAxe2017-01-092017-11-10305 Alooneric CortteElfBow2017-01-102017-01-111 Piperel RamsayElfSword2017-01-112017-04-1291 Casimir YardleyElfMagic2017-01-232017-05-06103</description>
    </item>
    
    <item>
      <title>Cartesian Product Of Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/cartesian_product/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/cartesian_product/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Adventurer&amp;rsquo;s Equipment -- Create table called equipment CREATE TABLE equipment ( -- string variable  name varchar(255), -- string variable  clothes varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Dwarf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Dwarf&amp;#39;) Insert Rows Into Equipment Table INSERT INTO equipment (name, clothes, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather Armor&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Robe&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Tasar Keynelis&amp;#39;, &amp;#39;Tunic&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Sataleeti Iarroris&amp;#39;,&amp;#39;Chainmail&amp;#39;, &amp;#39;Axe&amp;#39;) Cartestian Product Of Tables -- Return the name of people from the adventurers table, age, race, clothes, and weapon SELECT adventurers.</description>
    </item>
    
    <item>
      <title>Chain Multiple Commands</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/chain_multiple_commands/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/chain_multiple_commands/</guid>
      <description>Most commands take in some input and return some output. In Linux, we can use this feature to chain together multiple commands, each one taking the standard output of the previous command as its standard input. We can do this using the pipeline operator, |.
Create Example Files touch sales.txt marketing.txt operations.txt hr.txt procurement.txt devops.txt Create A Pipeline ls and sort are two commands. In this example we pipe the standard output of ls into the standard input of sort and then see sort&amp;rsquo;s standard output.</description>
    </item>
    
    <item>
      <title>Change Permissions</title>
      <link>https://chrisalbon.com/linux/basics/change_permissions/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/change_permissions/</guid>
      <description>To change the permissions of a file or directory we use the chmod command. chmod takes three digits, each one representing the permissions for the user, group, and everyone. Thus, 741 would mean:
 The user can read, write, and execute (7) The group can read only (4) Everyone can execute (1)  Here is a handy list translating the octal numbering system to permissions:
 0 - no permission 1 - execute 2 - write 3 - write and execute 4 - read 5 - read and execute 6 - read and write 7 - read, write, and execute  Create File touch company_data.</description>
    </item>
    
    <item>
      <title>Change Values</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/change_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/change_values/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) Update Row Values -- Update the elves table UPDATE elves -- To set age to the current age plus 1 SET age = age + 1 View Elves Table -- Retrieve all rows from the view Elf SELECT * FROM elves nameageracealive Dallar Woodfoot26ElfYes Cordin Garner30ElfYes Keat Knigh25ElfYes Colbat Nalor125ElfYes</description>
    </item>
    
    <item>
      <title>Changing Directories</title>
      <link>https://chrisalbon.com/linux/basics/changing_directories/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/changing_directories/</guid>
      <description>We can navigate Linux systems in the command line using the cd command.
View Current Working Directory pwd /home/chris  List Subdirectories Note -d */ is a hacky means to list only directories (not files) in a directory.
ls -d */ anaconda3/ automatic_backups/ Desktop/ Documents/ Downloads/ Music/ nvvp_workspace/ Pictures/ Public/ Templates/ tensorflow/ Videos/  Change To A Directory Using An Absolute Path cd /home/chris/anaconda3 View Current Working Directory pwd /home/chris/anaconda3  Go Up One Directory cd .</description>
    </item>
    
    <item>
      <title>Check Current Date And Time</title>
      <link>https://chrisalbon.com/linux/basics/check_current_date_and_time/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/check_current_date_and_time/</guid>
      <description> If we want to see the system&amp;rsquo;s current date and time, we can use the date command.
Check System&amp;rsquo;s Current Time date Tue Jul 17 10:07:27 PDT 2018  Check System&amp;rsquo;s Current Time In UTC Time date -u Tue Jul 17 17:26:25 UTC 2018  </description>
    </item>
    
    <item>
      <title>Compare Values To Subquery</title>
      <link>https://chrisalbon.com/postgresql/basics/compare_values_to_subquery/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/compare_values_to_subquery/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Check If Each Elf Is Older Than Any Of The Dwarves -- Retrieve All The Elves SELECT * FROM elves -- Where their age is greater than at least one WHERE age &amp;gt; ANY ( -- Of all the Dwarves  SELECT age FROM dwarves ) nameageraceweapon Dallar Woodfoot25ElfBow Cordin Garner29ElfBow Keat Knigh24ElfSword Colbat Nalor124ElfMagic</description>
    </item>
    
    <item>
      <title>Comparing Text Files</title>
      <link>https://chrisalbon.com/linux/text/comparing_text_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/comparing_text_files/</guid>
      <description>The diff command in Linux will show us the where the lines in text files differ and ignore lines that are the same.
Create Text File 1 echo &amp;#34;Khaydarbi Melikov is a foot soldier.&amp;#34; &amp;gt;&amp;gt; regiment_version1.txtecho &amp;#34;Khaydarbi Melikov is a member of the the Maroon Martyrs regiment&amp;#34; &amp;gt;&amp;gt; regiment_version1.txt Create Text File 2 echo &amp;#34;Khaydarbi Melikov is a foot soldier.&amp;#34; &amp;gt;&amp;gt; regiment_version2.txtecho &amp;#34;Khaydarbi Melikov is a member of the Reserve regiment&amp;#34; &amp;gt;&amp;gt; regiment_version2.</description>
    </item>
    
    <item>
      <title>Concatenate Multiple Files</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/concatenate_multiple_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/concatenate_multiple_files/</guid>
      <description>Often large collections of data will be broken into multiple smaller files. The command line makes it easy to concatenate the contents of these files into a single file for analysis.
Create Multiple Files In this example each file contains a single record of a sale, however in the real world each file can contain hundreds or even millions of records.
echo &amp;#39;Alan Jones&amp;#39;, &amp;#39;$50&amp;#39;&amp;gt; sales_records_1.csv echo &amp;#39;Stephanie Lawson&amp;#39;, &amp;#39;$20&amp;#39;&amp;gt; sales_records_2.</description>
    </item>
    
    <item>
      <title>Concatenate Multiple Table</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/concatenate_multiple_tables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/concatenate_multiple_tables/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Orcs -- Create table called orcs CREATE TABLE orcs ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Insert Rows Into Orc Table INSERT INTO orcs (name, age, race, weapon) VALUES (&amp;#39;Wokganit&amp;#39;, 23, &amp;#39;Orc&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Wudugog&amp;#39;, 145, &amp;#39;Orc&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Wegigoth&amp;#39;, 12, &amp;#39;Orc&amp;#39;, &amp;#39;Magic&amp;#39;), (&amp;#39;Wulgha&amp;#39;, 23, &amp;#39;Orc&amp;#39;, &amp;#39;Axe&amp;#39;) Concatenate All Tables -- All rows from elf table SELECT * FROM elves -- Concatenate with.</description>
    </item>
    
    <item>
      <title>Concatenate Values</title>
      <link>https://chrisalbon.com/postgresql/text/concatenate_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/text/concatenate_values/</guid>
      <description>Note: This code works in PostgreSQL databases, but might not work in other SQL database systems (e.g. MySQL).
Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Two Columns -- Retrieve name and age values and concatenate together as a sentence SELECT name||&amp;#39; is &amp;#39;||age||&amp;#39; years old.</description>
    </item>
    
    <item>
      <title>Convert Floats To Integers</title>
      <link>https://chrisalbon.com/postgresql/numeric/convert_floats_to_integers/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/numeric/convert_floats_to_integers/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Calculate Average -- Return average value of of age in adventurers SELECT AVG(age) FROM adventurers avg 26.</description>
    </item>
    
    <item>
      <title>Copy Rows From One Table To Another</title>
      <link>https://chrisalbon.com/postgresql/basics/copy_rows_from_one_table_to_another/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/copy_rows_from_one_table_to_another/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Villains -- Create table called equipment CREATE TABLE villains ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Insert Row Into Adventurers -- Insert into the table adventurers INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;) View Adventurers Table -- Retrieve all rows SELECT * FROM adventurers nameagerace Fjoak Doom-Wife28Human</description>
    </item>
    
    <item>
      <title>Copy Table Structure</title>
      <link>https://chrisalbon.com/postgresql/tables/copy_table_structure/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/copy_table_structure/</guid>
      <description> Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create New Table Using Existing Table&amp;rsquo;s Structure -- Create table called adventurers_copy using the same columns as... CREATE TABLE adventurers_copy AS ( -- The adventurers table  SELECT * FROM adventurers ) </description>
    </item>
    
    <item>
      <title>Count Rows</title>
      <link>https://chrisalbon.com/postgresql/basics/count_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/count_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Count Rows -- Count rows in adventurers SELECT COUNT(*) FROM adventurers count 4</description>
    </item>
    
    <item>
      <title>Count Unique Values</title>
      <link>https://chrisalbon.com/postgresql/basics/count_unique_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/count_unique_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Count Unique Values In Race -- Count the number of unique values in the race column SELECT COUNT (DISTINCT race) FROM adventurers count 2</description>
    </item>
    
    <item>
      <title>Create Bucket</title>
      <link>https://chrisalbon.com/aws/s3/cli/create_bucket/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/aws/s3/cli/create_bucket/</guid>
      <description> Create Bucket Make a bucket (mb) on AWS S3 called kicks-pasta-steer. The bucket name you choose must be globally unique, meaning nobody else in the world must have used that bucket name before.
aws s3 mb s3://kicks-pasta-steer make_bucket: kicks-pasta-steer  </description>
    </item>
    
    <item>
      <title>Create Column Aliases</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/create_column_aliases/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/create_column_aliases/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Two Columns -- Retrieve name and weapon column, renamed full_name and primary_weapon SELECT name as full_name, weapon as primary_weapon FROM adventurers full_nameprimary_weapon Fjoak Doom-WifeAxe Alooneric CortteBow Piperel RamsaySword Casimir YardleyMagic</description>
    </item>
    
    <item>
      <title>Create Column Conditional On Another Column</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/create_column_condition_on_another_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/create_column_condition_on_another_column/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create An If Else Statement There are a number of ways to do if-else in SQL, my prefered way is the CASE statement.</description>
    </item>
    
    <item>
      <title>Create Column Index</title>
      <link>https://chrisalbon.com/postgresql/basics/create_column_index/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/create_column_index/</guid>
      <description> Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) Create Index -- Index the names column in the elves table CREATE INDEX ON elves (name) </description>
    </item>
    
    <item>
      <title>Create Column Of Values</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/create_column_of_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/create_column_of_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create Column Of Values -- Get all rows and add a column called training where all values are &amp;#39;elite&amp;#39; SELECT *, &amp;#39;elite&amp;#39; as training FROM adventurers nameageraceweapontraining Fjoak Doom-Wife28HumanAxeelite Alooneric Cortte29ElfBowelite Piperel Ramsay35ElfSwordelite Casimir Yardley14ElfMagicelite</description>
    </item>
    
    <item>
      <title>Create Command</title>
      <link>https://chrisalbon.com/linux/basics/create_command/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/create_command/</guid>
      <description>Check If Command&amp;rsquo;s Name Is Taken type make_example_directory -bash: type: make_example_directory: not found  Okay good!
Create Custom Command Let us create a custom command that creates a bunch of files and subdirectories in a directory. I&amp;rsquo;ve used this command a few times for tutorial to simulate a real project. We will separate each command using ; so they can all be on one line. Specifically, the commands we will run are:</description>
    </item>
    
    <item>
      <title>Create Directory</title>
      <link>https://chrisalbon.com/linux/basics/create_directory/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/create_directory/</guid>
      <description>When we want to create a directory in the Linux command line, we can use the mkdir (make directory) command.
View Directory Contents ls -l total 60 drwxrwxr-x 20 chris chris 4096 Oct 11 2017 anaconda3 drwxrwxr-x 2 chris chris 4096 Oct 13 2017 automatic_backups drwxr-xr-x 3 chris chris 4096 Oct 21 2017 Desktop drwxr-xr-x 2 chris chris 4096 Oct 10 2017 Documents drwxr-xr-x 2 chris chris 4096 Jul 19 10:47 Downloads -rw-r--r-- 1 chris chris 8980 Oct 10 2017 examples.</description>
    </item>
    
    <item>
      <title>Create Environment Variable</title>
      <link>https://chrisalbon.com/linux/environment/create_environment_variables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/environment/create_environment_variables/</guid>
      <description>The best way to store login credentials and API tokens/secrets is by creating environment variables for them. This means they are variables in the Linux system and thus not present in any code that is shared on GitHub.
There are many ways to create environment variables, but my personal preference is to add them to the .bashrc file in our home directory. .bashrc does a lot of things, but it is a standard place to put customizations to our system &amp;ndash; for example, custom variables.</description>
    </item>
    
    <item>
      <title>Create File</title>
      <link>https://chrisalbon.com/linux/basics/create_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/create_file/</guid>
      <description>There are a number of ways to create files in the Linux command line.
View Directory Contents ls -l total 0  Create An Empty File touch empty_file.txt Create Another Empty File &amp;gt; another_empty_file.txt Create File With Some Content echo &amp;#39;This is the contents to the file&amp;#39; &amp;gt; hello_world.txt Quickly Create A File With Some Contents cat &amp;gt; hello_world.txt Then type the contents of the file and press ctrl-d</description>
    </item>
    
    <item>
      <title>Create Primary Key</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/create_primary_key/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/create_primary_key/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- integer variable  adventurer_id INT, -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255), PRIMARY KEY (adventurer_id) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (adventurer_id, name, age, race, weapon) VALUES (1, &amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (2, &amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (3, &amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (4, &amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) View Table -- Retrieve all rows SELECT * FROM adventurers adventurer_idnameageraceweapon 1Fjoak Doom-Wife28HumanAxe 2Alooneric Cortte29HumanBow 3Piperel Ramsay35ElfBow 4Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Create Sequential List Of Files And Directories</title>
      <link>https://chrisalbon.com/linux/basics/create_sequential_list_of_files_or_directories/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/create_sequential_list_of_files_or_directories/</guid>
      <description>Create Sequential List Of Files touch script_version_{1..5}.py Create Sequential List Of Directories mkdir data_{2015..2018} View Files And Directories ls -l total 16 drwxrwxr-x 2 chris chris 4096 Jul 29 11:17 data_2015 drwxrwxr-x 2 chris chris 4096 Jul 29 11:17 data_2016 drwxrwxr-x 2 chris chris 4096 Jul 29 11:17 data_2017 drwxrwxr-x 2 chris chris 4096 Jul 29 11:17 data_2018 -rw-rw-r-- 1 chris chris 0 Jul 29 11:18 script_version_1.py -rw-rw-r-- 1 chris chris 0 Jul 29 11:18 script_version_2.</description>
    </item>
    
    <item>
      <title>Create Subquery</title>
      <link>https://chrisalbon.com/postgresql/basics/create_subquery/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/create_subquery/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create Subquery -- Retrieve all the rows in adventurers SELECT * FROM adventurers -- Where the name of the adventurer is in WHERE name IN -- A subquery that will ( -- Select all the names in adventurers  SELECT name FROM adventurers -- Where race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) nameagerace Alooneric Cortte29Elf Piperel Ramsay35Elf Casimir Yardley14Elf</description>
    </item>
    
    <item>
      <title>Create Symbolic Links</title>
      <link>https://chrisalbon.com/linux/basics/create_symbolic_links/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/create_symbolic_links/</guid>
      <description>In Linux, we can use ln to create a link between files. A common use case is shown below, where we have a symbolic link from the current configuration file config_settings_v293.txt and a link config_setting.txt. In our code, we can refer config_settings.txt as if we were refering to config_settings_v293.txt. However, when a new version of the configuration settings is released, config_settings_v294.txt, we can swap the symbolic link from config_settings_v293.txt to config_settings_v294.</description>
    </item>
    
    <item>
      <title>Create Table</title>
      <link>https://chrisalbon.com/postgresql/tables/create_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/create_table/</guid>
      <description> Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) </description>
    </item>
    
    <item>
      <title>Create Table With Default Values</title>
      <link>https://chrisalbon.com/postgresql/tables/create_table_with_default_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/create_table_with_default_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable with default value of &amp;#39;no weapon&amp;#39;  weapon varchar(255) DEFAULT &amp;#39;no weapon&amp;#39; ) Insert Row -- Insert rows into the table adventurers -- Notice we don&amp;#39;t provide value for weapon column INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;) Retrieve Rows -- Retrieve all rows from table SELECT * FROM adventurers nameageraceweapon Piperel Ramsay35Elfno weapon Casimir Yardley14Elfno weapon</description>
    </item>
    
    <item>
      <title>Create Table With UUIDs</title>
      <link>https://chrisalbon.com/postgresql/tables/create_table_with_uuids/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/create_table_with_uuids/</guid>
      <description>Install UUID Extension -- Install uuid extension CREATE EXTENSION IF NOT EXISTS &amp;#34;uuid-ossp&amp;#34; Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- uuid variable  adventurer_id uuid DEFAULT uuid_generate_v4(), -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255), -- Assign adventurer_id as primary key  PRIMARY KEY (adventurer_id) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) View Table -- Retrieve all rows in table SELECT * FROM adventurers adventurer_idnameageraceweapon 61bf9084-2fcc-40dd-bbec-08de205e7877Fjoak Doom-Wife28HumanAxe 495c81ca-a49d-4848-84bc-01bfa27916ccAlooneric Cortte29HumanBow 1533f42e-e64b-4aa2-8432-926defe3d248Piperel Ramsay35ElfBow 090420af-372c-43b8-9eda-763a76eb692fCasimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Create Temporary Table</title>
      <link>https://chrisalbon.com/postgresql/tables/create_temporary_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/create_temporary_table/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Create Temporary Table From Original Table -- Create a temporary table called adventurers_temp that.</description>
    </item>
    
    <item>
      <title>Create View</title>
      <link>https://chrisalbon.com/postgresql/basics/create_view/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/create_view/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Create View -- Create view called elves containing CREATE VIEW elves AS ( -- Select all rows from adventurers table  SELECT * FROM adventurers -- Where the race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) Retrieve View -- Retrieve all rows from the view Elf SELECT * FROM elves nameageraceweapon Piperel Ramsay35ElfBow Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Delete All Rows</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/delete_all_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/delete_all_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) View Table -- Retrieve all rows SELECT * FROM adventurers nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29HumanBow Piperel Ramsay35ElfBow Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Delete Duplicates</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/delete_duplicates/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/delete_duplicates/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) View Elves Table -- Retrieve all rows from the view Elf SELECT * FROM elves nameageracealive Dallar Woodfoot25ElfYes Cordin Garner29ElfYes Keat Knigh24ElfYes Keat Knigh24ElfYes Keat Knigh24ElfYes Keat Knigh24ElfYes Colbat Nalor124ElfYes</description>
    </item>
    
    <item>
      <title>Delete Primary Key</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/delete_primary_key/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/delete_primary_key/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- integer variable  adventurer_id INT, -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255), PRIMARY KEY (adventurer_id) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (adventurer_id, name, age, race, weapon) VALUES (1, &amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (2, &amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (3, &amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (4, &amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) View Table -- Retrieve all rows SELECT * FROM adventurers adventurer_idnameageraceweapon 1Fjoak Doom-Wife28HumanAxe 2Alooneric Cortte29HumanBow 3Piperel Ramsay35ElfBow 4Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Delete Rows</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/delete_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/delete_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) View Table -- Retrieve all rows SELECT * FROM adventurers nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29HumanBow Piperel Ramsay35ElfBow Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Delete Rows That Don&#39;t Exist In Another Table</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/delete_rows_that_dont_exist_in_another_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/delete_rows_that_dont_exist_in_another_table/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Create Table Of Alive -- Create table called alive CREATE TABLE alive ( -- string variable  name varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) Insert Rows Into Alive Table INSERT INTO alive (name) VALUES (&amp;#39;Keat Knigh&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;) Delete Rows In Elf Table That Don&amp;rsquo;t Exist In Alive Table -- Delete in elf table DELETE FROM elves -- Where the name in elves is not in the list of names in alive.</description>
    </item>
    
    <item>
      <title>Delete Table</title>
      <link>https://chrisalbon.com/postgresql/tables/delete_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/delete_table/</guid>
      <description> Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Delete Table -- Delete table DROP TABLE adventurers </description>
    </item>
    
    <item>
      <title>Delete Table With Views</title>
      <link>https://chrisalbon.com/postgresql/tables/delete_table_with_views/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/delete_table_with_views/</guid>
      <description> Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Create View -- Create view called elves containing CREATE VIEW elves AS ( -- Select all rows from adventurers table  SELECT * FROM adventurers -- Where the race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) Delete Table -- Delete table and dependent views DROP TABLE adventurers CASCADE </description>
    </item>
    
    <item>
      <title>Delete View</title>
      <link>https://chrisalbon.com/postgresql/basics/delete_view/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/delete_view/</guid>
      <description> Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Create View -- Create view called elves containing CREATE VIEW elves AS ( -- Select all rows from adventurers table  SELECT * FROM adventurers -- Where the race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) Delete View -- Delete View DROP VIEW elves </description>
    </item>
    
    <item>
      <title>Duplicate Table</title>
      <link>https://chrisalbon.com/postgresql/tables/duplicate_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/duplicate_table/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Row -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) View Table -- Retrieve rows from table SELECT * FROM warriors nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword Casimir Yardley14ElfMagic</description>
    </item>
    
    <item>
      <title>Examine A Query</title>
      <link>https://chrisalbon.com/postgresql/basics/examine_a_query/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/examine_a_query/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Row -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) View Table -- Retrieve rows from table SELECT * FROM adventurers nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword Casimir Yardley14ElfMagic</description>
    </item>
    
    <item>
      <title>Exit Terminal Session</title>
      <link>https://chrisalbon.com/linux/basics/exit_terminal_session/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/exit_terminal_session/</guid>
      <description> To close a terminal session we can use the exit command.
Exit Terminal exit logout Connection to 10.0.1.24 closed.  </description>
    </item>
    
    <item>
      <title>Export To CSV</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/export_to_csv/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/export_to_csv/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Export To CSV Note: Relative file paths are not allowed.</description>
    </item>
    
    <item>
      <title>Extract Characters From Strings</title>
      <link>https://chrisalbon.com/postgresql/text/extract_characters_from_strings/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/text/extract_characters_from_strings/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Extract Characters From Strings -- Extract the first two characters from the race column values SELECT name, age, SUBSTR(race, 1, 2) FROM adventurers nameagesubstr Fjoak Doom-Wife28Hu Alooneric Cortte29Hu Piperel Ramsay35El Casimir Yardley14El</description>
    </item>
    
    <item>
      <title>Find Directories</title>
      <link>https://chrisalbon.com/linux/search/find_directories/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_directories/</guid>
      <description>Make Files And Directories touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketing View Files And Directories ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 29 21:21 marketing -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 product.html drwxrwxr-x 2 chris chris 4096 Jul 29 21:21 sales -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 sales.</description>
    </item>
    
    <item>
      <title>Find Files</title>
      <link>https://chrisalbon.com/linux/search/find_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_files/</guid>
      <description>Make Files And Directories touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketing View Files And Directories ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 29 21:21 marketing -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 product.html drwxrwxr-x 2 chris chris 4096 Jul 29 21:21 sales -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 sales.</description>
    </item>
    
    <item>
      <title>Find Files Based On Multiple Conditions</title>
      <link>https://chrisalbon.com/linux/search/find_files_based_on_multiple_conditions/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_files_based_on_multiple_conditions/</guid>
      <description>Make Files And Directories touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketing View Files And Directories ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 marketing -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 product.html drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 sales -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 sales.</description>
    </item>
    
    <item>
      <title>Find Files By Filename</title>
      <link>https://chrisalbon.com/linux/search/find_files_by_filename/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_files_by_filename/</guid>
      <description>Make Files And Directories touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketing View Files And Directories ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 marketing -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 product.html drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 sales -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 sales.</description>
    </item>
    
    <item>
      <title>Find Files By Size</title>
      <link>https://chrisalbon.com/linux/search/find_files_by_size/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_files_by_size/</guid>
      <description>Make Files And Directories touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketing View Files And Directories ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 marketing -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 product.html drwxrwxr-x 2 chris chris 4096 Jul 31 09:02 sales -rw-rw-r-- 1 chris chris 0 Jul 31 09:02 sales.</description>
    </item>
    
    <item>
      <title>Find Program&#39;s Location</title>
      <link>https://chrisalbon.com/linux/search/find_programs_location/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_programs_location/</guid>
      <description>Use the which command to find the location of a program on the system. This is particularly useful when you are trying to figure out which version of Python is currently set in the environment.
Find Program&amp;rsquo;s Location which python3 /home/chris/anaconda3/bin/python3  Just to prove that this is true, we can change directory, cd, to that location and find the file itself.
Go To Program&amp;rsquo;s Location cd /home/chris/anaconda3/bin/ List Contents Of Directory The python* selection means we are only listing files starting with python.</description>
    </item>
    
    <item>
      <title>Find Symbolic Links</title>
      <link>https://chrisalbon.com/linux/search/find_symbolic_links/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/find_symbolic_links/</guid>
      <description>Make Files, Directories, And A Symbolic Link touch sales.txt, marketing.txt, data_science.csv, product.html; mkdir sales marketingln -nsf sales.txt marketing.txt View Files And Directories, And Symbolic Link ls -l total 8 -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 data_science.csv, drwxrwxr-x 2 chris chris 4096 Jul 29 21:21 marketing lrwxrwxrwx 1 chris chris 9 Jul 29 21:58 marketing.txt -&amp;gt; sales.txt -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 marketing.txt, -rw-rw-r-- 1 chris chris 0 Jul 29 21:21 product.</description>
    </item>
    
    <item>
      <title>Find Values In Both Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/find_values_in_both_tables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/find_values_in_both_tables/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Find All Unique Values In Both Tables -- Retrieve all weapons from elves SELECT weapon FROM elves -- Find the unique values that overlap with.</description>
    </item>
    
    <item>
      <title>Find Values In One Table And Not Another</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/find_values_in_one_table_and_not_another/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/find_values_in_one_table_and_not_another/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Find Unique Values In Elves That Aren&amp;rsquo;t In Dwarves -- Retrieve all weapons from elves SELECT weapon FROM elves -- Find the unique values that are not in.</description>
    </item>
    
    <item>
      <title>For Loops</title>
      <link>https://chrisalbon.com/linux/flow_control/for_loops/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/flow_control/for_loops/</guid>
      <description>Create For Loop In plain English: For each name in Lucien, Maurice, Renald, Johnson, and Alfred, print the name.
for name in Lucien Maurice Renald Johnson Alfred; do echo $namedone Lucien Maurice Renald Johnson Alfred  Create C Style For Loop Alternatively, we can use a style of for loop seen in the programming language C.
In plain English: Starting with i being 0, (i=0), as long as i is less than 10 (i&amp;lt;10), keep returning i, adding one to i (i=i+1) at the end of each loop.</description>
    </item>
    
    <item>
      <title>Get Help With A Command</title>
      <link>https://chrisalbon.com/linux/basics/get_help_with_a_command/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/get_help_with_a_command/</guid>
      <description>The --help argument is a common choice for quickly learning about a command. Particularly useful, --help shows the arguments for that particular command so we don&amp;rsquo;t have to look them up online.
Another option is the whatis command, which prints a one-line description of the command.
Quickly Describe A Command whatis mkdir mkdir (1) - make directories mkdir (2) - create a directory  Note that in this case there are two mkdir commands with slightly different descriptions, but you can ignore that.</description>
    </item>
    
    <item>
      <title>Get Information On A File</title>
      <link>https://chrisalbon.com/linux/basics/get_information_on_a_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/get_information_on_a_file/</guid>
      <description> Make File touch sales.txt Get Information On File stat sales.txt  File: sales.txt Size: 0 Blocks: 0 IO Block: 4096 regular empty file Device: 10302h/66306d	Inode: 9437404 Links: 1 Access: (0664/-rw-rw-r--) Uid: ( 1000/ chris) Gid: ( 1000/ chris) Access: 2018-07-31 13:07:05.244384050 -0700 Modify: 2018-07-31 13:07:05.244384050 -0700 Change: 2018-07-31 13:07:05.244384050 -0700 Birth: -  </description>
    </item>
    
    <item>
      <title>Group Rows</title>
      <link>https://chrisalbon.com/postgresql/basics/group_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/group_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Group Rows -- Retrieve the race and average age from the table SELECT race, AVG(age) FROM adventurers -- Grouped by race GROUP BY race, weapon -- Where the weapon of the adventurer is a bow HAVING weapon = &amp;#39;Bow&amp;#39; raceavg Elf14 Human29</description>
    </item>
    
    <item>
      <title>Group Rows With Conditions</title>
      <link>https://chrisalbon.com/postgresql/basics/group_rows_with_conditions/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/group_rows_with_conditions/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Group Rows -- Retrieve the race and average age from the table SELECT race, age, AVG(age) FROM adventurers -- Grouped by race GROUP BY race age -- That are older than 20 HAVING age &amp;gt; 20 raceavg Elf24.</description>
    </item>
    
    <item>
      <title>If Else</title>
      <link>https://chrisalbon.com/postgresql/basics/if_else/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/if_else/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create An If Else Statement There are a number of ways to do if-else in SQL, my prefered way is the CASE statement.</description>
    </item>
    
    <item>
      <title>If Else For Integers</title>
      <link>https://chrisalbon.com/linux/flow_control/if_else_for_integers/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/flow_control/if_else_for_integers/</guid>
      <description> Create Variable age=23 Create If Else Statement The code below in plain English: If the variable age is greater than 17, then return &amp;ldquo;Adult&amp;rdquo; otherwise return &amp;ldquo;Child&amp;rdquo;.
if (( &amp;#34;$age&amp;#34;&amp;gt; 17 )); then  echo &amp;#34;Adult&amp;#34;else echo &amp;#34;Child&amp;#34;fi Adult  </description>
    </item>
    
    <item>
      <title>If Else For Strings</title>
      <link>https://chrisalbon.com/linux/flow_control/if_else_for_strings/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/flow_control/if_else_for_strings/</guid>
      <description> While you can often use [[ ]] for integers, (( )) is specifically designed to work with integers and provides a lot more functionality.
Create Variable name=&amp;#34;Ralph Holmes&amp;#34; Create If Else Statement if [[ &amp;#34;$name&amp;#34; == &amp;#34;Ralph Holmes&amp;#34; ]]; then echo &amp;#34;It is Ralph.&amp;#34;else echo &amp;#34;It is not Ralph&amp;#34;fi It is Ralph.  </description>
    </item>
    
    <item>
      <title>If Else With Multiple Conditions</title>
      <link>https://chrisalbon.com/linux/flow_control/if_else_with_multiple_conditions/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/flow_control/if_else_with_multiple_conditions/</guid>
      <description>Create Variable age=23 Check Greater Than 17 And Less Than 30 To combine conditional tests with &amp;ldquo;and&amp;rdquo; use &amp;amp;&amp;amp;.
if (( &amp;#34;$age&amp;#34;&amp;gt; 17 &amp;amp;&amp;amp; &amp;#34;$age&amp;#34; &amp;lt; 30 )); then  echo &amp;#34;Greater than 17 and less than 30&amp;#34;else echo &amp;#34;Not greater than 17 and less than 30&amp;#34;fi Greater than 17 and less than 30  Check Greater Than 17 Or Less Than 20 To combine conditional tests with &amp;ldquo;or&amp;rdquo; use ||.</description>
    </item>
    
    <item>
      <title>Import CSV</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/import_csv/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/import_csv/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Export To CSV -- Export the adventurers table to that file path and -- name using the comma delimiter and with column headings COPY adventurers TO &amp;#39;/Users/chrisalbon/example_file.</description>
    </item>
    
    <item>
      <title>Inner Join Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/inner_join/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/inner_join/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Adventurer&amp;rsquo;s Equipment -- Create table called equipment CREATE TABLE equipment ( -- string variable  name varchar(255), -- string variable  clothes varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Dwarf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Dwarf&amp;#39;) Insert Rows Into Equipment Table INSERT INTO equipment (name, clothes, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather Armor&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Robe&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, &amp;#39;Tunic&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;,&amp;#39;Chainmail&amp;#39;, &amp;#39;Axe&amp;#39;) Inner Join Tables -- Return the name of people from the adventurers table, age, race, clothes, and weapon SELECT adventurers.</description>
    </item>
    
    <item>
      <title>Insert Rows</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/insert_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/insert_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Row -- Insert row into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;) Retrieve Rows -- Retrieve all rows from table SELECT * FROM adventurers nameageraceweapon Fjoak Doom-Wife28HumanAxe</description>
    </item>
    
    <item>
      <title>Join And Sort Text</title>
      <link>https://chrisalbon.com/linux/text/join_and_sort_text/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/join_and_sort_text/</guid>
      <description> Make Three Files, Each With List Of Fruit echo &amp;#34;Apple&amp;#34; &amp;gt;&amp;gt; fruit_1.txt; echo &amp;#34;Banana&amp;#34; &amp;gt;&amp;gt; fruit_1.txt; echo &amp;#34;Orange&amp;#34; &amp;gt;&amp;gt; fruit_1.txtecho &amp;#34;Tangerine&amp;#34; &amp;gt;&amp;gt; fruit_2.txt; echo &amp;#34;Grape&amp;#34; &amp;gt;&amp;gt; fruit_2.txt; echo &amp;#34;Nectarine&amp;#34; &amp;gt;&amp;gt; fruit_2.txtecho &amp;#34;Strawberry&amp;#34; &amp;gt;&amp;gt; fruit_3.txt; echo &amp;#34;Blueberry&amp;#34; &amp;gt;&amp;gt; fruit_3.txt; echo &amp;#34;Mango&amp;#34; &amp;gt;&amp;gt; fruit_3.txt Merge And Sort Into New File sort fruit_1.txt fruit_2.txt fruit_3.txt &amp;gt; fruit.txt View Contents Of New File cat fruit.txt Apple Banana Blueberry Grape Mango Nectarine Orange Strawberry Tangerine  </description>
    </item>
    
    <item>
      <title>Join Columns</title>
      <link>https://chrisalbon.com/linux/text/join_columns/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/join_columns/</guid>
      <description>The Linux command join operates similar to the join command in SQL, merging two sets of data along a common key.
Make File With Soldier Names And Soldier Age Data echo &amp;#34;Steve Case, 23&amp;#34; &amp;gt;&amp;gt; soldiers.txtecho &amp;#34;Mary Mills, 35&amp;#34; &amp;gt;&amp;gt; soldiers.txtecho &amp;#34;Bob Dosjki, 22&amp;#34; &amp;gt;&amp;gt; soldiers.txtecho &amp;#34;Jack Doi, 45&amp;#34; &amp;gt;&amp;gt; soldiers.txtecho &amp;#34;Poe Domi, 23&amp;#34; &amp;gt;&amp;gt; soldiers.txt Make File With Soldier Names And Regiment Names echo &amp;#34;Steve Case, The Hell Hosts&amp;#34; &amp;gt;&amp;gt; regiments.</description>
    </item>
    
    <item>
      <title>Join Multiple Table</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/join_multiple_tables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/join_multiple_tables/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Weapons -- Create table called weapons CREATE TABLE weapons ( -- string variable  name varchar(255), -- string variable  weapon varchar(255), -- integer variable  weight int ) Create Table Of Armor -- Create table called armor CREATE TABLE armor ( -- string variable  name varchar(255), -- string variable  body varchar(255), -- string variable  helm varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;) Insert Rows Into Weapon Table INSERT INTO weapons (name, weapon, weight) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;,&amp;#39;Axe&amp;#39;, 2), (&amp;#39;Cordin Garner&amp;#39;, &amp;#39;Halberd&amp;#39;, 3), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Dagger&amp;#39;, 4), (&amp;#39;Colbat Nalor&amp;#39;, &amp;#39;Dagger&amp;#39;, 5) Insert Rows Into Armor Table INSERT INTO armor (name, body, helm) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather&amp;#39;, &amp;#39;Leather&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, &amp;#39;Leather&amp;#39;, NULL), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Plate&amp;#39;, &amp;#39;Plate&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, &amp;#39;Plate&amp;#39;, &amp;#39;Plate&amp;#39;) Join All Tables -- All rows from table SELECT elves.</description>
    </item>
    
    <item>
      <title>Left Join Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/left_join/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/left_join/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Adventurer&amp;rsquo;s Equipment -- Create table called equipment CREATE TABLE equipment ( -- string variable  name varchar(255), -- string variable  clothes varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Dwarf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Dwarf&amp;#39;) Insert Rows Into Equipment Table INSERT INTO equipment (name, clothes, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather Armor&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Robe&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Tasar Keynelis&amp;#39;, &amp;#39;Tunic&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Sataleeti Iarroris&amp;#39;,&amp;#39;Chainmail&amp;#39;, &amp;#39;Axe&amp;#39;) Left Join Tables -- Return the name of people from the adventurers table, age, race, clothes, and weapon SELECT adventurers.</description>
    </item>
    
    <item>
      <title>List Avaliable Commands</title>
      <link>https://chrisalbon.com/linux/basics/list_avaliable_commands/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/list_avaliable_commands/</guid>
      <description>We can see all avaliable commands for a system by listing the contents of the bin directory using ls /bin
Show All Avaliable Commands ls /bin bash cp fgrep loadkeys netcat open setupcon unicode_start bunzip2 cpio findmnt login netstat openvt sh vdir busybox dash fuser loginctl nisdomainname pidof sh.distrib which bzcat date fusermount lowntfs-3g ntfs-3g ping sleep whiptail bzcmp dbus-cleanup-sockets grep ls ntfs-3g.probe ping6 ss ypdomainname bzdiff dbus-daemon gunzip lsblk ntfs-3g.</description>
    </item>
    
    <item>
      <title>List Buckets</title>
      <link>https://chrisalbon.com/aws/s3/cli/list_buckets/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/aws/s3/cli/list_buckets/</guid>
      <description> Create First Bucket Make a bucket (mb) on AWS S3 called kicks-pasta-steer. The bucket name you choose must be globally unique, meaning nobody else in the world must have used that bucket name before.
aws s3 mb s3://kicks-pasta-steer make_bucket: kicks-pasta-steer  Create Second Bucket aws s3 mb s3://assume-laser-rental make_bucket: assume-laser-rental  List All Buckets aws s3 ls 2018-09-23 18:48:46 assume-laser-rental 2018-09-23 18:36:23 kicks-pasta-steer  </description>
    </item>
    
    <item>
      <title>List Columns In Table</title>
      <link>https://chrisalbon.com/postgresql/tables/list_columns_in_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/list_columns_in_table/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) View Columns Rows In Elf Table -- Get name, data ype and column position SELECT column_name, data_type, ordinal_position -- From the column&amp;#39;s metadata FROM information_schema.</description>
    </item>
    
    <item>
      <title>List Index Columns</title>
      <link>https://chrisalbon.com/postgresql/basics/list_indexed_columns/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/list_indexed_columns/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) Create Index -- Index the names column in the elves table CREATE INDEX ON elves (name) View All Indexes In Database SELECT indexes.</description>
    </item>
    
    <item>
      <title>List Processes</title>
      <link>https://chrisalbon.com/linux/processes/list_processes/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/processes/list_processes/</guid>
      <description>List Processes We are often interested in the STAT column: - R - process is running - S - process is sleeping - D - process is in uninterruptible sleep - T - process is terminated - D - process is dead - &amp;lt; - process is high priority - N - process is low priority
Note that normally the list of processes is very long, so for the sake of this tutorial we included | head which will show only the first few processes.</description>
    </item>
    
    <item>
      <title>List Tables In Database</title>
      <link>https://chrisalbon.com/postgresql/basics/list_tables_in_database/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/list_tables_in_database/</guid>
      <description>Create Table -- Create table called villains CREATE TABLE villains ( -- string variable  name varchar(255) ) Create Table -- Create table called heroes CREATE TABLE heroes ( -- string variable  name varchar(255) ) Create Table -- Create table called battles CREATE TABLE battles ( -- string variable  name varchar(255) ) List Tables In Database SELECT table_name FROM information_schema.tables WHERE table_schema = &amp;#39;public&amp;#39; AND table_type = &amp;#39;BASE TABLE&amp;#39; table_name battles heroes villians</description>
    </item>
    
    <item>
      <title>List The Contents Of A Directory</title>
      <link>https://chrisalbon.com/linux/basics/list_contents_of_a_directory/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/list_contents_of_a_directory/</guid>
      <description>ls is one of the most useful commands when using the Linux command line. ls lists the contents of the directory.
List Contents Of Directory ls bin compiler_compat conda-meta doc etc include lib libexec LICENSE.txt mkspecs phrasebooks pkgs plugins qml share ssl translations var x86_64-conda_cos6-linux-gnu  List Contents Of Directory In Detail Note that the first column contains the file&amp;rsquo;s permission setting, which are structured as:
 Character 1: Type Of File (d means directory) Characters 2-4: Access Rights For File&amp;rsquo;s Owner Characters 5-7: Access Rights For File&amp;rsquo;s Group Characters 7-9: Access Rights For Everyone  ls -l total 188 drwxrwxr-x 2 chris chris 12288 Oct 11 2017 bin drwxrwxr-x 2 chris chris 4096 Oct 11 2017 compiler_compat drwxrwxr-x 2 chris chris 20480 Oct 11 2017 conda-meta drwxrwxr-x 3 chris chris 4096 Oct 11 2017 doc drwxrwxr-x 7 chris chris 4096 Oct 11 2017 etc drwxrwxr-x 31 chris chris 12288 Oct 11 2017 include drwxrwxr-x 22 chris chris 36864 Oct 11 2017 lib drwxrwxr-x 4 chris chris 4096 Oct 11 2017 libexec -rw-r--r-- 1 chris chris 5350 Sep 24 2017 LICENSE.</description>
    </item>
    
    <item>
      <title>Lower And Upper Case</title>
      <link>https://chrisalbon.com/postgresql/text/lower_case_and_upper_case/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/text/lower_case_and_upper_case/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Upper Case String Values -- Upper case the values in the race column SELECT UPPER(race) FROM adventurers upper HUMAN HUMAN ELF ELF</description>
    </item>
    
    <item>
      <title>Mathematical Operations On Columns</title>
      <link>https://chrisalbon.com/postgresql/numeric/mathematical_operations_on_column/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/numeric/mathematical_operations_on_column/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;) Apply Addition To Column -- Apply operation UPDATE adventurers SET age = age + 10 View Table -- Retrieve data SELECT * FROM adventurers nameagerace Fjoak Doom-Wife38Human Alooneric Cortte39Elf Piperel Ramsay45Elf Casimir Yardley24Elf</description>
    </item>
    
    <item>
      <title>Monitor Processes</title>
      <link>https://chrisalbon.com/linux/processes/monitor_processes/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/processes/monitor_processes/</guid>
      <description>Monitor Processes top shows a live list of all processes with information about them. One piece of information that is often useful is us, which shows what percentage of the CPU is being used by user processes (e.g. a script training a neural network). Similarly, id tells us the percentage of the CPI that is idle.
top top - 13:34:55 up 5:51, 2 users, load average: 0.13, 0.10, 0.02 Tasks: 332 total, 1 running, 230 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.</description>
    </item>
    
    <item>
      <title>Multiple Commands On One Line</title>
      <link>https://chrisalbon.com/linux/basics/multiple_commands_on_one_line/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/multiple_commands_on_one_line/</guid>
      <description> You can have multiple commands in one line as long as they are separated with the ; symbol.
Note that this is not a very widely used feature &amp;ndash; but it is seen.
Make A Subdirectory, Make A File, View Directory Contents mkdir example_directory; touch example_file.txt; ls -l total 4 drwxrwxr-x 2 chris chris 4096 Jul 25 16:31 example_directory -rw-rw-r-- 1 chris chris 0 Jul 25 16:31 example_file.txt  </description>
    </item>
    
    <item>
      <title>Outer Join Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/outer_join/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/outer_join/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Adventurer&amp;rsquo;s Equipment -- Create table called equipment CREATE TABLE equipment ( -- string variable  name varchar(255), -- string variable  clothes varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Dwarf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Dwarf&amp;#39;) Insert Rows Into Equipment Table INSERT INTO equipment (name, clothes, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather Armor&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Robe&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Tasar Keynelis&amp;#39;, &amp;#39;Tunic&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Sataleeti Iarroris&amp;#39;,&amp;#39;Chainmail&amp;#39;, &amp;#39;Axe&amp;#39;) Outer Join Tables -- Return the name of people from the adventurers table, age, race, clothes, and weapon SELECT adventurers.</description>
    </item>
    
    <item>
      <title>Partial String Match</title>
      <link>https://chrisalbon.com/postgresql/text/partial_string_match/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/text/partial_string_match/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Rows %o% indicates we are matching any string that contains an o.</description>
    </item>
    
    <item>
      <title>Ping Website</title>
      <link>https://chrisalbon.com/linux/basics/ping_website/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/ping_website/</guid>
      <description>Linux makes it easy to ping a website to test connectivity and/or whether the website is live. Once executed, ping will ping the website until it is stopped by pressing ctrl-C.
Ping Google.com ping google.com PING google.com (172.217.4.174) 56(84) bytes of data. 64 bytes from lax28s01-in-f174.1e100.net (172.217.4.174): icmp_seq=1 ttl=56 time=41.8 ms 64 bytes from lax28s01-in-f174.1e100.net (172.217.4.174): icmp_seq=2 ttl=56 time=35.7 ms 64 bytes from lax28s01-in-f174.1e100.net (172.217.4.174): icmp_seq=3 ttl=56 time=43.6 ms 64 bytes from lax28s01-in-f174.</description>
    </item>
    
    <item>
      <title>Quickly View File Contents</title>
      <link>https://chrisalbon.com/linux/text/quickly_view_file_contents/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/text/quickly_view_file_contents/</guid>
      <description>Often we want to quickly take a peek at a file&amp;rsquo;s contents without opening the file in an editor program. The cat command makes this easy.
Create A Text File With Some Contents echo &amp;#39;Here is some text content inside of the file.&amp;#39; &amp;gt; example_file.txt View Contents Of Text File cat example_file.txt Here is some text content inside of the file.  View Contents Of Text File With Line Numbers cat -n example_file.</description>
    </item>
    
    <item>
      <title>Rename Columns In Views</title>
      <link>https://chrisalbon.com/postgresql/basics/rename_columns_in_views/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/rename_columns_in_views/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;) Create View -- Create view called elves containing with the column&amp;#39;s renamed: -- elven_name, elven_age, race, and elven_weapon CREATE VIEW elves (elven_name, elven_age, race, elven_weapon) AS ( -- Select all rows from adventurers table  SELECT * FROM adventurers -- Where the race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) Retrieve View -- Retrieve all rows from the view Elf SELECT * FROM elves elven_nameelven_ageraceelven_weapon Piperel Ramsay35ElfBow Casimir Yardley14ElfBow</description>
    </item>
    
    <item>
      <title>Replace Missing Values</title>
      <link>https://chrisalbon.com/postgresql/basics/replace_missing_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/replace_missing_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows With Missing Values -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, NULL), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, NULL) Retrieve Missing Values In SQL, missing values are denoted as NULL.</description>
    </item>
    
    <item>
      <title>Retrieve Only A Few Rows</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_only_a_few_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_only_a_few_rows/</guid>
      <description>Note: This code works in PostgreSQL databases, but might not work in other SQL database systems (e.g. MySQL).
Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Only Two Rows -- Retrieve rows from table SELECT * FROM adventurers -- Limited to two rows  LIMIT 2 nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow</description>
    </item>
    
    <item>
      <title>Retrieve Random Subset Of Rows</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_random_subset_of_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_random_subset_of_rows/</guid>
      <description>Note: This code works in PostgreSQL databases, but might not work in other SQL database systems (e.g. MySQL).
Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Only Two Rows -- Retrieve rows from table SELECT * FROM adventurers -- Shuffle randomly  ORDER BY RANDOM() -- Retrieve two rows  LIMIT 2 &amp;lt;!</description>
    </item>
    
    <item>
      <title>Retrieve Row</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Rows -- Retrieve all rows from table SELECT * FROM adventurers nameageraceweapon Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword Casimir Yardley14ElfMagic</description>
    </item>
    
    <item>
      <title>Retrieve Rows Based On Condition</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_rows_based_on_condition/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_rows_based_on_condition/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Rows Of Elves -- Retrieve all rows from table SELECT * FROM adventurers -- Where the race is Elf  WHERE race = &amp;#39;Elf&amp;#39; nameageraceweapon Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword Casimir Yardley14ElfMagic</description>
    </item>
    
    <item>
      <title>Retrieve Rows Based On Multiple Condition</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_rows_based_on_multiple_conditions/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_rows_based_on_multiple_conditions/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Rows Of Elven Swords Wielders -- Retrieve all rows from table SELECT * FROM adventurers -- Where the race is Elf  WHERE race = &amp;#39;Elf&amp;#39; -- weapon is sword  AND weapon = &amp;#39;Sword&amp;#39; nameageraceweapon Piperel Ramsay35ElfSword</description>
    </item>
    
    <item>
      <title>Retrieve Subset Of Columns</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_subset_columns/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_subset_columns/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Two Columns -- Retrieve name and age columns SELECT name, age FROM adventurers nameage Fjoak Doom-Wife28 Alooneric Cortte29 Piperel Ramsay35 Casimir Yardley14</description>
    </item>
    
    <item>
      <title>Retrieving Missing Values</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieving_missing_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieving_missing_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows With Missing Values -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, NULL), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, NULL) Retrieve Missing Values In SQL, missing values are denoted as NULL.</description>
    </item>
    
    <item>
      <title>Right Join Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/right_join/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/right_join/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Create Table Of Adventurer&amp;rsquo;s Equipment -- Create table called equipment CREATE TABLE equipment ( -- string variable  name varchar(255), -- string variable  clothes varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Dwarf&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Dwarf&amp;#39;) Insert Rows Into Equipment Table INSERT INTO equipment (name, clothes, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, &amp;#39;Leather Armor&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, &amp;#39;Robe&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Tasar Keynelis&amp;#39;, &amp;#39;Tunic&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Sataleeti Iarroris&amp;#39;,&amp;#39;Chainmail&amp;#39;, &amp;#39;Axe&amp;#39;) Right Join Tables -- Return the name of people from the adventurers table, age, race, clothes, and weapon SELECT adventurers.</description>
    </item>
    
    <item>
      <title>Save Output To File In Middle Of Command Chain</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/save_output_to_file_in_middle_of_command_chain/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/save_output_to_file_in_middle_of_command_chain/</guid>
      <description>The tee command creates a T-junction in a command pipeline, both saving the standard output of the previous command to a file and passing the standard output onward down the pipeline. It is often useful when we want to see the data at intermediate steps in a command pipeline without interrupting it.
Create Example File With List Of File Names echo &amp;#39;data_science.txt&amp;#39; &amp;gt;&amp;gt; files.txtecho &amp;#39;data_science.html&amp;#39; &amp;gt;&amp;gt; files.txtecho &amp;#39;data_science.csv&amp;#39; &amp;gt;&amp;gt; files.</description>
    </item>
    
    <item>
      <title>Save Queries As Variables</title>
      <link>https://chrisalbon.com/postgresql/basics/save_queries_as_variables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/save_queries_as_variables/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Create Two Subqueries, Save As Variables, Use In Another Query Note that there are better ways to run this particular query.</description>
    </item>
    
    <item>
      <title>Search Contents Of All Files Of Certain Type</title>
      <link>https://chrisalbon.com/linux/search/search_contents_of_all_files_of_certain_type/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/search_contents_of_all_files_of_certain_type/</guid>
      <description>Note: In this tutorial we do not generate the files we will search but rather search the contents of this site&amp;rsquo;s directory structure.
Recursively Search All Markdown For The Word &amp;ldquo;berry&amp;rdquo;  grep search command -n to display line number of matched pattern -i to make search case insensitive -r to search recursively --color to color the matches so they stand out --include=&#39;*.md&#39; to search only in files ending in .</description>
    </item>
    
    <item>
      <title>Search Filenames</title>
      <link>https://chrisalbon.com/linux/search/search_file_names/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/search_file_names/</guid>
      <description>Often we want to find a file on our system. The locate command offers a quick method for searching for all files in the system containing a string. In our example, we look for all files with bashrc in the name.
Search Filenames In System locate bashrc /etc/bash.bashrc /etc/skel/.bashrc /home/chris/.bashrc /home/chris/.bashrc-anaconda3.bak /home/chris/anaconda3/lib/python3.6/site-packages/pexpect/bashrc.sh /home/chris/anaconda3/pkgs/pexpect-4.2.1-py36h3b9d41b_0/lib/python3.6/site-packages/pexpect/bashrc.sh /usr/share/base-files/dot.bashrc /usr/share/doc/adduser/examples/adduser.local.conf.examples/bash.bashrc /usr/share/doc/adduser/examples/adduser.local.conf.examples/skel/dot.bashrc  Note that locate might not find recently created files. This is because the database of filenames locate uses is only generated periodically.</description>
    </item>
    
    <item>
      <title>Search The Contents Of A File</title>
      <link>https://chrisalbon.com/linux/search/search_contents_of_a_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/search/search_contents_of_a_file/</guid>
      <description> Make File With Some Content echo &amp;#34;There were 24 sales in March.&amp;#34; &amp;gt;&amp;gt; sales.txtecho &amp;#34;We have 90 employees.&amp;#34; &amp;gt;&amp;gt; employees.txt Search The File For Some String grep March sales.txt There were 24 sales in March.  Search The File For Some String, Return With Line Numbers grep -n March sales.txt 1:There were 24 sales in March.  Get Filenames That Match Search grep -l March sales.txt sales.txt  </description>
    </item>
    
    <item>
      <title>See Free Memory</title>
      <link>https://chrisalbon.com/linux/basics/see_free_memory/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/see_free_memory/</guid>
      <description>The best way to check the amount of free memory in a Linux system is to use the free command. This command lists the amount of free memory.
Check System&amp;rsquo;s Free Memory free  total used free shared buff/cache available Mem: 65908812 244948 64239140 206180 1424724 64672848 Swap: 50226172 0 50226172  Check System&amp;rsquo;s Free Memory In A More Human Readable Format free -h  total used free shared buff/cache available Mem: 62G 239M 61G 209M 1.</description>
    </item>
    
    <item>
      <title>See Who Is Logged Into A System</title>
      <link>https://chrisalbon.com/linux/basics/see_who_is_logged_in/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/see_who_is_logged_in/</guid>
      <description>We can check who is logged into the system using the who command.
Check Logged In Users who ubuntu pts/0 2018-07-17 09:55 (ip68-3-23-73.ph.ph.box.net)  This shows one user is logged into the system with the username ubuntu.</description>
    </item>
    
    <item>
      <title>Select Files Based On Filename</title>
      <link>https://chrisalbon.com/linux/basics/select_files_based_on_filename/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/select_files_based_on_filename/</guid>
      <description>Often we want to select files based on their file name or file extension. In Linux, we can use wildcard characters to accomplish this.
Create Some Files touch hello_world.txttouch HELLO_world.txttouch HELLO_world.mdtouch hello_america.txttouch goodbye_america.txttouch goodbye_america_2.txt View Directory Contents ls goodbye_america_2.txt goodbye_america.txt hello_america.txt hello_world.txt HELLO_world.txt  Select Files Containing &amp;ldquo;Hello&amp;rdquo; ls hello* hello_america.txt hello_world.txt  Select Files Starting With &amp;ldquo;g&amp;rdquo; or &amp;ldquo;i&amp;rdquo; ls [gi]* goodbye_america_2.txt goodbye_america.txt  Select All Markdown Files ls *.</description>
    </item>
    
    <item>
      <title>Select Highest Value In Each Group</title>
      <link>https://chrisalbon.com/postgresql/basics/select_highest_value_in_each_group/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/select_highest_value_in_each_group/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;) Select The Oldest Adventurer In Each Race -- Get the name, race, age of the first row in each group, -- when grouped by race SELECT DISTINCT ON (race) name, race, age FROM adventurers -- Order by race, then age, in descending order -- (so the oldest person is the top of each group) ORDER BY race, age DESC nameraceage Piperel RamsayElf35 Alooneric CortteHuman29</description>
    </item>
    
    <item>
      <title>Select Values Between Two Values</title>
      <link>https://chrisalbon.com/postgresql/basics/select_values_between_two_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/select_values_between_two_values/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Human&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;) Get Values Between Two Values, Method 1 -- Get all rows from adventurers SELECT * FROM adventurers -- Where age is between 20 and 30 WHERE age BETWEEN 20 AND 30 nameagerace Fjoak Doom-Wife28Human Alooneric Cortte29Human</description>
    </item>
    
    <item>
      <title>Self Join Table</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/self_join/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/self_join/</guid>
      <description>Create Table Of Adventurers -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  child_of varchar(255) ) Insert Rows Into Adventurers Table INSERT INTO adventurers (name, age, child_of) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, NULL), (&amp;#39;Cordin Garner&amp;#39;, 29, NULL), (&amp;#39;Keat Garner&amp;#39;, 24, &amp;#39;Cordin Garner&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, NULL) Inner Join Tables -- Select name of copy1 and name of copy2 (renamed &amp;#34;parent&amp;#34;) SELECT copy1.</description>
    </item>
    
    <item>
      <title>Show Column Information</title>
      <link>https://chrisalbon.com/postgresql/tables/show_column_information/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/show_column_information/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Show Column Information -- Select column name, data type, and max character limit SELECT column_name, data_type, character_maximum_length -- From the database&amp;#39;s schema FROM INFORMATION_SCHEMA.</description>
    </item>
    
    <item>
      <title>Silence Errors</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/silence_errors/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/silence_errors/</guid>
      <description>The most common method of silencing an error in Linux is to redirect than error to /dev/null which is like the trash bucket of the system. We can do that by including 2&amp;gt; /dev/null to the end of a command.
Create Code That Will Produce Error ls a_fake_directory/ ls: a_fake_directory/: No such file or directory  Silence Error Notice that we aren&amp;rsquo;t silencing so much as redirecting into /dev/null. This is like sending the error into a black hole.</description>
    </item>
    
    <item>
      <title>Sort Rows</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/sort_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/sort_rows/</guid>
      <description>The sort command reorganizes lines in a text file or standard output (technically the same thing) so they are arranged numerically and alphabetically.
Create Example File With List Of Names echo &amp;#39;Luca Gartside&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Reule Smyth&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Crurnirk Steelflow&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Uli Pinetotem&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Lai Zhi Lightdream&amp;#39; &amp;gt;&amp;gt; adventurers.txt View File cat adventurers.txt Luca Gartside Reule Smyth Spencer Smit Crurnirk Steelflow Uli Pinetotem Lai Zhi Lightdream  Sort List Of Names And Write To New File sort adventurers.</description>
    </item>
    
    <item>
      <title>Sort Rows</title>
      <link>https://chrisalbon.com/postgresql/basics/sort_rows/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/sort_rows/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Sort Rows By One Column -- Retrieve rows SELECT * FROM adventurers -- Order rows by age in ascending order ORDER BY age ASC nameageraceweapon Casimir Yardley14ElfMagic Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword</description>
    </item>
    
    <item>
      <title>Sort Rows In Groups</title>
      <link>https://chrisalbon.com/postgresql/basics/sort_rows_in_groups/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/sort_rows_in_groups/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Sort Rows By One Column -- Retrieve rows SELECT * FROM adventurers -- Order rows by age in ascending order ORDER BY age ASC nameageraceweapon Casimir Yardley14ElfMagic Fjoak Doom-Wife28HumanAxe Alooneric Cortte29ElfBow Piperel Ramsay35ElfSword</description>
    </item>
    
    <item>
      <title>Stack Tables</title>
      <link>https://chrisalbon.com/postgresql/merging_and_joining/stack_tables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/merging_and_joining/stack_tables/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Create Table Of Dwarves -- Create table called dwarves CREATE TABLE dwarves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, weapon) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Insert Rows Into Dwarf Table INSERT INTO dwarves (name, age, race, weapon) VALUES (&amp;#39;Kalog&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dranar&amp;#39;, 145, &amp;#39;Dwarf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Bratar&amp;#39;, 12, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Dragga&amp;#39;, 23, &amp;#39;Dwarf&amp;#39;, &amp;#39;Axe&amp;#39;) Stack Tables On Top Of Eachother -- All rows from elf table SELECT * FROM elves -- Stack on top of.</description>
    </item>
    
    <item>
      <title>Synchronize Files And Directories</title>
      <link>https://chrisalbon.com/linux/basics/synchronize_files_and_directories/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/synchronize_files_and_directories/</guid>
      <description>rsync is a very handy tool for syncing the files and folders in two directories. rsync only copies files that have changed since the time they were sync&amp;rsquo;d.
Make Two Directories mkdir origin destination Add Files In Origin Directory touch origin/file.txt View Origin Directory Contents ls -l origin total 0 -rw-rw-r-- 1 chris chris 0 Jul 31 20:04 file.txt  View Destination Directory Contents ls -l destination total 0  Sync Origin Directory To Destination Directory In this code we sync (rsync) all the files and subdirectories (-a) in origin to destination while printing out details of the process (v), deleting (--delete) any files in destination that no longer exist in origin.</description>
    </item>
    
    <item>
      <title>Test If Rows Exist In Subquery</title>
      <link>https://chrisalbon.com/postgresql/basics/test_if_rows_exist_in_subquery/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/test_if_rows_exist_in_subquery/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Test If Rows Exist In Subquery -- Retrieve all the rows in adventurers SELECT * FROM adventurers -- Where rows exist in WHERE EXISTS -- A subquery that will ( -- Select all the names in adventurers  SELECT name FROM adventurers -- Where race is elf  WHERE race = &amp;#39;Elf&amp;#39; ) nameagerace Fjoak Doom-Wife28Human Alooneric Cortte29Elf Piperel Ramsay35Elf Casimir Yardley14Elf</description>
    </item>
    
    <item>
      <title>Track Route Of Network Traffic</title>
      <link>https://chrisalbon.com/linux/basics/track_route_of_network_traffic/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/track_route_of_network_traffic/</guid>
      <description>Trace Route From Local Computer To Website traceroute shows the path of our network traffic across the internet. Press ctrl-C to cancel.
traceroute google.com traceroute to google.com (216.58.219.14), 30 hops max, 60 byte packets 1 10.0.1.1 (10.0.1.1) 0.920 ms 1.742 ms 2.294 ms 2 10.33.236.1 (10.33.236.1) 10.222 ms 14.140 ms 14.381 ms 3 72.215.229.12 (72.215.229.12) 18.079 ms 18.182 ms 18.423 ms 4 bellcorc02-te-0-0-0-5.ph.ph.cox.net (70.169.72.188) 20.697 ms 20.938 ms 24.585 ms 5 68.</description>
    </item>
    
    <item>
      <title>Update Rows Based On Another Table</title>
      <link>https://chrisalbon.com/postgresql/add_delete_change/update_rows_based_on_another_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/add_delete_change/update_rows_based_on_another_table/</guid>
      <description>Create Table Of Elves -- Create table called elves CREATE TABLE elves ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  alive varchar(255) ) Create Table Of Deaths -- Create table called deaths CREATE TABLE deaths ( -- string variable  name varchar(255) ) Insert Rows Into Elf Table INSERT INTO elves (name, age, race, alive) VALUES (&amp;#39;Dallar Woodfoot&amp;#39;, 25, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Cordin Garner&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Keat Knigh&amp;#39;, 24, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;, 124, &amp;#39;Elf&amp;#39;, &amp;#39;Yes&amp;#39;) Insert Rows Into Deaths Table INSERT INTO deaths (name) VALUES (&amp;#39;Keat Knigh&amp;#39;), (&amp;#39;Colbat Nalor&amp;#39;) View Elves Table -- Retrieve all rows from the view Elf SELECT * FROM elves nameageracealive Dallar Woodfoot25ElfYes Cordin Garner29ElfYes Keat Knigh24ElfYes Colbat Nalor124ElfYes</description>
    </item>
    
    <item>
      <title>Use Column Aliases With Where Clause</title>
      <link>https://chrisalbon.com/postgresql/basics/use_column_aliases_with_where_clause/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/use_column_aliases_with_where_clause/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Two Columns The trick is to wrap the column aliasing in paratheses.</description>
    </item>
    
    <item>
      <title>Value Matches Element Of A List</title>
      <link>https://chrisalbon.com/postgresql/basics/retrieve_rows_where_value_matches_element_of_list/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/retrieve_rows_where_value_matches_element_of_list/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) Retrieve Rows -- Retrieve all rows from table SELECT * FROM adventurers -- Where the value of weapon is in a list of weapons WHERE weapon IN (&amp;#39;Polearm&amp;#39;, &amp;#39;Whip&amp;#39;, &amp;#39;Staff&amp;#39;, &amp;#39;Dagger&amp;#39;, &amp;#39;Bow&amp;#39;) nameageraceweapon Alooneric Cortte29ElfBow</description>
    </item>
    
    <item>
      <title>View A File&#39;s Type</title>
      <link>https://chrisalbon.com/linux/basics/view_file_type/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/view_file_type/</guid>
      <description> The file command allows us to view a file&amp;rsquo;s type.
Make File echo &amp;#34;This is some text.&amp;#34; &amp;gt; sales.txt View A File&amp;rsquo;s Type file LICENSE.txt sales.txt: ASCII text  </description>
    </item>
    
    <item>
      <title>View A Text File&#39;s Contents</title>
      <link>https://chrisalbon.com/linux/basics/view_file_contents/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/view_file_contents/</guid>
      <description>Often we want to look at the contents of some code or configuration file. In Linux, we can do this using the less command.
Create A Text File With Some Contents echo &amp;#34;Hello World&amp;#34; &amp;gt; hello_world.txt View Contents Of File To view the contents of a file we can open it in the nano, a common text editor in Linux systems.
nano hello_world.txt If we want to leave a file we can press ctrl-x.</description>
    </item>
    
    <item>
      <title>View Aliases</title>
      <link>https://chrisalbon.com/linux/environment/view_aliases/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/environment/view_aliases/</guid>
      <description>We can see all the aliases in the environment using the alias command. This can be useful if we have setup some aliases operations we do frequently (like cd into a particular project&amp;rsquo;s folder) and we want to remember what they are.
aliases alias alert=&#39;notify-send --urgency=low -i &amp;quot;$([ $? = 0 ] &amp;amp;&amp;amp; echo terminal || echo error)&amp;quot; &amp;quot;$(history|tail -n1|sed -e &#39;\&#39;&#39;s/^\s*[0-9]\+\s*//;s/[;&amp;amp;|]\s*alert$//&#39;\&#39;&#39;)&amp;quot;&#39; alias egrep=&#39;egrep --color=auto&#39; alias fgrep=&#39;fgrep --color=auto&#39; alias grep=&#39;grep --color=auto&#39; alias l=&#39;ls -CF&#39; alias la=&#39;ls -A&#39; alias lcl=&#39;ls -l&#39; alias ll=&#39;ls -alF&#39; alias ls=&#39;ls --color=auto&#39;  </description>
    </item>
    
    <item>
      <title>View Current Working Directory</title>
      <link>https://chrisalbon.com/linux/basics/view_current_working_directory/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/view_current_working_directory/</guid>
      <description> Often we want to view the current working directory. To do this we can use the pwd command.
View Current Working Directory pwd /home/chris  </description>
    </item>
    
    <item>
      <title>View Environment Variable</title>
      <link>https://chrisalbon.com/linux/environment/view_environment_variables/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/environment/view_environment_variables/</guid>
      <description>The printenv command shows us the environment variables.
printenv SHELL=/bin/bash TERM=xterm-256color USER=chris LS_COLORS=rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.jpg=01;35:*.jpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36: MAIL=/var/mail/chris PATH=/home/chris/bin:/home/chris/.local/bin:/home/chris/anaconda3/bin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/snap/bin QT_QPA_PLATFORMTHEME=appmenu-qt5 PWD=/home/chris/example_directory LANG=en_US.UTF-8 SHLVL=1 HOME=/home/chris LOGNAME=chris LESSOPEN=| /usr/bin/lesspipe %s LESSCLOSE=/usr/bin/lesspipe %s %s _=/usr/bin/printenv OLDPWD=/home/chris  </description>
    </item>
    
    <item>
      <title>View First And Last Parts Of Files</title>
      <link>https://chrisalbon.com/linux/basics/view_first_and_last_parts_of_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/view_first_and_last_parts_of_files/</guid>
      <description>The sort command reorganizes lines in a text file or standard output (technically the same thing) so they are arranged numerically and alphabetically.
Create Example File With List Of Names echo &amp;#39;Luca Gartside&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Reule Smyth&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Spencer Smit&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Crurnirk Steelflow&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Uli Pinetotem&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Ognem Dustsplitter&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Ebil Frugroll&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Gordon Humphrey&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Jermaine Randall&amp;#39; &amp;gt;&amp;gt; adventurers.txtecho &amp;#39;Eli Steele&amp;#39; &amp;gt;&amp;gt; adventurers.</description>
    </item>
    
    <item>
      <title>View Size Of Table</title>
      <link>https://chrisalbon.com/postgresql/tables/view_size_of_table/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/tables/view_size_of_table/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Row -- Insert row into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) View Size Of Table Note: This is method only with in PostgreSQL databases</description>
    </item>
    
    <item>
      <title>View Unique Values</title>
      <link>https://chrisalbon.com/postgresql/basics/view_unique_values/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/postgresql/basics/view_unique_values/</guid>
      <description>Create Table -- Create table called adventurers CREATE TABLE adventurers ( -- string variable  name varchar(255), -- integer variable  age int, -- string variable  race varchar(255), -- string variable  weapon varchar(255) ) Insert Rows -- Insert into the table adventurers INSERT INTO adventurers (name, age, race, weapon) VALUES (&amp;#39;Fjoak Doom-Wife&amp;#39;, 28, &amp;#39;Human&amp;#39;, &amp;#39;Axe&amp;#39;), (&amp;#39;Alooneric Cortte&amp;#39;, 29, &amp;#39;Elf&amp;#39;, &amp;#39;Bow&amp;#39;), (&amp;#39;Piperel Ramsay&amp;#39;, 35, &amp;#39;Elf&amp;#39;, &amp;#39;Sword&amp;#39;), (&amp;#39;Casimir Yardley&amp;#39;, 14, &amp;#39;Elf&amp;#39;, &amp;#39;Magic&amp;#39;) View Unique Values In Race -- View unique values in the race column SELECT DISTINCT race FROM adventurers race Elf Human</description>
    </item>
    
    <item>
      <title>Write Errors To File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/write_errors_to_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/write_errors_to_file/</guid>
      <description>Standard errors are by default printed on the screen. However, it is often useful to write errors to a file for logging purposes. We can do that using 2&amp;gt;.
Create Code That Will Produce Error ls /a/ ls: cannot access &#39;/a/&#39;: No such file or directory  Create File To Store Error touch errors.log Write Error To File In this line we run the command that produces the error and then add 2&amp;gt; errors.</description>
    </item>
    
    <item>
      <title>Write Output To File</title>
      <link>https://chrisalbon.com/linux/inputs_and_outputs/write_output_to_file/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/inputs_and_outputs/write_output_to_file/</guid>
      <description>By default standard output of a program goes to the screen. For example, the standard output of ls is a list of files and directories in a directory, which is by default shown on the terminal screen. However, it does not need to be. We can redirect the standard output of a program to a file using the &amp;gt; operator.
Make Some Files And Folders touch config.txt; touch data.csv; touch readme.</description>
    </item>
    
    <item>
      <title>Zip And Unzip Directories</title>
      <link>https://chrisalbon.com/linux/basics/zip_and_unzip_directories/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/zip_and_unzip_directories/</guid>
      <description>Make Directory mkdir regiment_data Make Files In Directory touch regiment_data/battles.txt regiment_data/regiment.txt Zip Directory In the code below, we compress (zip) the regiment_data directory into the file regiment.zip. Note that -r means that we want to not only zip the directory but also its contents (which is almost always the case) . zip -r regiment.zip regiment_data
 adding: regiment_data/ (stored 0%) adding: regiment_data/battles.txt (stored 0%) adding: regiment_data/regiment.txt (stored 0%)  View Directory Contents ls -l total 8 drwxrwxr-x 2 chris chris 4096 Jul 31 13:39 regiment_data -rw-rw-r-- 1 chris chris 536 Jul 31 13:39 regiment.</description>
    </item>
    
    <item>
      <title>Zip And Unzip Files</title>
      <link>https://chrisalbon.com/linux/basics/zip_and_unzip_files/</link>
      <pubDate>Sun, 17 Jun 2018 00:00:00 -0700</pubDate>
      
      <guid>https://chrisalbon.com/linux/basics/zip_and_unzip_files/</guid>
      <description>Make Files echo &amp;#34;The number of soldiers in the regiment is 24.&amp;#34;&amp;gt; regiment.txt echo &amp;#34;The regiment has seen five battles.&amp;#34; &amp;gt; battles.txt Zip Files The -v argument is optional, prints an output with the details of the operation.
gzip regiment.txt battles.txt -v regiment.txt:	-2.2% -- replaced with regiment.txt.gz battles.txt:	-5.6% -- replaced with battles.txt.gz  View Contents Of Directory ls -l total 8 -rw-rw-r-- 1 chris chris 68 Jul 31 13:15 battles.</description>
    </item>
    
    <item>
      <title>Columns Shared By Two Data Frames</title>
      <link>https://chrisalbon.com/python/data_wrangling/columns_shared_by_two_data_frames/</link>
      <pubDate>Mon, 12 Mar 2018 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/columns_shared_by_two_data_frames/</guid>
      <description>Preliminaries # Import library import pandas as pd Create Data Frames # Create a data frame dataframe_one = pd.DataFrame() dataframe_one[&amp;#39;1&amp;#39;] = [&amp;#39;1&amp;#39;, &amp;#39;1&amp;#39;, &amp;#39;1&amp;#39;] dataframe_one[&amp;#39;B&amp;#39;] = [&amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;] # Create a second data frame dataframe_two = pd.DataFrame() dataframe_two[&amp;#39;2&amp;#39;] = [&amp;#39;2&amp;#39;, &amp;#39;2&amp;#39;, &amp;#39;2&amp;#39;] dataframe_two[&amp;#39;B&amp;#39;] = [&amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;b&amp;#39;] Find Shared Columns # Convert each data frame&amp;#39;s columns into sets, then find # the intersection of those two sets. This will be the # set of columns shared by both data frames.</description>
    </item>
    
    <item>
      <title>ANOVA F-value For Feature Selection</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/anova_f-value_for_feature_selection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/anova_f-value_for_feature_selection/</guid>
      <description>If the features are categorical, calculate a chi-square ($\chi^{2}$) statistic between each feature and the target vector. However, if the features are quantitative, compute the ANOVA F-value between each feature and the target vector.
The F-value scores examine if, when we group the numerical feature by the target vector, the means for each group are significantly different.
Preliminaries # Load libraries from sklearn.datasets import load_iris from sklearn.feature_selection import SelectKBest from sklearn.</description>
    </item>
    
    <item>
      <title>About Chris Albon</title>
      <link>https://chrisalbon.com/about/chris_albon/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/about/chris_albon/</guid>
      <description>I am the Director of Data Science at Devoted Health, using data science and machine learning to help fix America&amp;rsquo;s health care system. Previously, I was Chief Data Scientist at the Kenyan startup BRCK, cofounded Yonder, created the data science podcast Partially Derivative, led the data team at the humanitarian non-profit Ushahidi, and was the director of the low-resource technology governance project at FrontlineSMS. I also wrote Machine Learning For Python Cookbook (O&amp;rsquo;Reilly 2018) and created Machine Learning Flashcards.</description>
    </item>
    
    <item>
      <title>Accuracy</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/accuracy/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/accuracy/</guid>
      <description>Preliminaries # Load libraries from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification Generate Features And Target Data # Generate features matrix and target vector X, y = make_classification(n_samples = 10000, n_features = 3, n_informative = 3, n_redundant = 0, n_classes = 2, random_state = 1) Create Logistic Regression # Create logistic regression logit = LogisticRegression() Cross-Validate Model Using Accuracy # Cross-validate model using accuracy cross_val_score(logit, X, y, scoring=&amp;#34;accuracy&amp;#34;) array([ 0.</description>
    </item>
    
    <item>
      <title>Adaboost Classifier</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/adaboost_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/adaboost_classifier/</guid>
      <description>Preliminaries # Load libraries from sklearn.ensemble import AdaBoostClassifier from sklearn import datasets Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Adaboost Classifier The most important parameters are base_estimator, n_estimators, and learning_rate.
 base_estimator is the learning algorithm to use to train the weak models. This will almost always not needed to be changed because by far the most common learner to use with AdaBoost is a decision tree &amp;ndash; this parameter&amp;rsquo;s default argument.</description>
    </item>
    
    <item>
      <title>Add Padding Around String</title>
      <link>https://chrisalbon.com/python/basics/add_padding_around_string/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/add_padding_around_string/</guid>
      <description> Create Some Text text = &amp;#39;Chapter 1&amp;#39; Add Padding Around Text # Add Spaces Of Padding To The Left format(text, &amp;#39;&amp;gt;20&amp;#39;) &#39; Chapter 1&#39;  # Add Spaces Of Padding To The Right format(text, &amp;#39;&amp;lt;20&amp;#39;) &#39;Chapter 1 &#39;  # Add Spaces Of Padding On Each Side format(text, &amp;#39;^20&amp;#39;) &#39; Chapter 1 &#39;  # Add * Of Padding On Each Side format(text, &amp;#39;*^20&amp;#39;) &#39;*****Chapter 1******&#39;  </description>
    </item>
    
    <item>
      <title>Adding And Subtracting Matrices</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/adding_and_subtracting_matrices/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/adding_and_subtracting_matrices/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrices # Create matrix matrix_a = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 2]]) # Create matrix matrix_b = np.array([[1, 3, 1], [1, 3, 1], [1, 3, 8]]) Add Matrices # Add two matrices np.add(matrix_a, matrix_b) array([[ 2, 4, 2], [ 2, 4, 2], [ 2, 4, 10]])  Subtract Matrices # Subtract two matrices np.subtract(matrix_a, matrix_b) array([[ 0, -2, 0], [ 0, -2, 0], [ 0, -2, -6]])  </description>
    </item>
    
    <item>
      <title>Adding Dropout</title>
      <link>https://chrisalbon.com/deep_learning/keras/adding_dropout/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/adding_dropout/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers # Set random seed np.random.seed(0) Using TensorFlow backend.  Load IMDB Movie Review Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Adding Interaction Terms</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/adding_interaction_terms/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/adding_interaction_terms/</guid>
      <description>Preliminaries # Load libraries from sklearn.linear_model import LinearRegression from sklearn.datasets import load_boston from sklearn.preprocessing import PolynomialFeatures import warnings # Suppress Warning warnings.filterwarnings(action=&amp;#34;ignore&amp;#34;, module=&amp;#34;scipy&amp;#34;, message=&amp;#34;^internal gelsd&amp;#34;) Load Boston Housing Dataset # Load the data with only two features boston = load_boston() X = boston.data[:,0:2] y = boston.target Add Interaction Term Interaction effects can be account for by including a new feature comprising the product of corresponding values from the interacting features:</description>
    </item>
    
    <item>
      <title>Agglomerative Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/agglomerative_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/agglomerative_clustering/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.cluster import AgglomerativeClustering Load Iris Flower Data # Load data iris = datasets.load_iris() X = iris.data Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Conduct Agglomerative Clustering In scikit-learn, AgglomerativeClustering uses the linkage parameter to determine the merging strategy to minimize the 1) variance of merged clusters (ward), 2) average of distance between observations from pairs of clusters (average), or 3) maximum distance between observations from pairs of clusters (complete).</description>
    </item>
    
    <item>
      <title>All Combinations For A List Of Objects</title>
      <link>https://chrisalbon.com/python/basics/all_combinations_of_a_list_of_objects/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/all_combinations_of_a_list_of_objects/</guid>
      <description>Preliminary # Import combinations with replacements from itertools from itertools import combinations_with_replacement Create a list of objects # Create a list of objects to combine list_of_objects = [&amp;#39;warplanes&amp;#39;, &amp;#39;armor&amp;#39;, &amp;#39;infantry&amp;#39;] Find all combinations (with replacement) for the list # Create an empty list object to hold the results of the loop combinations = [] # Create a loop for every item in the length of list_of_objects, that, for i in list(range(len(list_of_objects))): # Finds every combination (with replacement) for each object in the list combinations.</description>
    </item>
    
    <item>
      <title>Apply Functions By Group In Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_apply_function_by_group/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_apply_function_by_group/</guid>
      <description>Preliminaries # import pandas as pd import pandas as pd Create a simulated dataset # Create an example dataframe data = {&amp;#39;Platoon&amp;#39;: [&amp;#39;A&amp;#39;,&amp;#39;A&amp;#39;,&amp;#39;A&amp;#39;,&amp;#39;A&amp;#39;,&amp;#39;A&amp;#39;,&amp;#39;A&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;B&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;C&amp;#39;,&amp;#39;C&amp;#39;], &amp;#39;Casualties&amp;#39;: [1,4,5,7,5,5,6,1,4,5,6,7,4,6,4,6]} df = pd.DataFrame(data) df    Casualties Platoon     0 1 A   1 4 A   2 5 A   3 7 A   4 5 A   5 5 A   6 6 B   7 1 B   8 4 B   9 5 B   10 6 B   11 7 C   12 4 C   13 6 C   14 4 C   15 6 C     Apply A Function (Rolling Mean) To The DataFrame, By Group # Group df by df.</description>
    </item>
    
    <item>
      <title>Apply Operations Over Items In A List</title>
      <link>https://chrisalbon.com/python/basics/apply_operations_over_items_in_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/apply_operations_over_items_in_lists/</guid>
      <description>Method 1: map() # Create a list of casualties from battles battleDeaths = [482, 93, 392, 920, 813, 199, 374, 237, 244]# Create a function that updates all battle deaths by adding 100 def updated(x): return x + 100# Create a list that applies updated() to all elements of battleDeaths list(map(updated, battleDeaths)) [582, 193, 492, 1020, 913, 299, 474, 337, 344]  Method 2: for x in y # Create a list of deaths casualties = [482, 93, 392, 920, 813, 199, 374, 237, 244]# Create a variable where we will put the updated casualty numbers casualtiesUpdated = []# Create a function that for each item in casualties, adds 10 for x in casualties: casualtiesUpdated.</description>
    </item>
    
    <item>
      <title>Apply Operations To Elements</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/apply_operations_to_elements/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/apply_operations_to_elements/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Create Vectorized Function # Create a function that adds 100 to something add_100 = lambda i: i + 100 # Create a vectorized function vectorized_add_100 = np.vectorize(add_100) Apply Function To Elements # Apply function to all elements in matrix vectorized_add_100(matrix) array([[101, 102, 103], [104, 105, 106], [107, 108, 109]])  </description>
    </item>
    
    <item>
      <title>Apply Operations To Groups In Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_groups/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_groups/</guid>
      <description>Preliminaries # import modules import pandas as pd# Create dataframe raw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;,&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;], &amp;#39;name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]} df = pd.</description>
    </item>
    
    <item>
      <title>Applying Functions To List Items</title>
      <link>https://chrisalbon.com/python/basics/applying_functions_to_list_items/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/applying_functions_to_list_items/</guid>
      <description>Create a list of regiment names regimentNames = [&amp;#39;Night Riflemen&amp;#39;, &amp;#39;Jungle Scouts&amp;#39;, &amp;#39;The Dragoons&amp;#39;, &amp;#39;Midnight Revengence&amp;#39;, &amp;#39;Wily Warriors&amp;#39;] Using A For Loop Create a for loop goes through the list and capitalizes each # create a variable for the for loop results regimentNamesCapitalized_f = [] # for every item in regimentNames for i in regimentNames: # capitalize the item and add it to regimentNamesCapitalized_f regimentNamesCapitalized_f.append(i.upper()) # View the outcome regimentNamesCapitalized_f [&#39;NIGHT RIFLEMEN&#39;, &#39;JUNGLE SCOUTS&#39;, &#39;THE DRAGOONS&#39;, &#39;MIDNIGHT REVENGENCE&#39;, &#39;WILY WARRIORS&#39;]  Using Map() Create a lambda function that capitalizes x capitalizer = lambda x: x.</description>
    </item>
    
    <item>
      <title>Applying Operations Over pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_dataframes/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_apply_operations_to_dataframes/</guid>
      <description>Import Modules import pandas as pd import numpy as np Create a dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;coverage&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    coverage name reports year     Cochice 25 Jason 4 2012   Pima 94 Molly 24 2012   Santa Cruz 57 Tina 31 2013   Maricopa 62 Jake 2 2014   Yuma 70 Amy 3 2014     Create a capitalization lambda function capitalizer = lambda x: x.</description>
    </item>
    
    <item>
      <title>Arithmetic Basics</title>
      <link>https://chrisalbon.com/python/basics/arithmetic_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/arithmetic_basics/</guid>
      <description>Create some simulated variables x = 6 y = 9 x plus y x + y 15  x minus y x - y -3  x times y x * y 54  the remainder of x divided by y x % y 6  x divided by y x / y 0.6666666666666666  x divided by y (floor) (i.e. the quotient) x // y 0  x raised to the y power x ** y 10077696  x plus y, then divide by x (x + y) / x 2.</description>
    </item>
    
    <item>
      <title>Assign A New Column To A Pandas DataFrame</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_assign_new_column_dataframe/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_assign_new_column_dataframe/</guid>
      <description> Preliminaries import pandas as pd Create Dataframe # Create empty dataframe df = pd.DataFrame() # Create a column df[&amp;#39;name&amp;#39;] = [&amp;#39;John&amp;#39;, &amp;#39;Steve&amp;#39;, &amp;#39;Sarah&amp;#39;] # View dataframe df    name     0 John   1 Steve   2 Sarah     Assign New Column To Dataframe # Assign a new column to df called &amp;#39;age&amp;#39; with a list of ages df.assign(age = [31, 32, 19])    name age     0 John 31   1 Steve 32   2 Sarah 19     </description>
    </item>
    
    <item>
      <title>Assignment Operators</title>
      <link>https://chrisalbon.com/python/basics/assignment_operators/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/assignment_operators/</guid>
      <description>Create some variables a = 2 b = 1 c = 0 d = 3 Assigns values from right side to left side c = a + b c 3  Add right to the left and assign the result to left (c = a + c) c += a c 5  Subtract right from the left and assign the result to left (c = a - c) c -= a c 3  Multiply right with the left and assign the result to left (c = a * c) c *= a c 6  Divide left with the right and assign the result to left (c = c / a) c /= a c 3.</description>
    </item>
    
    <item>
      <title>Back To Back Bar Plot In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_back_to_back_bar_plot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_back_to_back_bar_plot/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;pre_score&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;mid_score&amp;#39;: [25, 94, 57, 62, 70], &amp;#39;post_score&amp;#39;: [5, 43, 23, 23, 51]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;pre_score&amp;#39;, &amp;#39;mid_score&amp;#39;, &amp;#39;post_score&amp;#39;]) df    first_name pre_score mid_score post_score     0 Jason 4 25 5   1 Molly 24 94 43   2 Tina 31 57 23   3 Jake 2 62 23   4 Amy 3 70 51     Make plot # input data, specifically the second and  # third rows, skipping the first column x1 = df.</description>
    </item>
    
    <item>
      <title>Bag Of Words</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/bag_of_words/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/bag_of_words/</guid>
      <description>Preliminaries # Load library import numpy as np from sklearn.feature_extraction.text import CountVectorizer import pandas as pd Create Text Data # Create text text_data = np.array([&amp;#39;I love Brazil. Brazil!&amp;#39;, &amp;#39;Sweden is best&amp;#39;, &amp;#39;Germany beats both&amp;#39;]) Create Bag Of Words # Create the bag of words feature matrix count = CountVectorizer() bag_of_words = count.fit_transform(text_data) # Show feature matrix bag_of_words.toarray() array([[0, 0, 0, 2, 0, 0, 1, 0], [0, 1, 0, 0, 0, 1, 0, 1], [1, 0, 1, 0, 1, 0, 0, 0]], dtype=int64)  View Bag Of Words Matrix Column Headers # Get feature names feature_names = count.</description>
    </item>
    
    <item>
      <title>Bar Plot In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_bar_plot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_bar_plot/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;pre_score&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;mid_score&amp;#39;: [25, 94, 57, 62, 70], &amp;#39;post_score&amp;#39;: [5, 43, 23, 23, 51]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;pre_score&amp;#39;, &amp;#39;mid_score&amp;#39;, &amp;#39;post_score&amp;#39;]) df    first_name pre_score mid_score post_score     0 Jason 4 25 5   1 Molly 24 94 43   2 Tina 31 57 23   3 Jake 2 62 23   4 Amy 3 70 51     Make plot # Create a list of the mean scores for each variable mean_values = [df[&amp;#39;pre_score&amp;#39;].</description>
    </item>
    
    <item>
      <title>Basic Logging</title>
      <link>https://chrisalbon.com/python/logging/basic_logging/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/logging/basic_logging/</guid>
      <description>Preliminaries # Import standard library&amp;#39;s logging import logging Configure Logging # Configure logging to ignore messages below info (i.e. debug level is ignored) logging.basicConfig(level=logging.INFO) Create Function # Create function that converts dollars to cents def convert_dollars_to_cents(dollars): # Try... try: # Multiply dollars by 100 cents = dollars * 100 # Convert to integer cents = int(cents) # Send info message that function was run successful logging.info(&amp;#34;convert_dollars_to_cents run successfully&amp;#34;) # Return cents return cents # If a ValueError is raised except ValueError: # Create data type of input dollars_type = type(dollars) # Create error message detailing the error error_message = f&amp;#34;Function input is {dollars_type}, should be &amp;lt;class \&amp;#39;int\&amp;#39;&amp;gt;&amp;#34; # Send error message logging.</description>
    </item>
    
    <item>
      <title>Basic Operations With NumPy Array</title>
      <link>https://chrisalbon.com/python/basics/numpy_array_basic_operations/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/numpy_array_basic_operations/</guid>
      <description># Import modules import numpy as np# Create an array civilian_deaths = np.array([4352, 233, 3245, 256, 2394]) civilian_deaths array([4352, 233, 3245, 256, 2394])  # Mean value of the array civilian_deaths.mean() 2096.0  # Total amount of deaths civilian_deaths.sum() 10480  # Smallest value in the array civilian_deaths.min() 233  # Largest value in the array civilian_deaths.max() 4352  </description>
    </item>
    
    <item>
      <title>Beautiful Soup Basic HTML Scraping</title>
      <link>https://chrisalbon.com/python/web_scraping/beautiful_soup_html_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/web_scraping/beautiful_soup_html_basics/</guid>
      <description>Import the modules # Import required modules import requests from bs4 import BeautifulSoup Scrape the html and turn into a beautiful soup object # Create a variable with the url url = &amp;#39;http://chrisralbon.com&amp;#39; # Use requests to get the contents r = requests.get(url) # Get the text of the contents html_content = r.text # Convert the html content into a beautiful soup object soup = BeautifulSoup(html_content, &amp;#39;lxml&amp;#39;) Select the website&amp;rsquo;s title # View the title tag of the soup object soup.</description>
    </item>
    
    <item>
      <title>Bernoulli Naive Bayes Classifier</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/bernoulli_naive_bayes_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/bernoulli_naive_bayes_classifier/</guid>
      <description>The Bernoulli naive Bayes classifier assumes that all our features are binary such that they take only two values (e.g. a nominal categorical feature that has been one-hot encoded).
Preliminaries # Load libraries import numpy as np from sklearn.naive_bayes import BernoulliNB Create Binary Feature And Target Data # Create three binary features X = np.random.randint(2, size=(100, 3)) # Create a binary target vector y = np.random.randint(2, size=(100, 1)).ravel() View Feature Data # View first ten observations X[0:10] array([[1, 1, 1], [0, 1, 0], [1, 1, 1], [0, 0, 0], [1, 0, 1], [1, 1, 1], [0, 1, 1], [1, 1, 1], [1, 1, 1], [1, 1, 0]])  Train Bernoulli Naive Bayes Classifier # Create Bernoulli Naive Bayes object with prior probabilities of each class clf = BernoulliNB(class_prior=[0.</description>
    </item>
    
    <item>
      <title>Bessels Correction</title>
      <link>https://chrisalbon.com/statistics/frequentist/bessel_correction/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/bessel_correction/</guid>
      <description>Bessel&amp;rsquo;s correction is the reason we use $n-1$ instead of $n$ in the calculations of sample variance and sample standard deviation.
Sample variance:
$$ s^2 = \frac {1}{n-1} \sum_{i=1}^n \left(x_i - \overline{x} \right)^ 2 $$
When we calculate sample variance, we are attempting to estimate the population variance, an unknown value. To make this estimate, we estimate this unknown population variance from the mean of the squared deviations of samples from the overall sample mean.</description>
    </item>
    
    <item>
      <title>Big-O Notation</title>
      <link>https://chrisalbon.com/computer_science/algorithms/big-o_notation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/computer_science/algorithms/big-o_notation/</guid>
      <description>Big-O notation is used to classify the worst-case &amp;ldquo;speed&amp;rdquo; of an algorithm by looking at the order of magnitude of execution time.
From best to worst, some common Big-O&amp;rsquo;s are:
 O(1) O(log n) O(n) O(n log n) O(n2) O(n3) O(2n)  Below are some examples of a few of these.
Create Data # Create a list 100 elements long n = list(range(100)) O(1) - Constant Time-Complexity The length of n has no bearing on the number of steps required to complete the function.</description>
    </item>
    
    <item>
      <title>Binarize Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/binarize_image/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/binarize_image/</guid>
      <description> Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as greyscale image_grey = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Apply Adaptive Thresholding # Apply adaptive thresholding max_output_value = 255 neighorhood_size = 99 subtract_from_mean = 10 image_binarized = cv2.adaptiveThreshold(image_grey, max_output_value, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, neighorhood_size, subtract_from_mean) View Image # Show image plt.imshow(image_binarized, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() </description>
    </item>
    
    <item>
      <title>Binary Search</title>
      <link>https://chrisalbon.com/computer_science/algorithms/binary_search/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/computer_science/algorithms/binary_search/</guid>
      <description>Create Sorted List sorted_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20] print(sorted_list) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20]  Create Binary Search Algorithm def binary_search(sorted_list, target): &amp;#39;&amp;#39;&amp;#39;This function inputs a sorted list and a target value to find and returns ....&amp;#39;&amp;#39;&amp;#39; # Create variables for the index of the first and last elements start = 0 end = len(sorted_list) - 1 while end &amp;gt;= start: # Create a variable for the index of the middle term middle = start + (end - start) // 2 # // is integer division in Python 3.</description>
    </item>
    
    <item>
      <title>Blurring Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/blurring_images/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/blurring_images/</guid>
      <description> Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Blur Image # Blur image image_blurry = cv2.blur(image, (5,5)) View Image # Show image plt.imshow(image_blurry, cmap=&amp;#39;gray&amp;#39;), plt.xticks([]), plt.yticks([]) plt.show() </description>
    </item>
    
    <item>
      <title>Break A List Into N-Sized Chunks</title>
      <link>https://chrisalbon.com/python/data_wrangling/break_list_into_chunks_of_equal_size/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/break_list_into_chunks_of_equal_size/</guid>
      <description>In this snippet we take a list and break it up into n-size chunks. This is a very common practice when dealing with APIs that have a maximum request size.
Credit for this nifty function goes to Ned Batchelder who posted it on StackOverflow.
# Create a list of first names first_names = [&amp;#39;Steve&amp;#39;, &amp;#39;Jane&amp;#39;, &amp;#39;Sara&amp;#39;, &amp;#39;Mary&amp;#39;,&amp;#39;Jack&amp;#39;,&amp;#39;Bob&amp;#39;, &amp;#39;Bily&amp;#39;, &amp;#39;Boni&amp;#39;, &amp;#39;Chris&amp;#39;,&amp;#39;Sori&amp;#39;, &amp;#39;Will&amp;#39;, &amp;#39;Won&amp;#39;,&amp;#39;Li&amp;#39;]# Create a function called &amp;#34;chunks&amp;#34; with two arguments, l and n: def chunks(l, n): # For item i in a range that is a length of l, for i in range(0, len(l), n): # Create an index range for l of n items: yield l[i:i+n]# Create a list that from the results of the function chunks: list(chunks(first_names, 5)) [[&#39;Steve&#39;, &#39;Jane&#39;, &#39;Sara&#39;, &#39;Mary&#39;, &#39;Jack&#39;], [&#39;Bob&#39;, &#39;Bily&#39;, &#39;Boni&#39;, &#39;Chris&#39;, &#39;Sori&#39;], [&#39;Will&#39;, &#39;Won&#39;, &#39;Li&#39;]]  </description>
    </item>
    
    <item>
      <title>Break A Sequence Into Groups</title>
      <link>https://chrisalbon.com/scala/basics/break_a_sequence_into_groups/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/break_a_sequence_into_groups/</guid>
      <description> Create An Array Sequence // Create an array that contains arrays with first and last names val ages = List(42,25,28,38,58,63,23,458,2569,584,25,25,878) Group Array By Anonymous Function // If an element is even, return True, if not, return False val isEven = ages.groupBy(_ % 2 == 0) View Groups // View group that is evens evensOdds(true) List(42, 28, 38, 58, 458, 584, 878)  // View group that is odds evensOdds(false) List(25, 63, 23, 2569, 25, 25)  </description>
    </item>
    
    <item>
      <title>Break Up Dates And Times Into Multiple Features</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/break_up_dates_and_times_into_multiple_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/break_up_dates_and_times_into_multiple_features/</guid>
      <description>Preliminaries # Load library import pandas as pd Create Date And Time Data # Create data frame df = pd.DataFrame() # Create five dates df[&amp;#39;date&amp;#39;] = pd.date_range(&amp;#39;1/1/2001&amp;#39;, periods=150, freq=&amp;#39;W&amp;#39;) Break Up Dates And Times Into Individual Features # Create features for year, month, day, hour, and minute df[&amp;#39;year&amp;#39;] = df[&amp;#39;date&amp;#39;].dt.year df[&amp;#39;month&amp;#39;] = df[&amp;#39;date&amp;#39;].dt.month df[&amp;#39;day&amp;#39;] = df[&amp;#39;date&amp;#39;].dt.day df[&amp;#39;hour&amp;#39;] = df[&amp;#39;date&amp;#39;].dt.hour df[&amp;#39;minute&amp;#39;] = df[&amp;#39;date&amp;#39;].dt.minute # Show three rows df.head(3)   .</description>
    </item>
    
    <item>
      <title>Breaking Up A String Into Columns Using Regex In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_regex_to_create_columns/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_regex_to_create_columns/</guid>
      <description>Import modules import re import pandas as pd Create a dataframe of raw strings # Create a dataframe with a single column of strings data = {&amp;#39;raw&amp;#39;: [&amp;#39;Arizona 1 2014-12-23 3242.0&amp;#39;, &amp;#39;Iowa 1 2010-02-23 3453.7&amp;#39;, &amp;#39;Oregon 0 2014-06-20 2123.0&amp;#39;, &amp;#39;Maryland 0 2014-03-14 1123.6&amp;#39;, &amp;#39;Florida 1 2013-01-15 2134.0&amp;#39;, &amp;#39;Georgia 0 2012-07-14 2345.6&amp;#39;]} df = pd.DataFrame(data, columns = [&amp;#39;raw&amp;#39;]) df    raw     0 Arizona 1 2014-12-23 3242.</description>
    </item>
    
    <item>
      <title>Breaking Up String Variables</title>
      <link>https://chrisalbon.com/python/basics/breaking_up_string_variables/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/breaking_up_string_variables/</guid>
      <description> Basic name assignment variableName = &amp;#39;This is a string.&amp;#39; List assignment One, Two, Three = [1, 2, 3] Break up a string into variables firstLetter, secondLetter, thirdLetter, fourthLetter = &amp;#39;Bark&amp;#39;firstLetter &#39;B&#39;  secondLetter &#39;a&#39;  thirdLetter &#39;r&#39;  fourthLetter &#39;k&#39;  Breaking up a number into separate variables firstNumber, secondNumber, thirdNumber, fourthNumber = &amp;#39;9485&amp;#39;firstNumber &#39;9&#39;  secondNumber &#39;4&#39;  thirdNumber &#39;8&#39;  fourthNumber &#39;5&#39;  Assign the first letter of &amp;lsquo;spam&amp;rsquo; into varible a, assign all the remaining letters to variable b a, *b = &amp;#39;spam&amp;#39; a &#39;s&#39;  b [&#39;p&#39;, &#39;a&#39;, &#39;m&#39;]  </description>
    </item>
    
    <item>
      <title>Brute Force D20 Roll Simulator</title>
      <link>https://chrisalbon.com/python/basics/brute_force_d20_simulator/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/brute_force_d20_simulator/</guid>
      <description>This snippet is a completely inefficient simulator of a 20 sided dice. To create a &amp;ldquo;successful roll&amp;rdquo; the snippet has to generate dozens of random numbers.
Import random module import random Create a variable with a TRUE value rolling = True Create a while loop that rolls until the first digit is 2 or less and the second digit is 10 or less # while rolling is true while rolling: # create x, a random number between 0 and 99 x = random.</description>
    </item>
    
    <item>
      <title>Bubble Sort</title>
      <link>https://chrisalbon.com/computer_science/algorithms/bubble_sort/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/computer_science/algorithms/bubble_sort/</guid>
      <description> Create A Sequence unsorted_list = [8,5,3,6,2,1,9,4,7] unsorted_list [8, 5, 3, 6, 2, 1, 9, 4, 7]  Create A Bubble Sort Function # Define a function that takes an unsorted sequence def bubble_sort(unsorted_list): # Create a new list containing the values from the inputed list sequence = unsorted_list[:] # For each value of the sequence (epochs), for i, _ in enumerate(sequence): # For each value of the sequence, for i, _ in enumerate(sequence): # Try try: # If a value is greater than the value that follows it if sequence[i] &amp;gt; sequence[i+1]: # Swap the values in the sequence sequence[i], sequence[i+1] = sequence[i+1], sequence[i] # If you raise an index error, you are at the end of the sequence, except IndexError: # So ignore the error and continue with iteration continue # Print the sequence afer each epoch print(sequence)# Run the function bubble_sort(unsorted_list) [5, 3, 6, 2, 1, 8, 4, 7, 9] [3, 5, 2, 1, 6, 4, 7, 8, 9] [3, 2, 1, 5, 4, 6, 7, 8, 9] [2, 1, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9] [1, 2, 3, 4, 5, 6, 7, 8, 9]  </description>
    </item>
    
    <item>
      <title>Calculate Difference Between Dates And Times</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/calculate_difference_between_dates_and_times/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/calculate_difference_between_dates_and_times/</guid>
      <description> Preliminaries # Load library import pandas as pd Create Date And Time Data # Create data frame df = pd.DataFrame() # Create two datetime features df[&amp;#39;Arrived&amp;#39;] = [pd.Timestamp(&amp;#39;01-01-2017&amp;#39;), pd.Timestamp(&amp;#39;01-04-2017&amp;#39;)] df[&amp;#39;Left&amp;#39;] = [pd.Timestamp(&amp;#39;01-01-2017&amp;#39;), pd.Timestamp(&amp;#39;01-06-2017&amp;#39;)] Calculate Difference (Method 1) # Calculate duration between features df[&amp;#39;Left&amp;#39;] - df[&amp;#39;Arrived&amp;#39;] 0 0 days 1 2 days dtype: timedelta64[ns]  Calculate Difference (Method 2) # Calculate duration between features pd.Series(delta.days for delta in (df[&amp;#39;Left&amp;#39;] - df[&amp;#39;Arrived&amp;#39;])) 0 0 1 2 dtype: int64  </description>
    </item>
    
    <item>
      <title>Calculate Dot Product Of Two Vectors</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_dot_product_of_two_vectors/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_dot_product_of_two_vectors/</guid>
      <description> Preliminaries # Load library import numpy as np Create Two Vectors # Create two vectors vector_a = np.array([1,2,3]) vector_b = np.array([4,5,6]) Calculate Dot Product (Method 1) # Calculate dot product np.dot(vector_a, vector_b) 32  Calculate Dot Product (Method 2) # Calculate dot product vector_a @ vector_b 32  </description>
    </item>
    
    <item>
      <title>Calculate The Average, Variance, And Standard Deviation</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_average_variance_and_standard_deviation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_average_variance_and_standard_deviation/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Calculate Mean # Return mean np.mean(matrix) 5.0  Calculate Variance # Return variance np.var(matrix) 6.666666666666667  Calculate Standard Deviation # Return standard deviation np.std(matrix) 2.5819888974716112  </description>
    </item>
    
    <item>
      <title>Calculate The Determinant Of A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_the_determinant_of_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_the_determinant_of_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Calculate Determinant # Return determinant of matrix np.linalg.det(matrix) -9.5161973539299405e-16  </description>
    </item>
    
    <item>
      <title>Calculate The Trace Of A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_the_trace_of_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/calculate_the_trace_of_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Calculate The Trace # Calculate the trace of the matrix matrix.diagonal().sum() 15  </description>
    </item>
    
    <item>
      <title>Calibrate Predicted Probabilities</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/calibrate_predicted_probabilities/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/calibrate_predicted_probabilities/</guid>
      <description>Class probabilities are a common and useful part of machine learning models. In scikit-learn, most learning algortihms allow us to see the predicted probabilities of class membership using predict_proba. This can be extremely useful if, for instance, we want to only predict a certain class if the model predicts the probability that they are that class is over 90%. However, some models, including naive Bayes classifiers output probabilities that are not based on the real world.</description>
    </item>
    
    <item>
      <title>Calibrate Predicted Probabilities In SVC</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/calibrate_predicted_probabilities_in_svc/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/calibrate_predicted_probabilities_in_svc/</guid>
      <description>SVC&amp;rsquo;s use of a hyperplane to create decision regions do not naturally output a probability estimate that an observation is a member of a certain class. However, we can in fact output calibrated class probabilities with a few caveats. In an SVC, Platt scaling can be used, wherein first the SVC is trained, then a separate cross-validated logistic regression is trained to map the SVC outputs into probabilities:
$$P(y=1 \mid x)={\frac {1}{1+e^{(A*f(x)+B)}}}$$</description>
    </item>
    
    <item>
      <title>Cartesian Product</title>
      <link>https://chrisalbon.com/python/basics/cartesian_product/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/cartesian_product/</guid>
      <description>Preliminaries # import pandas as pd import pandas as pd Create Data # Create two lists i = [1,2,3,4,5] j = [1,2,3,4,5] Calculate Cartesian Product (Method 1) # List every single x in i with every single y (i.e. Cartesian product) [(x, y) for x in i for y in j] [(1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (2, 1), (2, 2), (2, 3), (2, 4), (2, 5), (3, 1), (3, 2), (3, 3), (3, 4), (3, 5), (4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (5, 1), (5, 2), (5, 3), (5, 4), (5, 5)]  Calculate Cartesian Product (Method 2) # An alternative way to do the cartesian product # import itertools import itertools # for two sets, find the the cartisan product for i in itertools.</description>
    </item>
    
    <item>
      <title>Chain Together Lists</title>
      <link>https://chrisalbon.com/python/basics/chain_together_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/chain_together_lists/</guid>
      <description> Preliminaries from itertools import chain Create Two Lists # Create a list of allies allies = [&amp;#39;Spain&amp;#39;, &amp;#39;Germany&amp;#39;, &amp;#39;Namibia&amp;#39;, &amp;#39;Austria&amp;#39;] # Create a list of enemies enemies = [&amp;#39;Mexico&amp;#39;, &amp;#39;United Kingdom&amp;#39;, &amp;#39;France&amp;#39;] Iterate Over Both Lists As A Single Sequence # For each country in allies and enemies for country in chain(allies, enemies): # print the country print(country) Spain Germany Namibia Austria Mexico United Kingdom France  </description>
    </item>
    
    <item>
      <title>Change Data Type</title>
      <link>https://chrisalbon.com/scala/basics/change_data_type/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/change_data_type/</guid>
      <description>Change To Integer // Convert a float to an integer 32.34.toInt 32  // Convert a string to an integer &amp;#34;23394&amp;#34;.toInt 23394  Change To Double // Convert a string to a double &amp;#34;23394&amp;#34;.toDouble 23394.0  Change To Float // Convert a string to float &amp;#34;23394&amp;#34;.toFloat 23394.0  // Convert an integer to float 3923.toFloat 3923.0  Change To Long // Convert a string to long &amp;#34;23394&amp;#34;.toLong 23394  Change To Short // Convert a string to short &amp;#34;23394&amp;#34;.</description>
    </item>
    
    <item>
      <title>Chi-Squared For Feature Selection</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/chi-squared_for_feature_selection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/chi-squared_for_feature_selection/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import load_iris from sklearn.feature_selection import SelectKBest from sklearn.feature_selection import chi2 Load Data # Load iris data iris = load_iris() # Create features and target X = iris.data y = iris.target # Convert to categorical data by converting data to integers X = X.astype(int) Compare Chi-Squared Statistics # Select two features with highest chi-squared statistics chi2_selector = SelectKBest(chi2, k=2) X_kbest = chi2_selector.fit_transform(X, y) View Results # Show results print(&amp;#39;Original number of features:&amp;#39;, X.</description>
    </item>
    
    <item>
      <title>Chunk Sequence In Equal Sized Groups</title>
      <link>https://chrisalbon.com/scala/basics/chuck_sequence_into_equal_sized_groups/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/chuck_sequence_into_equal_sized_groups/</guid>
      <description>Create An Array Sequence // Create an array that contains arrays with first and last names val ages = List(42,25,28,38,58,63,23,458,2569,584,25,25,878) Chunk Array Into Groups Of Two Elements // Slide over sequence, create a list of two elements, then take two steps ages.sliding(2,2).toArray Array(List(42, 25), List(28, 38), List(58, 63), List(23, 458), List(2569, 584), List(25, 25), List(878))  Chunk Array Into Groups Of Two Elements, With Overlap // Slide over sequence, create a list of two elements, then take one step ages.</description>
    </item>
    
    <item>
      <title>Cleaning Text</title>
      <link>https://chrisalbon.com/python/basics/cleaning_text/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/cleaning_text/</guid>
      <description>Create some raw text # Create a list of three strings. incoming_reports = [&amp;#34;We are attacking on their left flank but are losing many men.&amp;#34;, &amp;#34;We cannot see the enemy army. Nothing else to report.&amp;#34;, &amp;#34;We are ready to attack but are waiting for your orders.&amp;#34;] Separate by word # import word tokenizer from nltk.tokenize import word_tokenize # Apply word_tokenize to each element of the list called incoming_reports tokenized_reports = [word_tokenize(report) for report in incoming_reports] # View tokenized_reports tokenized_reports [[&#39;We&#39;, &#39;are&#39;, &#39;attacking&#39;, &#39;on&#39;, &#39;their&#39;, &#39;left&#39;, &#39;flank&#39;, &#39;but&#39;, &#39;are&#39;, &#39;losing&#39;, &#39;many&#39;, &#39;men&#39;, &#39;.</description>
    </item>
    
    <item>
      <title>Color Palettes in Seaborn</title>
      <link>https://chrisalbon.com/python/data_visualization/seaborn_color_palettes/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/seaborn_color_palettes/</guid>
      <description>Preliminaries import pandas as pd %matplotlib inline import matplotlib.pyplot as plt import seaborn as snsdata = {&amp;#39;date&amp;#39;: [&amp;#39;2014-05-01 18:47:05.069722&amp;#39;, &amp;#39;2014-05-01 18:47:05.119994&amp;#39;, &amp;#39;2014-05-02 18:47:05.178768&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.280592&amp;#39;, &amp;#39;2014-05-03 18:47:05.332662&amp;#39;, &amp;#39;2014-05-03 18:47:05.385109&amp;#39;, &amp;#39;2014-05-04 18:47:05.436523&amp;#39;, &amp;#39;2014-05-04 18:47:05.486877&amp;#39;], &amp;#39;deaths_regiment_1&amp;#39;: [34, 43, 14, 15, 15, 14, 31, 25, 62, 41], &amp;#39;deaths_regiment_2&amp;#39;: [52, 66, 78, 15, 15, 5, 25, 25, 86, 1], &amp;#39;deaths_regiment_3&amp;#39;: [13, 73, 82, 58, 52, 87, 26, 5, 56, 75], &amp;#39;deaths_regiment_4&amp;#39;: [44, 75, 26, 15, 15, 14, 54, 25, 24, 72], &amp;#39;deaths_regiment_5&amp;#39;: [25, 24, 25, 15, 57, 68, 21, 27, 62, 5], &amp;#39;deaths_regiment_6&amp;#39;: [84, 84, 26, 15, 15, 14, 26, 25, 62, 24], &amp;#39;deaths_regiment_7&amp;#39;: [46, 57, 26, 15, 15, 14, 26, 25, 62, 41]} df = pd.</description>
    </item>
    
    <item>
      <title>Compare Two Dictionaries</title>
      <link>https://chrisalbon.com/python/basics/compare_two_dictionaries/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/compare_two_dictionaries/</guid>
      <description>Make Two Dictionaries importers = {&amp;#39;El Salvador&amp;#39; : 1234, &amp;#39;Nicaragua&amp;#39; : 152, &amp;#39;Spain&amp;#39; : 252 } exporters = {&amp;#39;Spain&amp;#39; : 252, &amp;#39;Germany&amp;#39; : 251, &amp;#39;Italy&amp;#39; : 1563 } Find Duplicate Keys # Find the intersection of importers and exporters importers.keys() &amp;amp; exporters.keys() {&#39;Spain&#39;}  Find Difference In Keys # Find the difference between importers and exporters importers.keys() - exporters.keys() {&#39;El Salvador&#39;, &#39;Nicaragua&#39;}  Find Key, Values Pairs In Common # Find countries where the amount of exports matches the amount of imports importers.</description>
    </item>
    
    <item>
      <title>Compare Two Floats</title>
      <link>https://chrisalbon.com/scala/basics/compare_two_floats/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/compare_two_floats/</guid>
      <description>Create Two Float Values // Create a value val price_old = 2.343232 // Create a value that is very slight different val price_new = 2.343231 Create A Function That Compares Two Floats // Define a function called ~= that contains three arguments: two numbers and a precision level, def ~=(x: Double, y: Double, precision: Double) = { // If the absolute difference is less than the precision level, return true, otherwise return false  if ((x - y).</description>
    </item>
    
    <item>
      <title>Concurrent Processing</title>
      <link>https://chrisalbon.com/python/basics/concurrent_processing/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/concurrent_processing/</guid>
      <description> Preliminaries from concurrent import futures Create Data data = range(100) Create Function # Create some function that takes a value def some_function(value): # And outputs it raised to its own power return value**value Run The Function On The Data Concurrently # With a pool of workers with futures.ProcessPoolExecutor() as executor: # Map the function to the data result = executor.map(some_function, data) View Results # List the first 5 outputs list(result)[0:5] [1, 1, 4, 27, 256]  </description>
    </item>
    
    <item>
      <title>Construct A Dictionary From Multiple Lists</title>
      <link>https://chrisalbon.com/python/data_wrangling/construct_a_dictionary_from_multiple_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/construct_a_dictionary_from_multiple_lists/</guid>
      <description> Create Two Lists # Create a list of theofficer&amp;#39;s name officer_names = [&amp;#39;Sodoni Dogla&amp;#39;, &amp;#39;Chris Jefferson&amp;#39;, &amp;#39;Jessica Billars&amp;#39;, &amp;#39;Michael Mulligan&amp;#39;, &amp;#39;Steven Johnson&amp;#39;] # Create a list of the officer&amp;#39;s army officer_armies = [&amp;#39;Purple Army&amp;#39;, &amp;#39;Orange Army&amp;#39;, &amp;#39;Green Army&amp;#39;, &amp;#39;Red Army&amp;#39;, &amp;#39;Blue Army&amp;#39;] Construct A Dictionary From The Two Lists # Create a dictionary that is the zip of the two lists dict(zip(officer_names, officer_armies)) {&#39;Chris Jefferson&#39;: &#39;Orange Army&#39;, &#39;Jessica Billars&#39;: &#39;Green Army&#39;, &#39;Michael Mulligan&#39;: &#39;Red Army&#39;, &#39;Sodoni Dogla&#39;: &#39;Purple Army&#39;, &#39;Steven Johnson&#39;: &#39;Blue Army&#39;}  </description>
    </item>
    
    <item>
      <title>Continue And Break Loops</title>
      <link>https://chrisalbon.com/python/basics/continue_and_break_loops/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/continue_and_break_loops/</guid>
      <description>Import the random module import random Create a while loop # set running to true running = True# while running is true while running: # Create a random integer between 0 and 5 s = random.randint(0,5) # If the integer is less than 3 if s &amp;lt; 3: # Print this print(&amp;#39;It is too small, starting over.&amp;#39;) # Reset the next interation of the loop # (i.e skip everything below and restart from the top) continue # If the integer is 4 if s == 4: running = False # Print this print(&amp;#39;It is 4!</description>
    </item>
    
    <item>
      <title>Convert A CSV Into Python Code To Recreate It</title>
      <link>https://chrisalbon.com/python/data_wrangling/csv_to_python_code/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/csv_to_python_code/</guid>
      <description>Preliminaries # Import the pandas package import pandas as pd Load the external dataset # Load the csv file as a pandas dataframe df_original = pd.read_csv(&amp;#39;http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv&amp;#39;) df = pd.read_csv(&amp;#39;http://vincentarelbundock.github.io/Rdatasets/csv/datasets/iris.csv&amp;#39;) Print the code required to create that dataset # Print the code to create the dataframe print(&amp;#39;==============================&amp;#39;) print(&amp;#39;RUN THE CODE BELOW THIS LINE&amp;#39;) print(&amp;#39;==============================&amp;#39;) print(&amp;#39;raw_data =&amp;#39;, df.to_dict(orient=&amp;#39;list&amp;#39;)) print(&amp;#39;df = pd.DataFrame(raw_data, columns = &amp;#39; + str(list(df_original)) + &amp;#39;)&amp;#39;) ============================== RUN THE CODE BELOW THIS LINE ============================== raw_data = {&#39;Sepal.</description>
    </item>
    
    <item>
      <title>Convert A Categorical Variable Into Dummy Variables</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_convert_categorical_to_dummies/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_convert_categorical_to_dummies/</guid>
      <description># import modules import pandas as pd# Create a dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;sex&amp;#39;: [&amp;#39;male&amp;#39;, &amp;#39;female&amp;#39;, &amp;#39;male&amp;#39;, &amp;#39;female&amp;#39;, &amp;#39;female&amp;#39;]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;sex&amp;#39;]) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    first_name last_name sex     0 Jason Miller male   1 Molly Jacobson female   2 Tina Ali male   3 Jake Milner female   4 Amy Cooze female     # Create a set of dummy variables from the sex variable pd.</description>
    </item>
    
    <item>
      <title>Convert A Categorical Variable Into Dummy Variables</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_convert_numeric_categorical_to_numeric_with_patsy/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_convert_numeric_categorical_to_numeric_with_patsy/</guid>
      <description># import modules import pandas as pd import patsy# Create dataframe raw_data = {&amp;#39;countrycode&amp;#39;: [1, 2, 3, 2, 1]} df = pd.DataFrame(raw_data, columns = [&amp;#39;countrycode&amp;#39;]) df    countrycode     0 1   1 2   2 3   3 2   4 1     # Convert the countrycode variable into three binary variables patsy.dmatrix(&amp;#39;C(countrycode)-1&amp;#39;, df, return_type=&amp;#39;dataframe&amp;#39;)    C(countrycode)[1] C(countrycode)[2] C(countrycode)[3]     0 1.</description>
    </item>
    
    <item>
      <title>Convert A String Categorical Variable To A Numeric Variable</title>
      <link>https://chrisalbon.com/python/data_wrangling/convert_categorical_to_numeric/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/convert_categorical_to_numeric/</guid>
      <description>import modules import pandas as pd Create dataframe raw_data = {&amp;#39;patient&amp;#39;: [1, 1, 1, 2, 2], &amp;#39;obs&amp;#39;: [1, 2, 3, 1, 2], &amp;#39;treatment&amp;#39;: [0, 1, 0, 1, 0], &amp;#39;score&amp;#39;: [&amp;#39;strong&amp;#39;, &amp;#39;weak&amp;#39;, &amp;#39;normal&amp;#39;, &amp;#39;weak&amp;#39;, &amp;#39;strong&amp;#39;]} df = pd.DataFrame(raw_data, columns = [&amp;#39;patient&amp;#39;, &amp;#39;obs&amp;#39;, &amp;#39;treatment&amp;#39;, &amp;#39;score&amp;#39;]) df    patient obs treatment score     0 1 1 0 strong   1 1 2 1 weak   2 1 3 0 normal   3 2 1 1 weak   4 2 2 0 strong     Create a function that converts all values of df[&#39;score&#39;] into numbers def score_to_numeric(x): if x==&amp;#39;strong&amp;#39;: return 3 if x==&amp;#39;normal&amp;#39;: return 2 if x==&amp;#39;weak&amp;#39;: return 1 Apply the function to the score variable df[&amp;#39;score_num&amp;#39;] = df[&amp;#39;score&amp;#39;].</description>
    </item>
    
    <item>
      <title>Convert A Variable To A Time Variable In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_convert_to_datetime/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_convert_to_datetime/</guid>
      <description># Import Preliminaries import pandas as pd# Create a dataset with the index being a set of names raw_data = {&amp;#39;date&amp;#39;: [&amp;#39;2014-06-01T01:21:38.004053&amp;#39;, &amp;#39;2014-06-02T01:21:38.004053&amp;#39;, &amp;#39;2014-06-03T01:21:38.004053&amp;#39;], &amp;#39;score&amp;#39;: [25, 94, 57]} df = pd.DataFrame(raw_data, columns = [&amp;#39;date&amp;#39;, &amp;#39;score&amp;#39;]) df    date score     0 2014-06-01T01:21:38.004053 25   1 2014-06-02T01:21:38.004053 94   2 2014-06-03T01:21:38.004053 57     # Transpose the dataset, so that the index (in this case the names) are columns df[&amp;#34;date&amp;#34;] = pd.</description>
    </item>
    
    <item>
      <title>Convert HTML Characters To Strings</title>
      <link>https://chrisalbon.com/python/basics/convert_html_symbols_to_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/convert_html_symbols_to_strings/</guid>
      <description>## Preliminariesimport html## Create Texttext = &amp;#39;This item costs &amp;amp;#165;400 or &amp;amp;#163;4.&amp;#39;## Convert To Stringhtml.unescape(text) &#39;This item costs 400 or 4.&#39;  ## Convert To HTML Entitieshtml.escape(text) &#39;This item costs &amp;amp;amp;#165;400 or &amp;amp;amp;#163;4.&#39;  </description>
    </item>
    
    <item>
      <title>Convert Pandas Categorical Data For Scikit-Learn</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/convert_pandas_categorical_column_into_integers_for_scikit-learn/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/convert_pandas_categorical_column_into_integers_for_scikit-learn/</guid>
      <description>Preliminaries # Import required packages from sklearn import preprocessing import pandas as pd Create DataFrame raw_data = {&amp;#39;patient&amp;#39;: [1, 1, 1, 2, 2], &amp;#39;obs&amp;#39;: [1, 2, 3, 1, 2], &amp;#39;treatment&amp;#39;: [0, 1, 0, 1, 0], &amp;#39;score&amp;#39;: [&amp;#39;strong&amp;#39;, &amp;#39;weak&amp;#39;, &amp;#39;normal&amp;#39;, &amp;#39;weak&amp;#39;, &amp;#39;strong&amp;#39;]} df = pd.DataFrame(raw_data, columns = [&amp;#39;patient&amp;#39;, &amp;#39;obs&amp;#39;, &amp;#39;treatment&amp;#39;, &amp;#39;score&amp;#39;]) Fit The Label Encoder # Create a label (category) encoder object le = preprocessing.LabelEncoder()# Fit the encoder to the pandas column le.</description>
    </item>
    
    <item>
      <title>Convert Strings To Dates</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/convert_strings_to_dates/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/convert_strings_to_dates/</guid>
      <description>Preliminaries # Load libraries import numpy as np import pandas as pd Create Strings # Create strings date_strings = np.array([&amp;#39;03-04-2005 11:35 PM&amp;#39;, &amp;#39;23-05-2010 12:01 AM&amp;#39;, &amp;#39;04-09-2009 09:09 PM&amp;#39;]) Convert Strings To Timestamps If errors=&amp;quot;coerce&amp;quot; then any problem will not raise an error (the default behavior) but instead will set the value causing the error to NaT (i.e. a missing value).
  Code Description Example   %Y Full year `2001`   %m Month w/ zero padding `04`   %d Day of the month w/ zero padding `09`   %I Hour (12hr clock) w/ zero padding `02`   %p AM or PM `AM`   %M Minute w/ zero padding `05`   %S Second w/ zero padding `09`   # Convert to datetimes [pd.</description>
    </item>
    
    <item>
      <title>Convert pandas Columns Time Zone</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/convert_pandas_column_timezone/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/convert_pandas_column_timezone/</guid>
      <description>Preliminaries # Load libraries import pandas as pd from pytz import all_timezones View Timezones # Show ten time zones all_timezones[0:10] [&#39;Africa/Abidjan&#39;, &#39;Africa/Accra&#39;, &#39;Africa/Addis_Ababa&#39;, &#39;Africa/Algiers&#39;, &#39;Africa/Asmara&#39;, &#39;Africa/Asmera&#39;, &#39;Africa/Bamako&#39;, &#39;Africa/Bangui&#39;, &#39;Africa/Banjul&#39;, &#39;Africa/Bissau&#39;]  Create pandas Series Of Dates # Create ten dates dates = pd.Series(pd.date_range(&amp;#39;2/2/2002&amp;#39;, periods=10, freq=&amp;#39;M&amp;#39;)) Add Time Zone Of pandas Series # Set time zone dates_with_abidjan_time_zone = dates.dt.tz_localize(&amp;#39;Africa/Abidjan&amp;#39;) # View pandas series dates_with_abidjan_time_zone 0 2002-02-28 00:00:00+00:00 1 2002-03-31 00:00:00+00:00 2 2002-04-30 00:00:00+00:00 3 2002-05-31 00:00:00+00:00 4 2002-06-30 00:00:00+00:00 5 2002-07-31 00:00:00+00:00 6 2002-08-31 00:00:00+00:00 7 2002-09-30 00:00:00+00:00 8 2002-10-31 00:00:00+00:00 9 2002-11-30 00:00:00+00:00 dtype: datetime64[ns, Africa/Abidjan]  Convert Time Zone Of pandas Series # Convert time zone dates_with_london_time_zone = dates_with_abidjan_time_zone.</description>
    </item>
    
    <item>
      <title>Converting A Dictionary Into A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/converting_a_dictionary_into_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/converting_a_dictionary_into_a_matrix/</guid>
      <description>Preliminaries # Load library from sklearn.feature_extraction import DictVectorizer Create Dictionary # Our dictionary of data data_dict = [{&amp;#39;Red&amp;#39;: 2, &amp;#39;Blue&amp;#39;: 4}, {&amp;#39;Red&amp;#39;: 4, &amp;#39;Blue&amp;#39;: 3}, {&amp;#39;Red&amp;#39;: 1, &amp;#39;Yellow&amp;#39;: 2}, {&amp;#39;Red&amp;#39;: 2, &amp;#39;Yellow&amp;#39;: 2}] Feature Matrix From Dictionary # Create DictVectorizer object dictvectorizer = DictVectorizer(sparse=False) # Convert dictionary into feature matrix features = dictvectorizer.fit_transform(data_dict) # View feature matrix features array([[ 4., 2., 0.], [ 3., 4., 0.], [ 0., 1., 2.</description>
    </item>
    
    <item>
      <title>Converting Strings To Datetime</title>
      <link>https://chrisalbon.com/python/basics/strings_to_datetime/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/strings_to_datetime/</guid>
      <description>Import modules from datetime import datetime from dateutil.parser import parse import pandas as pd Create a string variable with the war start time war_start = &amp;#39;2011-01-03&amp;#39; Convert the string to datetime format datetime.strptime(war_start, &amp;#39;%Y-%m-%d&amp;#39;) datetime.datetime(2011, 1, 3, 0, 0)  Create a list of strings as dates attack_dates = [&amp;#39;7/2/2011&amp;#39;, &amp;#39;8/6/2012&amp;#39;, &amp;#39;11/13/2013&amp;#39;, &amp;#39;5/26/2011&amp;#39;, &amp;#39;5/2/2001&amp;#39;] Convert attack_dates strings into datetime format [datetime.strptime(x, &amp;#39;%m/%d/%Y&amp;#39;) for x in attack_dates] [datetime.datetime(2011, 7, 2, 0, 0), datetime.</description>
    </item>
    
    <item>
      <title>Convolutional Neural Network</title>
      <link>https://chrisalbon.com/deep_learning/keras/convolutional_neural_network/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/convolutional_neural_network/</guid>
      <description>Preliminaries import numpy as np from keras.datasets import mnist from keras.models import Sequential from keras.layers import Dense, Dropout, Flatten from keras.layers.convolutional import Conv2D, MaxPooling2D from keras.utils import np_utils from keras import backend as K # Set that the color channel value will be first K.set_image_data_format(&amp;#39;channels_first&amp;#39;) # Set seed np.random.seed(0) Using TensorFlow backend.  Load MNIST Image Data # Set image information channels = 1 height = 28 width = 28 # Load data and target from MNIST data (train_data, train_target), (test_data, test_target) = mnist.</description>
    </item>
    
    <item>
      <title>Count Values In Pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_count_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_count_values/</guid>
      <description>Import the pandas module import pandas as pd Create all the columns of the dataframe as series year = pd.Series([1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894]) guardCorps = pd.Series([0,2,2,1,0,0,1,1,0,3,0,2,1,0,0,1,0,1,0,1]) corps1 = pd.Series([0,0,0,2,0,3,0,2,0,0,0,1,1,1,0,2,0,3,1,0]) corps2 = pd.Series([0,0,0,2,0,2,0,0,1,1,0,0,2,1,1,0,0,2,0,0]) corps3 = pd.Series([0,0,0,1,1,1,2,0,2,0,0,0,1,0,1,2,1,0,0,0]) corps4 = pd.Series([0,1,0,1,1,1,1,0,0,0,0,1,0,0,0,0,1,1,0,0]) corps5 = pd.Series([0,0,0,0,2,1,0,0,1,0,0,1,0,1,1,1,1,1,1,0]) corps6 = pd.Series([0,0,1,0,2,0,0,1,2,0,1,1,3,1,1,1,0,3,0,0]) corps7 = pd.Series([1,0,1,0,0,0,1,0,1,1,0,0,2,0,0,2,1,0,2,0]) corps8 = pd.Series([1,0,0,0,1,0,0,1,0,0,0,0,1,0,0,0,1,1,0,1]) corps9 = pd.Series([0,0,0,0,0,2,1,1,1,0,2,1,1,0,1,2,0,1,0,0]) corps10 = pd.</description>
    </item>
    
    <item>
      <title>Create A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_matrix/</guid>
      <description>Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 4], [2, 5]]) Note NumPy&amp;rsquo;s mat data structure is less flexible for our purposes and should be avoided.</description>
    </item>
    
    <item>
      <title>Create A New File Then Write To It</title>
      <link>https://chrisalbon.com/python/basics/create_a_new_file_and_the_write_to_it/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/create_a_new_file_and_the_write_to_it/</guid>
      <description>Create A New File And Write To It # Create a file if it doesn&amp;#39;t already exist with open(&amp;#39;file.txt&amp;#39;, &amp;#39;xt&amp;#39;) as f: # Write to the file f.write(&amp;#39;This file now exsits!&amp;#39;) # Close the connection to the file f.close() Open The File And Read It # Open the file with open(&amp;#39;file.txt&amp;#39;, &amp;#39;rt&amp;#39;) as f: # Read the data in the file data = f.read() # Close the connection to the file f.</description>
    </item>
    
    <item>
      <title>Create A Pipeline In Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_create_pipeline/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_create_pipeline/</guid>
      <description>Pandas&amp;rsquo; pipeline feature allows you to string together Python functions in order to build a pipeline of data processing.
Preliminaries import pandas as pd Create Dataframe # Create empty dataframe df = pd.DataFrame() # Create a column df[&amp;#39;name&amp;#39;] = [&amp;#39;John&amp;#39;, &amp;#39;Steve&amp;#39;, &amp;#39;Sarah&amp;#39;] df[&amp;#39;gender&amp;#39;] = [&amp;#39;Male&amp;#39;, &amp;#39;Male&amp;#39;, &amp;#39;Female&amp;#39;] df[&amp;#39;age&amp;#39;] = [31, 32, 19] # View dataframe df    name gender age     0 John Male 31   1 Steve Male 32   2 Sarah Female 19     Create Functions To Process Data # Create a function that def mean_age_by_group(dataframe, col): # groups the data by a column and returns the mean age per group return dataframe.</description>
    </item>
    
    <item>
      <title>Create A Range</title>
      <link>https://chrisalbon.com/scala/basics/create_a_range/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/create_a_range/</guid>
      <description> Create A Range 1 to 10 // Create a range between 1 and 10 1 to 10 Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)  Create A Range In An Array // Create an array between 1 and 10 and put in an array (1 to 10).toArray Array(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)  Use A Range In A For Loop // For each 1 in 1,2,3,4,5 for (i &amp;lt;- 1 to 10) // Print i  println(&amp;#34;index: &amp;#34;+ i) index: 1 index: 2 index: 3 index: 4 index: 5 index: 6 index: 7 index: 8 index: 9 index: 10  </description>
    </item>
    
    <item>
      <title>Create A Sparse Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_sparse_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_sparse_matrix/</guid>
      <description>Preliminaries # Load libraries import numpy as np from scipy import sparse Create Dense Matrix # Create a matrix matrix = np.array([[0, 0], [0, 1], [3, 0]]) Convert To Sparse Matrix # Create compressed sparse row (CSR) matrix matrix_sparse = sparse.csr_matrix(matrix) Note: There are many types of sparse matrices. In the example above we use CSR but the type we use should reflect our use case.</description>
    </item>
    
    <item>
      <title>Create A Temporary File</title>
      <link>https://chrisalbon.com/python/basics/create_a_temporary_file/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/create_a_temporary_file/</guid>
      <description>Preliminaries from tempfile import NamedTemporaryFile Create A Temporary File f = NamedTemporaryFile(&amp;#39;w+t&amp;#39;) Write To The Temp File # Write to the file, the output is the number of characters f.write(&amp;#39;Nobody lived on Deadweather but us and the pirates. It wasnt hard to understand why.&amp;#39;) 85  View The Tmp File&amp;rsquo;s Name f.name &#39;/var/folders/0b/pj3wsd750fjf8xzfb0n127w80000gn/T/tmphv1dkovx&#39;  Read The File # Go to the top of the file f.seek(0) # Read the file f.</description>
    </item>
    
    <item>
      <title>Create A Vector</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_vector/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/create_a_vector/</guid>
      <description> Preliminaries # Load library import numpy as np Create Row Vector # Create a vector as a row vector_row = np.array([1, 2, 3]) Create Column Vector # Create a vector as a column vector_column = np.array([[1], [2], [3]])</description>
    </item>
    
    <item>
      <title>Create A pandas Column With A For Loop</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_create_column_with_loop/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_create_column_with_loop/</guid>
      <description>Preliminaries import pandas as pd import numpy as np Create an example dataframe raw_data = {&amp;#39;student_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;test_score&amp;#39;: [76, 88, 84, 67, 53, 96, 64, 91, 77, 73, 52, np.NaN]} df = pd.DataFrame(raw_data, columns = [&amp;#39;student_name&amp;#39;, &amp;#39;test_score&amp;#39;]) Create a function to assign letter grades # Create a list to store the data grades = [] # For each row in the column, for row in df[&amp;#39;test_score&amp;#39;]: # if more than a value, if row &amp;gt; 95: # Append a letter grade grades.</description>
    </item>
    
    <item>
      <title>Create Baseline Classification Model</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/create_baseline_classification_model/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/create_baseline_classification_model/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import load_iris from sklearn.dummy import DummyClassifier from sklearn.model_selection import train_test_split Load Iris Flower Dataset # Load data iris = load_iris() # Create target vector and feature matrix X, y = iris.data, iris.target Split Data Into Training And Test Set # Split into training and test set X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) Create Dummy Regression Always Predicts The Mean Value Of Target # Create dummy classifer dummy = DummyClassifier(strategy=&amp;#39;uniform&amp;#39;, random_state=1) # &amp;#34;Train&amp;#34; model dummy.</description>
    </item>
    
    <item>
      <title>Create Baseline Regression Model</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/create_baseline_regression_model/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/create_baseline_regression_model/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import load_boston from sklearn.dummy import DummyRegressor from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler Load Boston Housing Dataset # Load data boston = load_boston() # Create features X, y = boston.data, boston.target Split Data Into Training And Test Set # Make test and training split X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0) Create Dummy Regression Always Predicts The Mean Value Of Target # Create a dummy regressor dummy_mean = DummyRegressor(strategy=&amp;#39;mean&amp;#39;) # &amp;#34;Train&amp;#34; dummy regressor dummy_mean.</description>
    </item>
    
    <item>
      <title>Create Counts Of Items</title>
      <link>https://chrisalbon.com/python/data_wrangling/creating_counts_of_items/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/creating_counts_of_items/</guid>
      <description>Preliminaries from collections import Counter Create A Counter # Create a counter of the fruits eaten today fruit_eaten = Counter([&amp;#39;Apple&amp;#39;, &amp;#39;Apple&amp;#39;, &amp;#39;Apple&amp;#39;, &amp;#39;Banana&amp;#39;, &amp;#39;Pear&amp;#39;, &amp;#39;Pineapple&amp;#39;]) # View counter fruit_eaten Counter({&#39;Apple&#39;: 3, &#39;Banana&#39;: 1, &#39;Pear&#39;: 1, &#39;Pineapple&#39;: 1})  Update The Count For An Element # Update the count for &amp;#39;Pineapple&amp;#39; (because you just ate an pineapple) fruit_eaten.update([&amp;#39;Pineapple&amp;#39;]) # View the counter fruit_eaten Counter({&#39;Apple&#39;: 3, &#39;Banana&#39;: 1, &#39;Pear&#39;: 1, &#39;Pineapple&#39;: 2})  View The Items With The Highest Counts # View the items with the top 3 counts fruit_eaten.</description>
    </item>
    
    <item>
      <title>Create Interaction Features</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/create_interaction_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/create_interaction_features/</guid>
      <description> Preliminaries # Load libraries from sklearn.preprocessing import PolynomialFeatures import numpy as np Create Feature Matrix # Create feature matrix X = np.array([[2, 3], [2, 3], [2, 3]]) Add Interaction Features # Create PolynomialFeatures object with interaction_only set to True interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False) # Transform feature matrix interaction.fit_transform(X) array([[ 2., 3., 6.], [ 2., 3., 6.], [ 2., 3., 6.]])  </description>
    </item>
    
    <item>
      <title>Create a Column Based on a Conditional in pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_create_column_using_conditional/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_create_column_using_conditional/</guid>
      <description>Preliminaries # Import required modules import pandas as pd import numpy as np Make a dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(data, columns = [&amp;#39;name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    name age preTestScore postTestScore     0 Jason 42 4 25   1 Molly 52 24 94   2 Tina 36 31 57   3 Jake 24 2 62   4 Amy 73 3 70     Add a new column for elderly # Create a new column called df.</description>
    </item>
    
    <item>
      <title>Creating A Time Series Plot With Seaborn And pandas</title>
      <link>https://chrisalbon.com/python/data_visualization/seaborn_pandas_timeseries_plot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/seaborn_pandas_timeseries_plot/</guid>
      <description>Preliminaries import pandas as pd %matplotlib inline import matplotlib.pyplot as plt import seaborn as snsdata = {&amp;#39;date&amp;#39;: [&amp;#39;2014-05-01 18:47:05.069722&amp;#39;, &amp;#39;2014-05-01 18:47:05.119994&amp;#39;, &amp;#39;2014-05-02 18:47:05.178768&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.280592&amp;#39;, &amp;#39;2014-05-03 18:47:05.332662&amp;#39;, &amp;#39;2014-05-03 18:47:05.385109&amp;#39;, &amp;#39;2014-05-04 18:47:05.436523&amp;#39;, &amp;#39;2014-05-04 18:47:05.486877&amp;#39;], &amp;#39;deaths_regiment_1&amp;#39;: [34, 43, 14, 15, 15, 14, 31, 25, 62, 41], &amp;#39;deaths_regiment_2&amp;#39;: [52, 66, 78, 15, 15, 5, 25, 25, 86, 1], &amp;#39;deaths_regiment_3&amp;#39;: [13, 73, 82, 58, 52, 87, 26, 5, 56, 75], &amp;#39;deaths_regiment_4&amp;#39;: [44, 75, 26, 15, 15, 14, 54, 25, 24, 72], &amp;#39;deaths_regiment_5&amp;#39;: [25, 24, 25, 15, 57, 68, 21, 27, 62, 5], &amp;#39;deaths_regiment_6&amp;#39;: [84, 84, 26, 15, 15, 14, 26, 25, 62, 24], &amp;#39;deaths_regiment_7&amp;#39;: [46, 57, 26, 15, 15, 14, 26, 25, 62, 41]} df = pd.</description>
    </item>
    
    <item>
      <title>Creating Lists From Dictionary Keys And Values</title>
      <link>https://chrisalbon.com/python/data_wrangling/create_list_from_dictionary_keys_and_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/create_list_from_dictionary_keys_and_values/</guid>
      <description> Create a dictionary dict = {&amp;#39;county&amp;#39;: [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;fireReports&amp;#39;: [4, 24, 31, 2, 3]} Create a list from the dictionary keys # Create a list of keys list(dict.keys()) [&#39;fireReports&#39;, &#39;year&#39;, &#39;county&#39;]  Create a list from the dictionary values # Create a list of values list(dict.values()) [[4, 24, 31, 2, 3], [2012, 2012, 2013, 2014, 2014], [&#39;Cochice&#39;, &#39;Pima&#39;, &#39;Santa Cruz&#39;, &#39;Maricopa&#39;, &#39;Yuma&#39;]]  </description>
    </item>
    
    <item>
      <title>Creating Scatterplots With Seaborn</title>
      <link>https://chrisalbon.com/python/data_visualization/seaborn_scatterplot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/seaborn_scatterplot/</guid>
      <description>Preliminaries import pandas as pd %matplotlib inline import random import matplotlib.pyplot as plt import seaborn as sns Create data # Create empty dataframe df = pd.DataFrame() # Add columns df[&amp;#39;x&amp;#39;] = random.sample(range(1, 1000), 5) df[&amp;#39;y&amp;#39;] = random.sample(range(1, 1000), 5) df[&amp;#39;z&amp;#39;] = [1,0,0,1,0] df[&amp;#39;k&amp;#39;] = [&amp;#39;male&amp;#39;,&amp;#39;male&amp;#39;,&amp;#39;male&amp;#39;,&amp;#39;female&amp;#39;,&amp;#39;female&amp;#39;]# View first few rows of data df.head()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .</description>
    </item>
    
    <item>
      <title>Cropping Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/cropping_images/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/cropping_images/</guid>
      <description> Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Crop Image # Select first half of the columns and all rows image_cropped = image[:,:126] View Image # View image plt.imshow(image_cropped, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() </description>
    </item>
    
    <item>
      <title>Cross Validation Pipeline</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_pipeline/</guid>
      <description>The code below does a lot in only a few lines. To help explain things, here are the steps that code is doing:
 Split the raw data into three folds. Select one for testing and two for training. Preprocess the data by scaling the training features. Train a support vector classifier on the training data. Apply the classifier to the test data. Record the accuracy score. Repeat steps 1-5 two more times, once for each fold.</description>
    </item>
    
    <item>
      <title>Cross Validation With Parameter Tuning Using Grid Search</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_parameter_tuning_grid_search/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/cross_validation_parameter_tuning_grid_search/</guid>
      <description>In machine learning, two tasks are commonly done at the same time in data pipelines: cross validation and (hyper)parameter tuning. Cross validation is the process of training learners using one set of data and testing it using a different set. Parameter tuning is the process to selecting the values for a model&amp;rsquo;s parameters that maximize the accuracy of the model.
In this tutorial we work through an example which combines cross validation and parameter tuning using scikit-learn.</description>
    </item>
    
    <item>
      <title>Cross-Validation</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/cross-validaton/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/cross-validaton/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn import datasets from sklearn import metrics from sklearn.model_selection import KFold, cross_val_score from sklearn.pipeline import make_pipeline from sklearn.linear_model import LogisticRegression from sklearn.preprocessing import StandardScaler Load Digits Dataset # Load the digits dataset digits = datasets.load_digits() # Create the features matrix X = digits.data # Create the target vector y = digits.target Create Pipeline # Create standardizer standardizer = StandardScaler() # Create logistic regression logit = LogisticRegression() # Create a pipeline that standardizes, then runs logistic regression pipeline = make_pipeline(standardizer, logit) Create k-Fold Cross-Validation # Create k-Fold cross-validation kf = KFold(n_splits=10, shuffle=True, random_state=1) Conduct k-Fold Cross-Validation # Do k-fold cross-validation cv_results = cross_val_score(pipeline, # Pipeline X, # Feature matrix y, # Target vector cv=kf, # Cross-validation technique scoring=&amp;#34;accuracy&amp;#34;, # Loss function n_jobs=-1) # Use all CPU scores Calculate Mean Performance Score # Calculate mean cv_results.</description>
    </item>
    
    <item>
      <title>Crosstabs In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_crosstabs/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_crosstabs/</guid>
      <description>Import pandas import pandas as pdraw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;infantry&amp;#39;, &amp;#39;infantry&amp;#39;, &amp;#39;cavalry&amp;#39;, &amp;#39;cavalry&amp;#39;, &amp;#39;infantry&amp;#39;, &amp;#39;infantry&amp;#39;, &amp;#39;cavalry&amp;#39;, &amp;#39;cavalry&amp;#39;,&amp;#39;infantry&amp;#39;, &amp;#39;infantry&amp;#39;, &amp;#39;cavalry&amp;#39;, &amp;#39;cavalry&amp;#39;], &amp;#39;experience&amp;#39;: [&amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;, &amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;, &amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;, &amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;,&amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;, &amp;#39;veteran&amp;#39;, &amp;#39;rookie&amp;#39;], &amp;#39;name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]} df = pd.</description>
    </item>
    
    <item>
      <title>Custom Performance Metric</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/custom_performance_metric/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/custom_performance_metric/</guid>
      <description>Preliminaries # Load libraries from sklearn.metrics import make_scorer, r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import Ridge from sklearn.datasets import make_regression Create Feature # Generate features matrix and target vector X, y = make_regression(n_samples = 100, n_features = 3, random_state = 1) # Create training set and test set X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=1) Train model # Create ridge regression object classifier = Ridge() # Train ridge regression model model = classifier.</description>
    </item>
    
    <item>
      <title>DBSCAN Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/dbscan_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/dbscan_clustering/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.cluster import DBSCAN Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Conduct DBSCAN Clustering DBSCAN has three main parameters to set:
 eps: The maximum distance from an observation for another observation to be considered its neighbor. min_samples: The minimum number of observation less than eps distance from an observation for to be considered a core observation.</description>
    </item>
    
    <item>
      <title>Data Structure Basics</title>
      <link>https://chrisalbon.com/python/basics/data_structure_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/data_structure_basics/</guid>
      <description>Lists &amp;ldquo;A list is a data structure that holds an ordered collection of items i.e. you can store a sequence of items in a list.&amp;rdquo; - A Byte Of Python
Lists are mutable.
# Create a list of countries, then print the results allies = [&amp;#39;USA&amp;#39;,&amp;#39;UK&amp;#39;,&amp;#39;France&amp;#39;,&amp;#39;New Zealand&amp;#39;, &amp;#39;Australia&amp;#39;,&amp;#39;Canada&amp;#39;,&amp;#39;Poland&amp;#39;]; allies [&#39;USA&#39;, &#39;UK&#39;, &#39;France&#39;, &#39;New Zealand&#39;, &#39;Australia&#39;, &#39;Canada&#39;, &#39;Poland&#39;]  # Print the length of the list len(allies) 7  # Add an item to the list, then print the results allies.</description>
    </item>
    
    <item>
      <title>Date And Time Basics</title>
      <link>https://chrisalbon.com/python/basics/date_and_time_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/date_and_time_basics/</guid>
      <description># Import modules from datetime import datetime from datetime import timedelta# Create a variable with the current time now = datetime.now() now datetime.datetime(2014, 5, 11, 20, 5, 11, 688051)  # The current year now.year 2014  # The current month now.month 5  # The current day now.day 11  # The current hour now.hour 20  # The current minute now.minute 5  # The difference between two dates delta = datetime(2011, 1, 7) - datetime(2011, 1, 6) delta datetime.</description>
    </item>
    
    <item>
      <title>Decision Tree Classifier</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/decision_tree_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/decision_tree_classifier/</guid>
      <description>Preliminaries # Load libraries from sklearn.tree import DecisionTreeClassifier from sklearn import datasets Load Iris Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Decision Tree Using Gini Impurity # Create decision tree classifer object using gini clf = DecisionTreeClassifier(criterion=&amp;#39;gini&amp;#39;, random_state=0) Train Model # Train model model = clf.fit(X, y) Create Observation To Predict # Make new observation observation = [[ 5, 4, 3, 2]] Predict Observation # Predict observation&amp;#39;s class  model.</description>
    </item>
    
    <item>
      <title>Decision Tree Regression</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/decision_tree_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/decision_tree_regression/</guid>
      <description>Preliminaries # Load libraries from sklearn.tree import DecisionTreeRegressor from sklearn import datasets Load Boston Housing Dataset # Load data with only two features boston = datasets.load_boston() X = boston.data[:,0:2] y = boston.target Create Decision Tree Decision tree regression works similar to decision tree classification, however instead of reducing Gini impurity or entropy, potential splits are measured on how much they reduce the mean squared error (MSE):
$$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$$</description>
    </item>
    
    <item>
      <title>Delete Duplicates In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_delete_duplicates/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_delete_duplicates/</guid>
      <description>import modules import pandas as pd Create dataframe with duplicates raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Jason&amp;#39;, &amp;#39;Jason&amp;#39;,&amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Miller&amp;#39;, &amp;#39;Miller&amp;#39;,&amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 42, 1111111, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 4, 4, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 25, 25, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .</description>
    </item>
    
    <item>
      <title>Delete Observations With Missing Values</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/delete_observations_with_missing_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/delete_observations_with_missing_values/</guid>
      <description> Preliminaries # Load libraries import numpy as np import pandas as pd Create Feature Matrix # Create feature matrix X = np.array([[1.1, 11.1], [2.2, 22.2], [3.3, 33.3], [4.4, 44.4], [np.nan, 55]]) Delete Observations With Missing Values # Remove observations with missing values X[~np.isnan(X).any(axis=1)] array([[ 1.1, 11.1], [ 2.2, 22.2], [ 3.3, 33.3], [ 4.4, 44.4]])  </description>
    </item>
    
    <item>
      <title>Deleting Missing Values</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/deleting_missing_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/deleting_missing_values/</guid>
      <description>Preliminaries # Load library import numpy as np import pandas as pd Create Data Frame # Create feature matrix X = np.array([[1, 2], [6, 3], [8, 4], [9, 5], [np.nan, 4]]) Drop Missing Values Using NumPy # Remove observations with missing values X[~np.isnan(X).any(axis=1)] array([[ 1., 2.], [ 6., 3.], [ 8., 4.], [ 9., 5.]])  Drop Missing Values Using pandas # Load data as a data frame df = pd.</description>
    </item>
    
    <item>
      <title>Demonstrate The Central Limit Theorem</title>
      <link>https://chrisalbon.com/statistics/frequentist/demonstrate_the_central_limit_theorem/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/demonstrate_the_central_limit_theorem/</guid>
      <description>Preliminaries # Import packages import pandas as pd import numpy as np # Set matplotlib as inline %matplotlib inline  Create Population Data From Non-Normal Distribution # Create an empty dataframe population = pd.DataFrame() # Create an column that is 10000 random numbers drawn from a uniform distribution population[&amp;#39;numbers&amp;#39;] = np.random.uniform(0,10000,size=10000)# Plot a histogram of the score data. # This confirms the data is not a normal distribution. population[&amp;#39;numbers&amp;#39;].hist(bins=100) &amp;lt;matplotlib.</description>
    </item>
    
    <item>
      <title>Describe An Array</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/describe_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/describe_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) View Shape # View number of rows and columns matrix.shape (3, 4)  View Total Elements # View number of elements (rows * columns) matrix.size 12  View Number Of Dimensions # View number of dimensions matrix.ndim 2  </description>
    </item>
    
    <item>
      <title>Descriptive Statistics For pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_descriptive_stats/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_descriptive_stats/</guid>
      <description>Import modules import pandas as pd Create dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(data, columns = [&amp;#39;name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df   name age preTestScore postTestScore     0  Jason  42  4  25   1  Molly  52  24  94   2  Tina  36  31  57   3  Jake  24  2  62   4  Amy  73  3  70    5 rows  4 columns</description>
    </item>
    
    <item>
      <title>Detect Edges</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/detect_edges/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/detect_edges/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load image # Load image as greyscale image_gray = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Detect Edges # Calculate median intensity median_intensity = np.median(image_gray) # Set thresholds to be one standard deviation above and below median intensity lower_threshold = int(max(0, (1.0 - 0.33) * median_intensity)) upper_threshold = int(min(255, (1.0 + 0.33) * median_intensity)) # Apply canny edge detector image_canny = cv2.</description>
    </item>
    
    <item>
      <title>Detecting Outliers</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/detecting_outliers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/detecting_outliers/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn.covariance import EllipticEnvelope from sklearn.datasets import make_blobs Create Data # Create simulated data X, _ = make_blobs(n_samples = 10, n_features = 2, centers = 1, random_state = 1) # Replace the first observation&amp;#39;s values with extreme values X[0,0] = 10000 X[0,1] = 10000 Detect Outliers EllipticEnvelope assumes the data is normally distributed and based on that assumption &amp;ldquo;draws&amp;rdquo; an ellipse around the data, classifying any observation inside the ellipse as an inlier (labeled as 1) and any observation outside the ellipse as an outlier (labeled as -1).</description>
    </item>
    
    <item>
      <title>Dictionary Basics</title>
      <link>https://chrisalbon.com/python/basics/dictionary_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/dictionary_basics/</guid>
      <description>Basics  Not sequences, but mappings. That is, stored by key, not relative position. Dictionaries are mutable.  Build a dictionary via brackets unef_org = {&amp;#39;name&amp;#39; : &amp;#39;UNEF&amp;#39;, &amp;#39;staff&amp;#39; : 32, &amp;#39;url&amp;#39; : &amp;#39;http://unef.org&amp;#39;} View the variable unef_org {&#39;name&#39;: &#39;UNEF&#39;, &#39;staff&#39;: 32, &#39;url&#39;: &#39;http://unef.org&#39;}  Build a dict via keys who_org = {} who_org[&amp;#39;name&amp;#39;] = &amp;#39;WHO&amp;#39; who_org[&amp;#39;staff&amp;#39;] = &amp;#39;10&amp;#39; who_org[&amp;#39;url&amp;#39;] = &amp;#39;http://who.org&amp;#39; View the variable who_org {&#39;name&#39;: &#39;WHO&#39;, &#39;staff&#39;: &#39;10&#39;, &#39;url&#39;: &#39;http://who.</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction On Sparse Feature Matrix</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_on_sparse_feature_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_on_sparse_feature_matrix/</guid>
      <description>Preliminaries # Load libraries from sklearn.preprocessing import StandardScaler from sklearn.decomposition import TruncatedSVD from scipy.sparse import csr_matrix from sklearn import datasets import numpy as np Load Digits Data And Make Sparse # Load the data digits = datasets.load_digits() # Standardize the feature matrix X = StandardScaler().fit_transform(digits.data) # Make sparse matrix X_sparse = csr_matrix(X) Create Truncated Singular Value Decomposition # Create a TSVD tsvd = TruncatedSVD(n_components=10) Run Truncated Singular Value Decomposition # Conduct TSVD on sparse matrix X_sparse_tsvd = tsvd.</description>
    </item>
    
    <item>
      <title>Dimensionality Reduction With Kernel PCA</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_with_kernel_pca/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_with_kernel_pca/</guid>
      <description> 
Preliminaries # Load libraries from sklearn.decomposition import PCA, KernelPCA from sklearn.datasets import make_circles Create Linearly Inseparable Data # Create linearly inseparable data X, _ = make_circles(n_samples=1000, random_state=1, noise=0.1, factor=0.1) Conduct Kernel PCA # Apply kernal PCA with radius basis function (RBF) kernel kpca = KernelPCA(kernel=&amp;#34;rbf&amp;#34;, gamma=15, n_components=1) X_kpca = kpca.fit_transform(X) View Results print(&amp;#39;Original number of features:&amp;#39;, X.shape[1]) print(&amp;#39;Reduced number of features:&amp;#39;, X_kpca.shape[1]) Original number of features: 2 Reduced number of features: 1  </description>
    </item>
    
    <item>
      <title>Dimensionality Reduction With PCA</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_with_pca/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/dimensionality_reduction_with_pca/</guid>
      <description>Preliminaries # Load libraries from sklearn.preprocessing import StandardScaler from sklearn.decomposition import PCA from sklearn import datasets Load Data # Load the data digits = datasets.load_digits() Standardize Feature Values # Standardize the feature matrix X = StandardScaler().fit_transform(digits.data) Conduct Principal Component Analysis # Create a PCA that will retain 99% of the variance pca = PCA(n_components=0.99, whiten=True) # Conduct PCA X_pca = pca.fit_transform(X) View Results # Show results print(&amp;#39;Original number of features:&amp;#39;, X.</description>
    </item>
    
    <item>
      <title>Discretize Features</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/discretize_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/discretize_features/</guid>
      <description> Preliminaries # Load libraries from sklearn.preprocessing import Binarizer import numpy as np Create Data # Create feature age = np.array([[6], [12], [20], [36], [65]]) Option 1: Binarize Feature # Create binarizer binarizer = Binarizer(18) # Transform feature binarizer.fit_transform(age) array([[0], [0], [1], [1], [1]])  Option 2: Break Up Feature Into Bins # Bin feature np.digitize(age, bins=[20,30,64]) array([[0], [0], [1], [2], [3]])  </description>
    </item>
    
    <item>
      <title>Display JSON</title>
      <link>https://chrisalbon.com/python/basics/display_json/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/display_json/</guid>
      <description>Preliminary # Import library import json Create String With JSON Data _string = &amp;#39;{&amp;#34;data&amp;#34;: {&amp;#34;title&amp;#34;: &amp;#34;Machine Learning With Python Cookbook&amp;#34;,&amp;#34;author&amp;#34;: {&amp;#34;name&amp;#34;: &amp;#34;Chris Albon&amp;#34;,&amp;#34;biography&amp;#34;: {&amp;#34;eduation&amp;#34;: {&amp;#34;phd&amp;#34;: &amp;#34;UC Davis&amp;#34;,&amp;#34;masters&amp;#34;: &amp;#34;UC Davis&amp;#34;,&amp;#34;undergraduate&amp;#34;: &amp;#34;Univ. Of Miami&amp;#34;,&amp;#34;acronym&amp;#34;: &amp;#34;CRA&amp;#34;,&amp;#34;full name&amp;#34;: &amp;#34;Christopher Albon&amp;#34;,&amp;#34;favorites&amp;#34;: {&amp;#34;food&amp;#34;: &amp;#34;Steak&amp;#34;,&amp;#34;sport&amp;#34;: [&amp;#34;baseball&amp;#34;, &amp;#34;basketball&amp;#34;]},&amp;#34;dissertation&amp;#34;: &amp;#34;Health Systems During And After Civil WarS&amp;#34;}}}}}&amp;#39; Convert String To JSON json_data = json.loads(_string) Display JSON print(json.dumps(json_data, indent=2)) { &amp;quot;data&amp;quot;: { &amp;quot;title&amp;quot;: &amp;quot;Machine Learning With Python Cookbook&amp;quot;, &amp;quot;author&amp;quot;: { &amp;quot;name&amp;quot;: &amp;quot;Chris Albon&amp;quot;, &amp;quot;biography&amp;quot;: { &amp;quot;eduation&amp;quot;: { &amp;quot;phd&amp;quot;: &amp;quot;UC Davis&amp;quot;, &amp;quot;masters&amp;quot;: &amp;quot;UC Davis&amp;quot;, &amp;quot;undergraduate&amp;quot;: &amp;quot;Univ.</description>
    </item>
    
    <item>
      <title>Display Scientific Notation As Floats</title>
      <link>https://chrisalbon.com/python/basics/display_scientific_notation_as_floats/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/display_scientific_notation_as_floats/</guid>
      <description>Create Values # Create a numbers in scientific notation value_scientific_notation = 6.32000000e-03 # Create a vector of numbers in scientific notation vector_scientific_notation = [6.32000000e-03, 1.80000000e+01, 2.31000000e+00, 0.00000000e+00, 5.38000000e-01, 6.57500000e+00, 6.52000000e+01, 4.09000000e+00, 1.00000000e+00, 2.96000000e+02, 1.53000000e+01, 3.96900000e+02, 4.98000000e+00] Display Values As Floats # Display value as a float &amp;#39;{:f}&amp;#39;.format(value_scientific_notation) &#39;0.006320&#39;  # Display vector values as floats [&amp;#39;{:f}&amp;#39;.format(x) for x in vector_scientific_notation] [&#39;0.006320&#39;, &#39;18.000000&#39;, &#39;2.310000&#39;, &#39;0.000000&#39;, &#39;0.538000&#39;, &#39;6.575000&#39;, &#39;65.200000&#39;, &#39;4.090000&#39;, &#39;1.000000&#39;, &#39;296.</description>
    </item>
    
    <item>
      <title>Drilling Down With Beautiful Soup</title>
      <link>https://chrisalbon.com/python/web_scraping/beautiful_soup_drill_down/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/web_scraping/beautiful_soup_drill_down/</guid>
      <description>Preliminaries # Import required modules import requests from bs4 import BeautifulSoup import pandas as pd Download the HTML and create a Beautiful Soup object # Create a variable with the URL to this tutorial url = &amp;#39;http://en.wikipedia.org/wiki/List_of_A_Song_of_Ice_and_Fire_characters&amp;#39; # Scrape the HTML at the url r = requests.get(url) # Turn the HTML into a Beautiful Soup object soup = BeautifulSoup(r.text, &amp;#34;lxml&amp;#34;) If we looked at the soup object, we&amp;rsquo;d see that the names we want are in a heirarchical list.</description>
    </item>
    
    <item>
      <title>Drop Highly Correlated Features</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/drop_highly_correlated_features/</guid>
      <description>Preliminaries # Load libraries import pandas as pd import numpy as np Load Data # Create feature matrix with two highly correlated features X = np.array([[1, 1, 1], [2, 2, 0], [3, 3, 1], [4, 4, 0], [5, 5, 1], [6, 6, 0], [7, 7, 1], [8, 7, 0], [9, 7, 1]]) # Convert feature matrix into DataFrame df = pd.DataFrame(X) # View the data frame df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .</description>
    </item>
    
    <item>
      <title>Dropping Rows And Columns In pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/</guid>
      <description>Import modules import pandas as pd Create a dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    name reports year     Cochice Jason 4 2012   Pima Molly 24 2012   Santa Cruz Tina 31 2013   Maricopa Jake 2 2014   Yuma Amy 3 2014     Drop an observation (row) df.</description>
    </item>
    
    <item>
      <title>Effect Of Alpha On Lasso Regression</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/effect_of_alpha_on_lasso_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/effect_of_alpha_on_lasso_regression/</guid>
      <description>Often we want conduct a process called regularization, wherein we penalize the number of features in a model in order to only keep the most important features. This can be particularly important when you have a dataset with 100,000+ features.
Lasso regression is a common modeling technique to do regularization. The math behind it is pretty interesting, but practically, what you need to know is that Lasso regression comes with a parameter, alpha, and the higher the alpha, the most feature coefficients are zero.</description>
    </item>
    
    <item>
      <title>Encode Days Of The Week</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/encode_days_of_the_week/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/encode_days_of_the_week/</guid>
      <description> Preliminaries # Load library import pandas as pd Create Date And Time Data # Create dates dates = pd.Series(pd.date_range(&amp;#39;2/2/2002&amp;#39;, periods=3, freq=&amp;#39;M&amp;#39;)) # View data dates 0 2002-02-28 1 2002-03-31 2 2002-04-30 dtype: datetime64[ns]  Show Days Of The Week # Show days of the week dates.dt.weekday_name 0 Thursday 1 Sunday 2 Tuesday dtype: object  </description>
    </item>
    
    <item>
      <title>Encoding Ordinal Categorical Features</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/encoding_ordinal_categorical_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/encoding_ordinal_categorical_features/</guid>
      <description>Preliminaries # Load library import pandas as pd Create Feature Matrix # Create features df = pd.DataFrame({&amp;#39;Score&amp;#39;: [&amp;#39;Low&amp;#39;, &amp;#39;Low&amp;#39;, &amp;#39;Medium&amp;#39;, &amp;#39;Medium&amp;#39;, &amp;#39;High&amp;#39;]}) # View data frame df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    Score     0 Low   1 Low   2 Medium   3 Medium   4 High     Create Scale Map # Create mapper scale_mapper = {&amp;#39;Low&amp;#39;:1, &amp;#39;Medium&amp;#39;:2, &amp;#39;High&amp;#39;:3} Map Scale To Features # Map feature values to scale df[&amp;#39;Scale&amp;#39;] = df[&amp;#39;Score&amp;#39;].</description>
    </item>
    
    <item>
      <title>Enhance Contrast Of Color Image</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/enhance_contrast_of_color_image/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/enhance_contrast_of_color_image/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image # Load image image_bgr = cv2.imread(&amp;#39;images/plane.jpg&amp;#39;) Convert Image To YUV Color Format # Convert to YUV image_yuv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2YUV) Enhance Image # Apply histogram equalization image_yuv[:, :, 0] = cv2.equalizeHist(image_yuv[:, :, 0]) Convert To RGB # Convert to RGB image_rgb = cv2.cvtColor(image_yuv, cv2.COLOR_YUV2RGB) View Image # Show image plt.imshow(image_rgb), plt.axis(&amp;#34;off&amp;#34;) plt.</description>
    </item>
    
    <item>
      <title>Enhance Contrast Of Greyscale Image</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/enhance_contrast_of_greyscale_image/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/enhance_contrast_of_greyscale_image/</guid>
      <description> Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Enhance Image # Enhance image image_enhanced = cv2.equalizeHist(image) View Image # Show image plt.imshow(image_enhanced, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() </description>
    </item>
    
    <item>
      <title>Enumerate A List</title>
      <link>https://chrisalbon.com/python/data_wrangling/enumerate_a_list/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/enumerate_a_list/</guid>
      <description># Create a list of strings data = [&amp;#39;One&amp;#39;,&amp;#39;Two&amp;#39;,&amp;#39;Three&amp;#39;,&amp;#39;Four&amp;#39;,&amp;#39;Five&amp;#39;]# For each item in the enumerated variable, data for item in enumerate(data): # Print the whole enumerated element print(item) # Print only the value (not the index number) print(item[1]) (0, &#39;One&#39;) One (1, &#39;Two&#39;) Two (2, &#39;Three&#39;) Three (3, &#39;Four&#39;) Four (4, &#39;Five&#39;) Five  </description>
    </item>
    
    <item>
      <title>Evaluating Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/evaluating_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/evaluating_clustering/</guid>
      <description>Preliminaries import numpy as np from sklearn.metrics import silhouette_score from sklearn import datasets from sklearn.cluster import KMeans from sklearn.datasets import make_blobs Create Feature Data # Generate feature matrix X, _ = make_blobs(n_samples = 1000, n_features = 10, centers = 2, cluster_std = 0.5, shuffle = True, random_state = 1) Cluster Observations # Cluster data using k-means to predict classes model = KMeans(n_clusters=2, random_state=1).fit(X) # Get predicted classes y_hat = model.</description>
    </item>
    
    <item>
      <title>Exiting A Loop</title>
      <link>https://chrisalbon.com/python/basics/exiting_a_loop/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/exiting_a_loop/</guid>
      <description>Create A List # Create a list: armies = [&amp;#39;Red Army&amp;#39;, &amp;#39;Blue Army&amp;#39;, &amp;#39;Green Army&amp;#39;] Breaking Out Of A For Loop for army in armies: print(army) if army == &amp;#39;Blue Army&amp;#39;: print(&amp;#39;Blue Army Found! Stopping.&amp;#39;) break Red Army Blue Army Blue Army Found! Stopping.  Notice that the loop stopped after the conditional if statement was satisfied.
Exiting If Loop Completed A loop will exit when completed, but using an else statement we can add an action at the conclusion of the loop if it hasn&amp;rsquo;t been exited earlier.</description>
    </item>
    
    <item>
      <title>Expand Cells Containing Lists Into Their Own Variables In Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_expand_cells_containing_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_expand_cells_containing_lists/</guid>
      <description># import pandas import pandas as pd# create a dataset raw_data = {&amp;#39;score&amp;#39;: [1,2,3], &amp;#39;tags&amp;#39;: [[&amp;#39;apple&amp;#39;,&amp;#39;pear&amp;#39;,&amp;#39;guava&amp;#39;],[&amp;#39;truck&amp;#39;,&amp;#39;car&amp;#39;,&amp;#39;plane&amp;#39;],[&amp;#39;cat&amp;#39;,&amp;#39;dog&amp;#39;,&amp;#39;mouse&amp;#39;]]} df = pd.DataFrame(raw_data, columns = [&amp;#39;score&amp;#39;, &amp;#39;tags&amp;#39;]) # view the dataset df    score tags     0 1 [apple, pear, guava]   1 2 [truck, car, plane]   2 3 [cat, dog, mouse]     # expand df.tags into its own dataframe tags = df[&amp;#39;tags&amp;#39;].apply(pd.Series) # rename each variable is tags tags = tags.</description>
    </item>
    
    <item>
      <title>Extract Substrings Using Regex</title>
      <link>https://chrisalbon.com/scala/basics/extract_substring_using_regex/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/extract_substring_using_regex/</guid>
      <description> Create String // Create a string value val text: String = &amp;#34;27 aircraft&amp;#34; Create Regex Pattern // Create a regex with two pattern matches (one number and one word) val pattern = &amp;#34;([0-9]+) ([A-Za-z]+)&amp;#34;.r Extract Substrings That Match Regex // Apply the regex pattern such that each of the two pattern matches is assigned to a separate value val pattern(vehicle_number, vehicle_type) = text View Output // View the value vehicle_number 27  // View the value vehicle_type aircraft  </description>
    </item>
    
    <item>
      <title>F1 Score</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/f1_score/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/f1_score/</guid>
      <description>Preliminaries # Load libraries from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification Generate Features And Target Data # Generate features matrix and target vector X, y = make_classification(n_samples = 10000, n_features = 3, n_informative = 3, n_redundant = 0, n_classes = 2, random_state = 1) Create Logistic Regression # Create logistic regression logit = LogisticRegression() Cross-Validate Model Using F1 # Cross-validate model using precision cross_val_score(logit, X, y, scoring=&amp;#34;f1&amp;#34;) array([ 0.</description>
    </item>
    
    <item>
      <title>Fast C Hyperparameter Tuning</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/fast_c_hyperparameter_tuning/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/fast_c_hyperparameter_tuning/</guid>
      <description>Sometimes the characteristics of a learning algorithm allows us to search for the best hyperparameters significantly faster than either brute force or randomized model search methods.
scikit-learn&amp;rsquo;s LogisticRegressionCV method includes a parameter Cs. If supplied a list, Cs is the candidate hyperparameter values to select from. If supplied a integer, Cs a list of that many candidate values will is drawn from a logarithmic scale between 0.0001 and and 10000 (a range of reasonable values for C).</description>
    </item>
    
    <item>
      <title>Feature Extraction With PCA</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/feature_extraction_with_pca/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/feature_extraction_with_pca/</guid>
      <description>Principle Component Analysis (PCA) is a common feature extraction method in data science. Technically, PCA finds the eigenvectors of a covariance matrix with the highest eigenvalues and then uses those to project the data into a new subspace of equal or less dimensions. Practically, PCA converts a matrix of n features into a new dataset of (hopefully) less than n features. That is, it reduces the number of features by constructing a new, smaller number variables which capture a signficant portion of the information found in the original features.</description>
    </item>
    
    <item>
      <title>Feature Importance</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/feature_importance/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/feature_importance/</guid>
      <description>Preliminaries # Load libraries from sklearn.ensemble import RandomForestClassifier from sklearn import datasets import numpy as np import matplotlib.pyplot as plt Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Train A Decision Tree Model # Create decision tree classifer object clf = RandomForestClassifier(random_state=0, n_jobs=-1) # Train model model = clf.fit(X, y) View Feature Importance # Calculate feature importances importances = model.feature_importances_ Visualize Feature Importance # Sort feature importances in descending order indices = np.</description>
    </item>
    
    <item>
      <title>Feature Selection Using Random Forest</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/feature_selection_using_random_forest/</guid>
      <description>Often in data science we have hundreds or even millions of features and we want a way to create a model that only includes the most important features. This has three benefits. First, we make our model more simple to interpret. Second, we can reduce the variance of the model, and therefore overfitting. Finally, we can reduce the computational cost (and time) of training a model. The process of identifying only the most relevant features is called &amp;ldquo;feature selection.</description>
    </item>
    
    <item>
      <title>Feedforward Neural Network For Binary Classification</title>
      <link>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_binary_classification/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_binary_classification/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Feedforward Neural Network For Multiclass Classification</title>
      <link>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_multiclass_classification/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_multiclass_classification/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import reuters from keras.utils.np_utils import to_categorical from keras.preprocessing.text import Tokenizer from keras import models from keras import layers # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Data # Set the number of features we want number_of_features = 5000 # Load feature and target data (train_data, train_target_vector), (test_data, test_target_vector) = reuters.load_data(num_words=number_of_features) # Convert feature data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Feedforward Neural Networks For Regression</title>
      <link>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/feedforward_neural_network_for_regression/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.preprocessing.text import Tokenizer from keras import models from keras import layers from sklearn.datasets import make_regression from sklearn.model_selection import train_test_split from sklearn import preprocessing # Set random seed np.random.seed(0) Using TensorFlow backend.  Generate Training Data # Generate features matrix and target vector features, target = make_regression(n_samples = 10000, n_features = 3, n_informative = 3, n_targets = 1, noise = 0.0, random_state = 0) # Divide our data into training and test sets train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.</description>
    </item>
    
    <item>
      <title>Filter A Sequence</title>
      <link>https://chrisalbon.com/scala/basics/filter_a_sequence/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/filter_a_sequence/</guid>
      <description> Create An Array Sequence // Create an array that contains arrays with first and last names val ages = Array(42,25,28,38,58,63,23,458,2569,584,25,25,878) Elements Less Than 100 ages.filter(_ &amp;lt; 100) Array(42, 25, 28, 38, 58, 63, 23, 25, 25)  Elements Greater Than 100 ages.filter(_ &amp;gt;= 100) Array(458, 2569, 584, 878)  Elements That Are Even ages.filter(_ % 2 == 0) Array(42, 28, 38, 58, 458, 584, 878)  </description>
    </item>
    
    <item>
      <title>Filter pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/filter_dataframes/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/filter_dataframes/</guid>
      <description>Import modules import pandas as pd Create Dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;coverage&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    coverage name reports year     Cochice 25 Jason 4 2012   Pima 94 Molly 24 2012   Santa Cruz 57 Tina 31 2013   Maricopa 62 Jake 2 2014   Yuma 70 Amy 3 2014     View Column df[&amp;#39;name&amp;#39;] Cochice Jason Pima Molly Santa Cruz Tina Maricopa Jake Yuma Amy Name: name, dtype: object  View Two Columns df[[&amp;#39;name&amp;#39;, &amp;#39;reports&amp;#39;]]   .</description>
    </item>
    
    <item>
      <title>Find Best Preprocessing Steps During Model Selection</title>
      <link>https://chrisalbon.com/machine_learning/model_selection/find_best_preprocessing_steps_during_model_selection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_selection/find_best_preprocessing_steps_during_model_selection/</guid>
      <description>We have to be careful to properly handle preprocessing when conducting model selection. First, GridSearchCV uses cross-validation to determine which model has the highest performance. However, in cross-validation we are in effect pretending that the fold held out as the test set is not seen, and thus not part of fitting any preprocessing steps (e.g. scaling or standardization). For this reason, we cannot preprocess the data then run GridSearchCV.</description>
    </item>
    
    <item>
      <title>Find Largest Key Or Value In A Map</title>
      <link>https://chrisalbon.com/scala/basics/find_largest_key_or_value_in_a_map/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/find_largest_key_or_value_in_a_map/</guid>
      <description> Create A Map // Create an immutable map with three key value pairs val numbers = Map(1 -&amp;gt; 100, 2 -&amp;gt; 200, 3 -&amp;gt; 300) Find Largest Key // Find largest key numbers.max (3,300)  Find Largest Value // Find the largest value numbers.valuesIterator.max 300  </description>
    </item>
    
    <item>
      <title>Find Largest Value In A Dataframe Column</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_find_largest_value_in_column/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_find_largest_value_in_column/</guid>
      <description># import modules %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np# Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 4 25   1 Molly Jacobson 52 24 94   2 Tina Ali 36 31 57   3 Jake Milner 24 2 62   4 Amy Cooze 73 3 70     # Index of the row with the highest value in the preTestScore column df[&amp;#39;preTestScore&amp;#39;].</description>
    </item>
    
    <item>
      <title>Find Nearest Neighbors</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/find_nearest_neighbors/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/find_nearest_neighbors/</guid>
      <description>Preliminaries # Load libraries from sklearn.neighbors import NearestNeighbors from sklearn import datasets from sklearn.preprocessing import StandardScaler import numpy as np Load Iris Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Standardize Iris Data It is important to standardize our data before we calculate any distances.
# Create standardizer standardizer = StandardScaler() # Standardize features X_std = standardizer.fit_transform(X) Find Each Observation&amp;rsquo;s Two Nearest Neighbors # Find three nearest neighbors based on euclidean distance (including itself) nn_euclidean = NearestNeighbors(n_neighbors=3, metric=&amp;#39;euclidean&amp;#39;).</description>
    </item>
    
    <item>
      <title>Find Support Vectors</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/find_support_vectors/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/find_support_vectors/</guid>
      <description>Preliminaries # Load libraries from sklearn.svm import SVC from sklearn import datasets from sklearn.preprocessing import StandardScaler import numpy as np Load Iris Flower Dataset #Load data with only two classes iris = datasets.load_iris() X = iris.data[:100,:] y = iris.target[:100] Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Train Support Vector Classifier # Create support vector classifier object svc = SVC(kernel=&amp;#39;linear&amp;#39;, random_state=0) # Train classifier model = svc.</description>
    </item>
    
    <item>
      <title>Find The Max Value In A Dictionary</title>
      <link>https://chrisalbon.com/python/basics/find_the_max_value_in_a_dictionary/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/find_the_max_value_in_a_dictionary/</guid>
      <description> Create A Dictionary ages = {&amp;#39;John&amp;#39;: 21, &amp;#39;Mike&amp;#39;: 52, &amp;#39;Sarah&amp;#39;: 12, &amp;#39;Bob&amp;#39;: 43 } Find The Maximum Value Of The Values max(zip(ages.values(), ages.keys())) (52, &#39;Mike&#39;)  </description>
    </item>
    
    <item>
      <title>Find The Maximum And Minimum</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/find_maximum_and_minimum/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/find_maximum_and_minimum/</guid>
      <description>Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Find Maximum Element # Return maximum element np.max(matrix) 9  Find Minimum Element # Return minimum element np.min(matrix) 1  Find Maximum Element By Column # Find the maximum element in each column np.max(matrix, axis=0) array([7, 8, 9])  Find Maximum Element By Row # Find the maximum element in each row np.</description>
    </item>
    
    <item>
      <title>Find The Rank Of A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/find_the_rank_of_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/find_the_rank_of_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Find Rank Of Matrix # Return matrix rank np.linalg.matrix_rank(matrix) 2  </description>
    </item>
    
    <item>
      <title>Find Unique Values In Pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_find_unique_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_find_unique_values/</guid>
      <description>import pandas as pd import numpy as npraw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;51st&amp;#39;, &amp;#39;29th&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;19th&amp;#39;, &amp;#39;12th&amp;#39;, &amp;#39;101st&amp;#39;, &amp;#39;90th&amp;#39;, &amp;#39;30th&amp;#39;, &amp;#39;193th&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;94th&amp;#39;, &amp;#39;91th&amp;#39;], &amp;#39;trucks&amp;#39;: [&amp;#39;MAZ-7310&amp;#39;, np.nan, &amp;#39;MAZ-7310&amp;#39;, &amp;#39;MAZ-7310&amp;#39;, &amp;#39;Tatra 810&amp;#39;, &amp;#39;Tatra 810&amp;#39;, &amp;#39;Tatra 810&amp;#39;, &amp;#39;Tatra 810&amp;#39;, &amp;#39;ZIS-150&amp;#39;, &amp;#39;Tatra 810&amp;#39;, &amp;#39;ZIS-150&amp;#39;, &amp;#39;ZIS-150&amp;#39;], &amp;#39;tanks&amp;#39;: [&amp;#39;Merkava Mark 4&amp;#39;, &amp;#39;Merkava Mark 4&amp;#39;, &amp;#39;Merkava Mark 4&amp;#39;, &amp;#39;Leopard 2A6M&amp;#39;, &amp;#39;Leopard 2A6M&amp;#39;, &amp;#39;Leopard 2A6M&amp;#39;, &amp;#39;Arjun MBT&amp;#39;, &amp;#39;Leopard 2A6M&amp;#39;, &amp;#39;Arjun MBT&amp;#39;, &amp;#39;Arjun MBT&amp;#39;, &amp;#39;Arjun MBT&amp;#39;, &amp;#39;Arjun MBT&amp;#39;], &amp;#39;aircraft&amp;#39;: [&amp;#39;none&amp;#39;, &amp;#39;none&amp;#39;, &amp;#39;none&amp;#39;, &amp;#39;Harbin Z-9&amp;#39;, &amp;#39;Harbin Z-9&amp;#39;, &amp;#39;none&amp;#39;, &amp;#39;Harbin Z-9&amp;#39;, &amp;#39;SH-60B Seahawk&amp;#39;, &amp;#39;SH-60B Seahawk&amp;#39;, &amp;#39;SH-60B Seahawk&amp;#39;, &amp;#39;SH-60B Seahawk&amp;#39;, &amp;#39;SH-60B Seahawk&amp;#39;]} df = pd.</description>
    </item>
    
    <item>
      <title>Flatten A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/flatten_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/flatten_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Flatten Matrix # Flatten matrix matrix.flatten() array([1, 2, 3, 4, 5, 6, 7, 8, 9])  </description>
    </item>
    
    <item>
      <title>Flatten Lists Of Lists</title>
      <link>https://chrisalbon.com/python/basics/flatten_list_of_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/flatten_list_of_lists/</guid>
      <description># Create a list containing three lists of names list_of_lists = [[&amp;#39;Amy&amp;#39;,&amp;#39;Betty&amp;#39;,&amp;#39;Cathryn&amp;#39;,&amp;#39;Dana&amp;#39;], [&amp;#39;Elizabeth&amp;#39;,&amp;#39;Fay&amp;#39;,&amp;#39;Gora&amp;#39;], [&amp;#39;Heidi&amp;#39;,&amp;#39;Jane&amp;#39;,&amp;#39;Kayley&amp;#39;]]# For each element in list_of_lists, take each element in the list flattened_list = [i for row in list_of_lists for i in row]# View the flattened list flattened_list [&#39;Amy&#39;, &#39;Betty&#39;, &#39;Cathryn&#39;, &#39;Dana&#39;, &#39;Elizabeth&#39;, &#39;Fay&#39;, &#39;Gora&#39;, &#39;Heidi&#39;, &#39;Jane&#39;, &#39;Kayley&#39;]  </description>
    </item>
    
    <item>
      <title>Flatten Sequence Of Sequences</title>
      <link>https://chrisalbon.com/scala/basics/flatten_sequence_of_sequences/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/flatten_sequence_of_sequences/</guid>
      <description> Create An Array Sequence // Create an array that contains arrays with first and last names val fullNames = Array( Array(&amp;#34;Jason&amp;#34;, &amp;#34;Miller&amp;#34;), Array(&amp;#34;Jason&amp;#34;, &amp;#34;Miller&amp;#34;), // Duplicate  Array(&amp;#34;Sally&amp;#34;, &amp;#34;Fields&amp;#34;), Array(&amp;#34;Betty&amp;#34;, &amp;#34;Johnson&amp;#34;) ) Flatten The Sequence // Flatten the sequence fullNames.flatten Array(Jason, Miller, Jason, Miller, Sally, Fields, Betty, Johnson)  Flatten The Sequence And Only Keep Unique Values // Flatten the sequence and remove any duplicates fullNames.flatten.distinct Array(Jason, Miller, Sally, Fields, Betty, Johnson)  </description>
    </item>
    
    <item>
      <title>For Loop</title>
      <link>https://chrisalbon.com/python/basics/for_loops/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/for_loops/</guid>
      <description># One at a time, assign each value of the sequence to i and, for i in [432, 342, 928, 920]: # multiply i by 10 and store the product in a new variable, x create a new variable, x, x = i * 10 # print the value of x print(x) # after the entire sequence processes, else: # print this print(&amp;#39;All done!&amp;#39;) 4320 3420 9280 9200 All done!  </description>
    </item>
    
    <item>
      <title>For Loop A Map</title>
      <link>https://chrisalbon.com/scala/basics/for_loop_a_map/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/for_loop_a_map/</guid>
      <description> Create A Map val vehicles = Map(&amp;#34;vehicle_type&amp;#34; -&amp;gt; &amp;#34;Tank&amp;#34;, &amp;#34;number&amp;#34; -&amp;gt; 21) Loop With Value And Index // Create a value for the returned values, for each key and value in the map, val numberOfVehicles = for ((key, value) &amp;lt;- vehicles) yield { // Return the values  value }// View the returned values numberOfVehicles List(Tank, 21)  </description>
    </item>
    
    <item>
      <title>For Looping</title>
      <link>https://chrisalbon.com/scala/basics/for_looping/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/for_looping/</guid>
      <description>Create An Array val staffMembers = Array(&amp;#34;Jason Miller&amp;#34;, &amp;#34;Steve Miller&amp;#34;, &amp;#34;Sally Fields&amp;#34;) Loop Over Every Item In The Array // Create a value that is the output, then for each person in staff val staffFirstNames = for (person &amp;lt;- staffMembers) yield { // Upper case the name  val upperCaseFullNames = person.toUpperCase // Get the first name by splitting the full name by space and taking the first element  val firstName = upperCaseFullNames.</description>
    </item>
    
    <item>
      <title>Format Numbers As Currency</title>
      <link>https://chrisalbon.com/scala/basics/format_numbers_as_currency/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/format_numbers_as_currency/</guid>
      <description>Load The NumberFormat Currency Package // Create a value with the numberformat currency package val format_as_dollars = java.text.NumberFormat.getCurrencyInstance Format A Number As Dollars format_as_dollars.format(123.456789) $123.46  Change To A Local Currency Java&amp;rsquo;s locale uses ISO 3166-1 country codes.
// Load the java libraries import java.util.{Currency, Locale} // Create a value with the numberformat currency package val format_as_afghan = java.text.NumberFormat.getCurrencyInstance // Set the locale of Currency to Afganistan val af = Currency.</description>
    </item>
    
    <item>
      <title>Formatting Numbers</title>
      <link>https://chrisalbon.com/python/basics/formatting_numbers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/formatting_numbers/</guid>
      <description> Create A Long Number annual_revenue = 9282904.9282872782 Format Number # Format rounded to two decimal places format(annual_revenue, &amp;#39;0.2f&amp;#39;) &#39;9282904.93&#39;  # Format with commas and rounded to one decimal place format(annual_revenue, &amp;#39;0,.1f&amp;#39;) &#39;9,282,904.9&#39;  # Format as scientific notation format(annual_revenue, &amp;#39;e&amp;#39;) &#39;9.282905e+06&#39;  # Format as scientific notation rounded to two deciminals format(annual_revenue, &amp;#39;0.2E&amp;#39;) &#39;9.28E+06&#39;  </description>
    </item>
    
    <item>
      <title>Function Annotation Examples</title>
      <link>https://chrisalbon.com/python/basics/function_annotation_examples/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/function_annotation_examples/</guid>
      <description> Create A Function With Annotations &amp;#39;&amp;#39;&amp;#39; Create a function. The argument &amp;#39;text&amp;#39; is the string to print with the default value &amp;#39;default string&amp;#39; and the argument The argument &amp;#39;n&amp;#39; is an integer of times to print with the default value of 1. The function should return a string. &amp;#39;&amp;#39;&amp;#39; def print_text(text:&amp;#39;string to print&amp;#39;=&amp;#39;default string&amp;#39;, n:&amp;#39;integer, times to print&amp;#39;=1) -&amp;gt; str: return text * n Run The Function # Run the function with arguments print_text(&amp;#39;string&amp;#39;, 4) &#39;stringstringstringstring&#39;  # Run the function with default arguments print_text() &#39;default string&#39;  </description>
    </item>
    
    <item>
      <title>Function Basics</title>
      <link>https://chrisalbon.com/python/basics/function_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/function_basics/</guid>
      <description>Create Function Called print_max def print_max(x, y): # if a is larger than b if x &amp;gt; y: # then print this print(x, &amp;#39;is maximum&amp;#39;) # if a is equal to b elif x == y: # print this print(x, &amp;#39;is equal to&amp;#39;, y) # otherwise else: # print this print(y, &amp;#39;is maximum&amp;#39;) Run Function With Two Arguments print_max(3,4) 4 is maximum  Note: By default, variables created within functions are local to the function.</description>
    </item>
    
    <item>
      <title>Functions Vs. Generators</title>
      <link>https://chrisalbon.com/python/basics/functions_vs_generators/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/functions_vs_generators/</guid>
      <description>Create A Function # Create a function that def function(names): # For each name in a list of names for name in names: # Returns the name return name# Create a variable of that function students = function([&amp;#39;Abe&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Christina&amp;#39;, &amp;#39;Derek&amp;#39;, &amp;#39;Eleanor&amp;#39;])# Run the function students &#39;Abe&#39;  Now we have a problem, we were only returned the name of the first student. Why? Because the function only ran the for name in names iteration once!</description>
    </item>
    
    <item>
      <title>Gaussian Naive Bayes Classifier</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/gaussian_naive_bayes_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/gaussian_naive_bayes_classifier/</guid>
      <description>Because of the assumption of the normal distribution, Gaussian Naive Bayes is best used in cases when all our features are continuous.
Preliminaries # Load libraries from sklearn import datasets from sklearn.naive_bayes import GaussianNB Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Train Gaussian Naive Bayes Classifier # Create Gaussian Naive Bayes object with prior probabilities of each class clf = GaussianNB(priors=[0.</description>
    </item>
    
    <item>
      <title>Generate Text Reports On Performance</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/generate_text_reports_on_performance/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/generate_text_reports_on_performance/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report Load Iris Flower Data # Load data iris = datasets.load_iris() # Create feature matrix X = iris.data # Create target vector y = iris.target # Create list of target class names class_names = iris.target_names Create Training And Test Sets # Create training and test set X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1) Train A Logistic Regression Model # Create logistic regression classifier = LogisticRegression() # Train model and make predictions y_hat = classifier.</description>
    </item>
    
    <item>
      <title>Generate Tweets Using Markov Chains</title>
      <link>https://chrisalbon.com/python/other/generate_tweets_using_markov_chain/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/other/generate_tweets_using_markov_chain/</guid>
      <description>Preliminaries import markovify Load Corpus The corpus I am using is just one I found online. The corpus you choose is central to generating realistic text.
# Get raw text as string with open(&amp;#34;brown.txt&amp;#34;) as f: text = f.read() Build Markov Chain # Build the model. text_model = markovify.Text(text) Generate One Tweet # Print three randomly-generated sentences of no more than 140 characters for i in range(3): print(text_model.make_short_sentence(140)) Within a month, calls were still productive and most devotees of baseball attended the dozens of them.</description>
    </item>
    
    <item>
      <title>Generating Random Numbers With NumPy</title>
      <link>https://chrisalbon.com/python/basics/generating_random_numbers_with_numpy/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/generating_random_numbers_with_numpy/</guid>
      <description> Import Numpy import numpy as np Generate A Random Number From The Normal Distribution np.random.normal() 0.5661104974399703  Generate Four Random Numbers From The Normal Distribution np.random.normal(size=4) array([-1.03175853, 1.2867365 , -0.23560103, -1.05225393])  Generate Four Random Numbers From The Uniform Distribution np.random.uniform(size=4) array([ 0.00193123, 0.51932356, 0.87656884, 0.33684494])  Generate Four Random Integers Between 1 and 100 np.random.randint(low=1, high=100, size=4) array([96, 25, 94, 77])  </description>
    </item>
    
    <item>
      <title>Generator Expressions</title>
      <link>https://chrisalbon.com/python/basics/generator_expressions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/generator_expressions/</guid>
      <description># Create a list of students students = [&amp;#39;Abe&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Christina&amp;#39;, &amp;#39;Derek&amp;#39;, &amp;#39;Eleanor&amp;#39;]# Create a generator expression that yields lower-case versions of the student&amp;#39;s names lowercase_names = (student.lower() for student in students)# View the generator object lowercase_names &amp;lt;generator object &amp;lt;genexpr&amp;gt; at 0x104837518&amp;gt;  # Get the next name lower-cased next(lowercase_names) &#39;abe&#39;  # Get the next name lower-cased next(lowercase_names) &#39;bob&#39;  # Get the remaining names lower-cased list(lowercase_names) [&#39;christina&#39;, &#39;derek&#39;, &#39;eleanor&#39;]  </description>
    </item>
    
    <item>
      <title>Geocoding And Reverse Geocoding</title>
      <link>https://chrisalbon.com/python/data_wrangling/geocoding_and_reverse_geocoding/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/geocoding_and_reverse_geocoding/</guid>
      <description>Geocoding (converting a physical address or location into latitude/longitude) and reverse geocoding (converting a lat/long to a physical address or location) are common tasks when working with geo-data.
Python offers a number of packages to make the task incredibly easy. In the tutorial below, I use pygeocoder, a wrapper for Google&amp;rsquo;s geo-API, to both geocode and reverse geocode.
Preliminaries First we want to load the packages we will want to use in the script.</description>
    </item>
    
    <item>
      <title>Geolocate A City And Country</title>
      <link>https://chrisalbon.com/python/data_wrangling/geolocate_a_city_and_country/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/geolocate_a_city_and_country/</guid>
      <description>This tutorial creates a function that attempts to take a city and country and return its latitude and longitude. But when the city is unavailable (which is often be the case), the returns the latitude and longitude of the center of the country.
Preliminaries from geopy.geocoders import Nominatim geolocator = Nominatim() import numpy as np Create Geolocation Function def geolocate(city=None, country=None): &amp;#39;&amp;#39;&amp;#39; Inputs city and country, or just country. Returns the lat/long coordinates of either the city if possible, if not, then returns lat/long of the center of the country.</description>
    </item>
    
    <item>
      <title>Geolocate A City Or Country</title>
      <link>https://chrisalbon.com/python/data_wrangling/geolocate_a_city_or_country/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/geolocate_a_city_or_country/</guid>
      <description>This tutorial creates a function that attempts to take a city and country and return its latitude and longitude. But when the city is unavailable (which is often be the case), the returns the latitude and longitude of the center of the country.
Preliminaries from geopy.geocoders import Nominatim geolocator = Nominatim() import numpy as np Create Geolocation Function def geolocate(city=None, country=None): &amp;#39;&amp;#39;&amp;#39; Inputs city and country, or just country. Returns the lat/long coordinates of either the city if possible, if not, then returns lat/long of the center of the country.</description>
    </item>
    
    <item>
      <title>Getting The Diagonal Of A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/getting_the_diagonal_of_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/getting_the_diagonal_of_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Get The Diagonal # Return diagonal elements matrix.diagonal() array([1, 5, 9])  Calculate The Trace # Calculate the tracre of the matrix matrix.diagonal().sum() 15  </description>
    </item>
    
    <item>
      <title>GitHub Cheatsheet</title>
      <link>https://chrisalbon.com/git_and_github/basics/github_cheatsheet/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/git_and_github/basics/github_cheatsheet/</guid>
      <description>Find The Version Of Git git --version
Create A New Git Repository  Go to the fold of the project.
 Run git init
  Clone An Existing Git Repository Cloning is the process of pulling down a copy of a repository stored on a server.
 Go to the parent folder of where you want to repository&amp;rsquo;s folder to be in.
 git clone [url to repository&#39;s git file] [name of folder / repository you want]</description>
    </item>
    
    <item>
      <title>Group A Time Series With pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_group_by_time/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_group_by_time/</guid>
      <description>Import required modules import pandas as pd import numpy as np Create a dataframe df = pd.DataFrame() df[&amp;#39;german_army&amp;#39;] = np.random.randint(low=20000, high=30000, size=100) df[&amp;#39;allied_army&amp;#39;] = np.random.randint(low=20000, high=40000, size=100) df.index = pd.date_range(&amp;#39;1/1/2014&amp;#39;, periods=100, freq=&amp;#39;H&amp;#39;) df.head()  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    german_army allied_army     2014-01-01 00:00:00 21413 37604   2014-01-01 01:00:00 25913 21144   2014-01-01 02:00:00 22418 34201   2014-01-01 03:00:00 20704 37313   2014-01-01 04:00:00 27859 24467     Truncate the dataframe df.</description>
    </item>
    
    <item>
      <title>Group Bar Plot In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_grouped_bar_plot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_grouped_bar_plot/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;pre_score&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;mid_score&amp;#39;: [25, 94, 57, 62, 70], &amp;#39;post_score&amp;#39;: [5, 43, 23, 23, 51]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;pre_score&amp;#39;, &amp;#39;mid_score&amp;#39;, &amp;#39;post_score&amp;#39;]) df   first_name pre_score mid_score post_score     0  Jason  4  25  5   1  Molly  24  94  43   2  Tina  31  57  23   3  Jake  2  62  23   4  Amy  3  70  51     Make plot # Setting the positions and width for the bars pos = list(range(len(df[&amp;#39;pre_score&amp;#39;]))) width = 0.</description>
    </item>
    
    <item>
      <title>Group Data By Time</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_group_data_by_time/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_group_data_by_time/</guid>
      <description>On March 13, 2016, version 0.18.0 of Pandas was released, with significant changes in how the resampling function operates. This tutorial follows v0.18.0 and will not work for previous versions of pandas.
First let&amp;rsquo;s load the modules we care about
Preliminaries # Import required packages import pandas as pd import datetime import numpy as np Next, let&amp;rsquo;s create some sample data that we can group by time as an sample.</description>
    </item>
    
    <item>
      <title>Group Observations Using K-Means Clustering</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/group_observations_using_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/group_observations_using_clustering/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import make_blobs from sklearn.cluster import KMeans import pandas as pd Create Data # Make simulated feature matrix X, _ = make_blobs(n_samples = 50, n_features = 2, centers = 3, random_state = 1) # Create DataFrame df = pd.DataFrame(X, columns=[&amp;#39;feature_1&amp;#39;,&amp;#39;feature_2&amp;#39;]) Train Clusterer # Make k-means clusterer clusterer = KMeans(3, random_state=1) # Fit clusterer clusterer.fit(X) KMeans(algorithm=&#39;auto&#39;, copy_x=True, init=&#39;k-means++&#39;, max_iter=300, n_clusters=3, n_init=10, n_jobs=1, precompute_distances=&#39;auto&#39;, random_state=1, tol=0.0001, verbose=0)  Create Feature Based On Predicted Cluster # Predict values df[&amp;#39;group&amp;#39;] = clusterer.</description>
    </item>
    
    <item>
      <title>Group Pandas Data By Hour Of The Day</title>
      <link>https://chrisalbon.com/python/data_wrangling/group_pandas_data_by_hour_of_the_day/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/group_pandas_data_by_hour_of_the_day/</guid>
      <description>Preliminaries # Import libraries import pandas as pd import numpy as np Create Data # Create a time series of 2000 elements, one very five minutes starting on 1/1/2000 time = pd.date_range(&amp;#39;1/1/2000&amp;#39;, periods=2000, freq=&amp;#39;5min&amp;#39;) # Create a pandas series with a random values between 0 and 100, using &amp;#39;time&amp;#39; as the index series = pd.Series(np.random.randint(100, size=2000), index=time) View Data # View the first few rows of the data series[0:10] 2000-01-01 00:00:00 40 2000-01-01 00:05:00 13 2000-01-01 00:10:00 99 2000-01-01 00:15:00 72 2000-01-01 00:20:00 4 2000-01-01 00:25:00 36 2000-01-01 00:30:00 24 2000-01-01 00:35:00 20 2000-01-01 00:40:00 83 2000-01-01 00:45:00 44 Freq: 5T, dtype: int64  Group Data By Time Of The Day # Group the data by the index&amp;#39;s hour value, then aggregate by the average series.</description>
    </item>
    
    <item>
      <title>Grouping Rows In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_group_rows_by/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_group_rows_by/</guid>
      <description># Import modules import pandas as pd# Example dataframe raw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;,&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;], &amp;#39;name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]} df = pd.</description>
    </item>
    
    <item>
      <title>Handle Imbalanced Classes In Random Forest</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/handle_imbalanced_classes_in_random_forests/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/handle_imbalanced_classes_in_random_forests/</guid>
      <description>Preliminaries # Load libraries from sklearn.ensemble import RandomForestClassifier import numpy as np from sklearn import datasets Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Adjust Iris Dataset To Make Classes Imbalanced # Make class highly imbalanced by removing first 40 observations X = X[40:,:] y = y[40:] # Create target vector indicating if class 0, otherwise 1 y = np.where((y == 0), 0, 1) Train Random Forest While Balancing Classes When using RandomForestClassifier a useful setting is class_weight=balanced wherein classes are automatically weighted inversely proportional to how frequently they appear in the data.</description>
    </item>
    
    <item>
      <title>Handling Imbalanced Classes In Logistic Regression</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/handling_imbalanced_classes_in_logistic_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/handling_imbalanced_classes_in_logistic_regression/</guid>
      <description>Like many other learning algorithms in scikit-learn, LogisticRegression comes with a built-in method of handling imbalanced classes. If we have highly imbalanced classes and have no addressed it during preprocessing, we have the option of using the class_weight parameter to weight the classes to make certain we have a balanced mix of each class. Specifically, the balanced argument will automatically weigh classes inversely proportional to their frequency:
$$w_j = \frac{n}{kn_{j}}$$</description>
    </item>
    
    <item>
      <title>Handling Imbalanced Classes With Downsampling</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_downsampling/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_downsampling/</guid>
      <description>In downsampling, we randomly sample without replacement from the majority class (i.e. the class with more observations) to create a new subset of observation equal in size to the minority class.
Preliminaries # Load libraries import numpy as np from sklearn.datasets import load_iris Load Iris Dataset # Load iris data iris = load_iris() # Create feature matrix X = iris.data # Create target vector y = iris.target Make Iris Dataset Imbalanced # Remove first 40 observations X = X[40:,:] y = y[40:] # Create binary target vector indicating if class 0 y = np.</description>
    </item>
    
    <item>
      <title>Handling Imbalanced Classes With Upsampling</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_upsampling/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_imbalanced_classes_with_upsampling/</guid>
      <description>In upsampling, for every observation in the majority class, we randomly select an observation from the minority class with replacement. The end result is the same number of observations from the minority and majority classes.
Preliminaries # Load libraries import numpy as np from sklearn.datasets import load_iris Load Iris Dataset # Load iris data iris = load_iris() # Create feature matrix X = iris.data # Create target vector y = iris.</description>
    </item>
    
    <item>
      <title>Handling Missing Values In Time Series</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/handling_missing_values_in_time_series/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/handling_missing_values_in_time_series/</guid>
      <description>Preliminaries # Load libraries import pandas as pd import numpy as np Create Date Data With Gap In Values # Create date time_index = pd.date_range(&amp;#39;01/01/2010&amp;#39;, periods=5, freq=&amp;#39;M&amp;#39;) # Create data frame, set index df = pd.DataFrame(index=time_index) # Create feature with a gap of missing values df[&amp;#39;Sales&amp;#39;] = [1.0,2.0,np.nan,np.nan,5.0] Interpolate Missing Values # Interpolate missing values df.interpolate()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .</description>
    </item>
    
    <item>
      <title>Handling Outliers</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_outliers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/handling_outliers/</guid>
      <description>Preliminaries # Load library import pandas as pd Create Data # Create DataFrame houses = pd.DataFrame() houses[&amp;#39;Price&amp;#39;] = [534433, 392333, 293222, 4322032] houses[&amp;#39;Bathrooms&amp;#39;] = [2, 3.5, 2, 116] houses[&amp;#39;Square_Feet&amp;#39;] = [1500, 2500, 1500, 48000] houses   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    Price Bathrooms Square_Feet     0 534433 2.</description>
    </item>
    
    <item>
      <title>Handling Time Zones</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/handling_time_zones/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/handling_time_zones/</guid>
      <description>Preliminaries # Load libraries import pandas as pd from pytz import all_timezones View Timezones # Show ten time zones all_timezones[0:10] [&#39;Africa/Abidjan&#39;, &#39;Africa/Accra&#39;, &#39;Africa/Addis_Ababa&#39;, &#39;Africa/Algiers&#39;, &#39;Africa/Asmara&#39;, &#39;Africa/Asmera&#39;, &#39;Africa/Bamako&#39;, &#39;Africa/Bangui&#39;, &#39;Africa/Banjul&#39;, &#39;Africa/Bissau&#39;]  Create Timestamp With Time Zone # Create datetime pd.Timestamp(&amp;#39;2017-05-01 06:00:00&amp;#39;, tz=&amp;#39;Europe/London&amp;#39;) Timestamp(&#39;2017-05-01 06:00:00+0100&#39;, tz=&#39;Europe/London&#39;)  Create Timestamp Without Time Zone # Create datetime date = pd.Timestamp(&amp;#39;2017-05-01 06:00:00&amp;#39;) Add Time Zone # Set time zone date_in_london = date.tz_localize(&amp;#39;Europe/London&amp;#39;) Convert Time Zone # Change time zone date_in_london.</description>
    </item>
    
    <item>
      <title>Hard Wrapping Text</title>
      <link>https://chrisalbon.com/python/basics/hard_wrapping_text/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/hard_wrapping_text/</guid>
      <description>Preliminaries import textwrap Create Text # Create some text excerpt = &amp;#39;Then there was the bad weather. It would come in one day when the fall was over. We would have to shut the windows in the night against the rain and the cold wind would strip the leaves from the trees in the Place Contrescarpe. The leaves lay sodden in the rain and the wind drove the rain against the big green autobus at the terminal and the Caf des Amateurs was crowded and the windows misted over from the heat and the smoke inside.</description>
    </item>
    
    <item>
      <title>Harris Corner Detector</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/harris_corner_detector/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/harris_corner_detector/</guid>
      <description>The Harris Corner Detector is a commonly used method of detecting the intersection of two edges. It looks for windows (also called neighborhoods or patches) where small movements of the window (imagine shaking the window) creates big changes in the contents of the pixels inside the window.
Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load image # Load image as grayscale image_bgr = cv2.</description>
    </item>
    
    <item>
      <title>Hierarchical Data In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_hierarchical_data/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_hierarchical_data/</guid>
      <description># import modules import pandas as pd# Create dataframe raw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;,&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;], &amp;#39;name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]} df = pd.</description>
    </item>
    
    <item>
      <title>Histograms In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_histogram/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_histogram/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np import math # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create dataframe df = pd.read_csv(&amp;#39;https://www.dropbox.com/s/52cb7kcflr8qm2u/5kings_battles_v1.csv?dl=1&amp;#39;) df.head()   name year battle_number attacker_king defender_king attacker_1 attacker_2 attacker_3 attacker_4 defender_1 defender_2 defender_3 defender_4 attacker_outcome battle_type major_death major_capture attacker_size defender_size attacker_commander defender_commander summer location region note     0  Battle of the Golden Tooth  298  1  Joffrey/Tommen Baratheon  Robb Stark  Lannister  NaN  NaN  NaN  Tully  NaN NaN NaN  win  pitched battle  1  0  15000  4000  Jaime Lannister  Clement Piper, Vance  1  Golden Tooth  The Westerlands  NaN   1  Battle at the Mummer&#39;s Ford  298  2  Joffrey/Tommen Baratheon  Robb Stark  Lannister  NaN  NaN  NaN  Baratheon  NaN NaN NaN  win  ambush  1  0  NaN  120  Gregor Clegane  Beric Dondarrion  1  Mummer&#39;s Ford  The Riverlands  NaN   2  Battle of Riverrun  298  3  Joffrey/Tommen Baratheon  Robb Stark  Lannister  NaN  NaN  NaN  Tully  NaN NaN NaN  win  pitched battle  0  1  15000  10000  Jaime Lannister, Andros Brax  Edmure Tully, Tytos Blackwood  1  Riverrun  The Riverlands  NaN   3  Battle of the Green Fork  298  4  Robb Stark  Joffrey/Tommen Baratheon  Stark  NaN  NaN  NaN  Lannister  NaN NaN NaN  loss  pitched battle  1  1  18000  20000  Roose Bolton, Wylis Manderly, Medger Cerwyn, H.</description>
    </item>
    
    <item>
      <title>How To Use Default Dicts</title>
      <link>https://chrisalbon.com/python/basics/how_to_use_default_dicts/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/how_to_use_default_dicts/</guid>
      <description> Preliminaries import collections Create A DefaultDict Default Dicts work just like regular dictionaries, except a key is called that doesn&amp;rsquo;t have a value, a default value (note: value, not key) is supplied.
# Create a defaultdict with the default value of 0 (int&amp;#39;s default value is 0) arrests = collections.defaultdict(int)  Add A New Key With A Value # Add an entry of a person with 10 arrests arrests[&amp;#39;Sarah Miller&amp;#39;] = 10# View dictionary arrests defaultdict(int, {&#39;Sarah Miller&#39;: 10})  Add A New Key Without A Value # Add an entry of a person with no value for arrests, # thus the default value is used arrests[&amp;#39;Bill James&amp;#39;] 0  # View dictionary arrests defaultdict(int, {&#39;Bill James&#39;: 0, &#39;Sarah Miller&#39;: 10})  </description>
    </item>
    
    <item>
      <title>Hyperparameter Tuning Using Grid Search</title>
      <link>https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_grid_search/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_grid_search/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn import linear_model, datasets from sklearn.model_selection import GridSearchCV Load Iris Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Logistic Regression # Create logistic regression logistic = linear_model.LogisticRegression() Create Hyperparameter Search Space # Create regularization penalty space penalty = [&amp;#39;l1&amp;#39;, &amp;#39;l2&amp;#39;] # Create regularization hyperparameter space C = np.logspace(0, 4, 10) # Create hyperparameter options hyperparameters = dict(C=C, penalty=penalty) Create Grid Search # Create grid search using 5-fold cross validation clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0) Conduct Grid Search # Fit grid search best_model = clf.</description>
    </item>
    
    <item>
      <title>Hyperparameter Tuning Using Random Search</title>
      <link>https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_random_search/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_selection/hyperparameter_tuning_using_random_search/</guid>
      <description>Preliminaries # Load libraries from scipy.stats import uniform from sklearn import linear_model, datasets from sklearn.model_selection import RandomizedSearchCV Load Iris Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Logistic Regression # Create logistic regression logistic = linear_model.LogisticRegression() Create Hyperparameter Search Space # Create regularization penalty space penalty = [&amp;#39;l1&amp;#39;, &amp;#39;l2&amp;#39;] # Create regularization hyperparameter distribution using uniform distribution C = uniform(loc=0, scale=4) # Create hyperparameter options hyperparameters = dict(C=C, penalty=penalty) Create Random Search # Create randomized search 5-fold cross validation and 100 iterations clf = RandomizedSearchCV(logistic, hyperparameters, random_state=1, n_iter=100, cv=5, verbose=0, n_jobs=-1) Conduct Random Search # Fit randomized search best_model = clf.</description>
    </item>
    
    <item>
      <title>Identifying Best Value Of k</title>
      <link>https://chrisalbon.com/machine_learning/nearest_neighbors/identifying_best_value_of_k/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/nearest_neighbors/identifying_best_value_of_k/</guid>
      <description>Preliminaries # Load libraries from sklearn.neighbors import KNeighborsClassifier from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.pipeline import Pipeline, FeatureUnion from sklearn.model_selection import GridSearchCV Load Iris Flower Data # Load data iris = datasets.load_iris() X = iris.data y = iris.target Standardize Data # Create standardizer standardizer = StandardScaler() # Standardize features X_std = standardizer.fit_transform(X) Fit A k-Nearest Neighbor Classifier # Fit a KNN classifier with 5 neighbors knn = KNeighborsClassifier(n_neighbors=5, metric=&amp;#39;euclidean&amp;#39;, n_jobs=-1).</description>
    </item>
    
    <item>
      <title>If Else</title>
      <link>https://chrisalbon.com/scala/basics/if_else/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/if_else/</guid>
      <description> Create A Value // Create a value called x that is a short integer of 3 val x: Short = 3 Create A Conditional Expression // Create a value that is 1 if x is greater than 0, otherwise -1 val binary = if (x &amp;gt; 0) 1 else -1 // View that value binary 1  </description>
    </item>
    
    <item>
      <title>If Else On Any Or All Elements</title>
      <link>https://chrisalbon.com/python/basics/ifelse_on_any_or_all_elements/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/ifelse_on_any_or_all_elements/</guid>
      <description>Preliminaries # import pandas as pd import pandas as pd Create a simulated dataset # Create an example dataframe data = {&amp;#39;score&amp;#39;: [1,2,3,4,5]} df = pd.DataFrame(data) df   score     0 1   1 2   2 3   3 4   4 5     Does any cell equal 3? # If any element in df.score equals three, if (df.</description>
    </item>
    
    <item>
      <title>Imbalanced Classes In SVM</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/imbalanced_classes_in_svm/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/imbalanced_classes_in_svm/</guid>
      <description>In support vector machines, $C$ is a hyperparameter determining the penalty for misclassifying an observation. One method for handling imbalanced classes in support vector machines is to weight $C$ by classes, so that
$$C_k = C * w_j$$
where $C$ is the penalty for misclassification, $w_j$ is a weight inversely proportional to class $j$&amp;rsquo;s frequency, and $C_j$ is the $C$ value for class $j$. The general idea is to increase the penalty for misclassifying minority classes to prevent them from being &amp;ldquo;overwhelmed&amp;rdquo; by the majority class.</description>
    </item>
    
    <item>
      <title>Impute Missing Values With Means</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/impute_missing_values_with_means/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/impute_missing_values_with_means/</guid>
      <description>Mean imputation replaces missing values with the mean value of that feature/variable. Mean imputation is one of the most &amp;lsquo;naive&amp;rsquo; imputation methods because unlike more complex methods like k-nearest neighbors imputation, it does not use the information we have about an observation to estimate a value for it.
Preliminaries import pandas as pd import numpy as np from sklearn.preprocessing import Imputer Create Data # Create an empty dataset df = pd.</description>
    </item>
    
    <item>
      <title>Imputing Missing Class Labels</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/imputing_missing_class_labels/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/imputing_missing_class_labels/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn.preprocessing import Imputer Create Feature Matrix With Missing Values # Create feature matrix with categorical feature X = np.array([[0, 2.10, 1.45], [1, 1.18, 1.33], [0, 1.22, 1.27], [0, -0.21, -1.19], [np.nan, 0.87, 1.31], [np.nan, -0.67, -0.22]]) Fill Missing Values&amp;rsquo; Class With Most Frequent Class # Create Imputer object imputer = Imputer(strategy=&amp;#39;most_frequent&amp;#39;, axis=0) # Fill missing values with most frequent class imputer.</description>
    </item>
    
    <item>
      <title>Imputing Missing Class Labels Using k-Nearest Neighbors</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/imputing_missing_class_labels_using_k-nearest_neighbors/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/imputing_missing_class_labels_using_k-nearest_neighbors/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn.neighbors import KNeighborsClassifier Create Feature Matrix # Create feature matrix with categorical feature X = np.array([[0, 2.10, 1.45], [1, 1.18, 1.33], [0, 1.22, 1.27], [1, -0.21, -1.19]]) Create Feature Matrix With Missing Values # Create feature matrix with missing values in the categorical feature X_with_nan = np.array([[np.nan, 0.87, 1.31], [np.nan, -0.67, -0.22]]) Train k-Nearest Neighbor Classifier # Train KNN learner clf = KNeighborsClassifier(3, weights=&amp;#39;distance&amp;#39;) trained_model = clf.</description>
    </item>
    
    <item>
      <title>Increment And Decrement Numbers</title>
      <link>https://chrisalbon.com/scala/basics/increment_and_decrement_numbers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/increment_and_decrement_numbers/</guid>
      <description> Create Integer Variable // Create an integer variable of 10 var i:Int = 10 Increment And Decrement // Increment up 1 i += 1 // View variable i 11  // Decrement up 1 i -= 1 // View variable i 10  // Increment up x2 i *= 2 // View variable i 20  // Decrement down by half i /= 2 // View variable i 10  </description>
    </item>
    
    <item>
      <title>Indexing And Slicing NumPy Arrays</title>
      <link>https://chrisalbon.com/python/basics/indexing_and_slicing_numpy_arrays/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/indexing_and_slicing_numpy_arrays/</guid>
      <description>Slicing Arrays Explanation Of Broadcasting Unlike many other data types, slicing an array into a new variable means that any chances to that new variable are broadcasted to the original variable. Put other way, a slice is a hotlink to the original array variable, not a separate and independent copy of it.
# Import Modules import numpy as np# Create an array of battle casualties from the first to the last battle battleDeaths = np.</description>
    </item>
    
    <item>
      <title>Indexing And Slicing NumPy Arrays</title>
      <link>https://chrisalbon.com/python/basics/numpy_indexing_and_slicing/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/numpy_indexing_and_slicing/</guid>
      <description># Import modules import numpy as np# Create a 2x2 array battle_deaths = [[344, 2345], [253, 4345]] deaths = np.array(battle_deaths) deaths array([[ 344, 2345], [ 253, 4345]])  # Select the top row, second item deaths[0, 1] 2345  # Select the second column deaths[:, 1] array([2345, 4345])  # Select the second row deaths[1, :] array([ 253, 4345])  # Create an array of civilian deaths civilian_deaths = np.array([4352, 233, 3245, 256, 2394]) civilian_deaths array([4352, 233, 3245, 256, 2394])  # Find the index of battles with less than 500 deaths few_civ_deaths = np.</description>
    </item>
    
    <item>
      <title>Insert Variables Into Strings</title>
      <link>https://chrisalbon.com/scala/basics/insert_variables_into_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/insert_variables_into_strings/</guid>
      <description> The proper term from this is string interpolation.
Create A Value // Create some values val number_of_soldiers: Short = 542 val casualties: Short = 32 Add The Value To A String print(f&amp;#34;Before the battle we had $number_of_soldierssoldiers. However, now we have ${number_of_soldiers - casualties}.&amp;#34;) Before the battle we had 542 soldiers. However, now we have 510.  </description>
    </item>
    
    <item>
      <title>Insertion Sort</title>
      <link>https://chrisalbon.com/computer_science/algorithms/insertion_sort/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/computer_science/algorithms/insertion_sort/</guid>
      <description> Create A Sequence alist = [8,5,3,6,2,1,9,4,7] alist [8, 5, 3, 6, 2, 1, 9, 4, 7]  Create A Selection Sort Algorithm # Define an function that takes a list def insertion_sort(alist): # Create a sequence from the argument list sequence = alist[:] # Get the length of the list n = len(sequence) # For 1 through the length for the sequence: for i in range(1, n): # save the value of the card value = sequence[i] # save the current position of the card position = i # while the card is not the first card and is smaller than the card to it&amp;#39;s left: while position &amp;gt; 0 and value &amp;lt; sequence[position - 1]: # the card overwrites the card to the left sequence[position] = sequence[position - 1] # And we move on to the next position position -= 1 # When we have found the right position (meaning the while loop is false) # put the card in its correct spot in the deck sequence[position] = value # View the deck so far print(sequence)# Run the sort insertion_sort(alist) [5, 8, 3, 6, 2, 1, 9, 4, 7] [3, 5, 8, 6, 2, 1, 9, 4, 7] [3, 5, 6, 8, 2, 1, 9, 4, 7] [2, 3, 5, 6, 8, 1, 9, 4, 7] [1, 2, 3, 5, 6, 8, 9, 4, 7] [1, 2, 3, 5, 6, 8, 9, 4, 7] [1, 2, 3, 4, 5, 6, 8, 9, 7] [1, 2, 3, 4, 5, 6, 7, 8, 9]  </description>
    </item>
    
    <item>
      <title>Installing OpenCV</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/installing_opencv/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/installing_opencv/</guid>
      <description>While there are a number of good libraries out there, OpenCV is the most popular and documented library for handling images. One of the biggest hurdles to using OpenCV is installing it. However, fortunately we can use Anaconda&amp;rsquo;s package manager tool conda to install OpenCV in a single line of code in our terminal:
conda install --channel https://conda.anaconda.org/menpo opencv3
Afterwards, we can check the installation by opening a notebook, importing OpenCV, and checking the version number (3.</description>
    </item>
    
    <item>
      <title>Invert A Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/invert_a_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/invert_a_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Matrix # Create matrix matrix = np.array([[1, 4], [2, 5]]) Invert Matrix # Calculate inverse of matrix np.linalg.inv(matrix) array([[-1.66666667, 1.33333333], [ 0.66666667, -0.33333333]])  </description>
    </item>
    
    <item>
      <title>Isolate Colors</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/isolate_colors/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/isolate_colors/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image # Load image image_bgr = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;) Convert To HSV Color Format # Convert BGR to HSV image_hsv = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV) Create Mask # Define range of blue values in HSV lower_blue = np.array([50,100,50]) upper_blue = np.array([130,255,255]) # Create mask mask = cv2.inRange(image_hsv, lower_blue, upper_blue) Apply Mask # Mask image image_bgr_masked = cv2.</description>
    </item>
    
    <item>
      <title>Iterate An Ifelse Over A List</title>
      <link>https://chrisalbon.com/python/basics/iterate_ifelse_over_list/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/iterate_ifelse_over_list/</guid>
      <description> Create some data word_list = [&amp;#39;Egypt&amp;#39;, &amp;#39;Watching&amp;#39;, &amp;#39;Eleanor&amp;#39;] vowels = [&amp;#39;A&amp;#39;, &amp;#39;E&amp;#39;, &amp;#39;I&amp;#39;, &amp;#39;O&amp;#39;, &amp;#39;U&amp;#39;] Create a for loop # for each item in the word_list, for word in word_list: # if any word starts with e, where e is vowels, if any([word.startswith(e) for e in vowels]): # then print is valid, print(&amp;#39;Is valid&amp;#39;) # if not,  else: # print invalid print(&amp;#39;Invalid&amp;#39;) Is valid Invalid Is valid  </description>
    </item>
    
    <item>
      <title>Iterate Over A Map</title>
      <link>https://chrisalbon.com/scala/basics/iterate_over_a_map/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/iterate_over_a_map/</guid>
      <description>Create A Map // Create a map with three key value pairs val prices = Map(&amp;#34;Video Card&amp;#34; -&amp;gt; 200.00, &amp;#34;Motherboard&amp;#34; -&amp;gt; 400.00, &amp;#34;CPU&amp;#34; -&amp;gt; 100.00) Loop Over A Map // for each key and value in prices for ((k,v) &amp;lt;- prices) yield { // Return the value plus 100  v+100 } List(300.0, 500.0, 200.0)  Apply Function To Each Map Value // Increase each value in the map by 1000 prices.</description>
    </item>
    
    <item>
      <title>Iterate Over Multiple Lists Simultaneously</title>
      <link>https://chrisalbon.com/python/basics/iterate_over_multiple_lists_simultaneously/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/iterate_over_multiple_lists_simultaneously/</guid>
      <description> Create Two Lists names = [&amp;#39;James&amp;#39;, &amp;#39;Bob&amp;#39;, &amp;#39;Sarah&amp;#39;, &amp;#39;Marco&amp;#39;, &amp;#39;Nancy&amp;#39;, &amp;#39;Sally&amp;#39;] ages = [42, 13, 14, 25, 63, 23] Iterate Over Both Lists At Once for name, age in zip(names, ages): print(name, age) James 42 Bob 13 Sarah 14 Marco 25 Nancy 63 Sally 23  </description>
    </item>
    
    <item>
      <title>Iterating Over Dictionary Keys</title>
      <link>https://chrisalbon.com/python/basics/iterating_over_dictionary_keys/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/iterating_over_dictionary_keys/</guid>
      <description>Create A Dictionary Officers = {&amp;#39;Michael Mulligan&amp;#39;: &amp;#39;Red Army&amp;#39;, &amp;#39;Steven Johnson&amp;#39;: &amp;#39;Blue Army&amp;#39;, &amp;#39;Jessica Billars&amp;#39;: &amp;#39;Green Army&amp;#39;, &amp;#39;Sodoni Dogla&amp;#39;: &amp;#39;Purple Army&amp;#39;, &amp;#39;Chris Jefferson&amp;#39;: &amp;#39;Orange Army&amp;#39;}Officers {&#39;Chris Jefferson&#39;: &#39;Orange Army&#39;, &#39;Jessica Billars&#39;: &#39;Green Army&#39;, &#39;Michael Mulligan&#39;: &#39;Red Army&#39;, &#39;Sodoni Dogla&#39;: &#39;Purple Army&#39;, &#39;Steven Johnson&#39;: &#39;Blue Army&#39;}  Use Dictionary Comprehension # Display all dictionary entries where the key doesn&amp;#39;t start with &amp;#39;Chris&amp;#39; {keys : Officers[keys] for keys in Officers if not keys.</description>
    </item>
    
    <item>
      <title>Join And Merge Pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_join_merge_dataframe/</guid>
      <description>import modules import pandas as pd from IPython.display import display from IPython.display import Image Create a dataframe raw_data = { &amp;#39;subject_id&amp;#39;: [&amp;#39;1&amp;#39;, &amp;#39;2&amp;#39;, &amp;#39;3&amp;#39;, &amp;#39;4&amp;#39;, &amp;#39;5&amp;#39;], &amp;#39;first_name&amp;#39;: [&amp;#39;Alex&amp;#39;, &amp;#39;Amy&amp;#39;, &amp;#39;Allen&amp;#39;, &amp;#39;Alice&amp;#39;, &amp;#39;Ayoung&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Anderson&amp;#39;, &amp;#39;Ackerman&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Aoni&amp;#39;, &amp;#39;Atiches&amp;#39;]} df_a = pd.DataFrame(raw_data, columns = [&amp;#39;subject_id&amp;#39;, &amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;]) df_a    subject_id first_name last_name     0 1 Alex Anderson   1 2 Amy Ackerman   2 3 Allen Ali   3 4 Alice Aoni   4 5 Ayoung Atiches     Create a second dataframe raw_data = { &amp;#39;subject_id&amp;#39;: [&amp;#39;4&amp;#39;, &amp;#39;5&amp;#39;, &amp;#39;6&amp;#39;, &amp;#39;7&amp;#39;, &amp;#39;8&amp;#39;], &amp;#39;first_name&amp;#39;: [&amp;#39;Billy&amp;#39;, &amp;#39;Brian&amp;#39;, &amp;#39;Bran&amp;#39;, &amp;#39;Bryce&amp;#39;, &amp;#39;Betty&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Bonder&amp;#39;, &amp;#39;Black&amp;#39;, &amp;#39;Balwner&amp;#39;, &amp;#39;Brice&amp;#39;, &amp;#39;Btisan&amp;#39;]} df_b = pd.</description>
    </item>
    
    <item>
      <title>K-Nearest Neighbors Classification</title>
      <link>https://chrisalbon.com/machine_learning/nearest_neighbors/k-nearest_neighbors_classifer/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/nearest_neighbors/k-nearest_neighbors_classifer/</guid>
      <description>K-nearest neighbors classifier (KNN) is a simple and powerful classification learner.
KNN has three basic parts:
 $y_i$: The class of an observation (what we are trying to predict in the test data). $X_i$: The predictors/IVs/attributes of an observation. $K$: A positive number specified by the researcher. K denotes the number of observations closest to a particular observation that define its &amp;ldquo;neighborhood&amp;rdquo;. For example, K=2 means that each observation&amp;rsquo;s has a neighorhood comprising of the two other observations closest to it.</description>
    </item>
    
    <item>
      <title>LSTM Recurrent Neural Network</title>
      <link>https://chrisalbon.com/deep_learning/keras/lstm_recurrent_neural_network/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/lstm_recurrent_neural_network/</guid>
      <description>Oftentimes we have text data that we want to classify. While it is possible to use a type of convolutional network, we are going to focus on a more popular option: the recurrent neural network. The key feature of recurrent neural networks is that information loops back in the network. This gives recurrent neural networks a type of memory it can use to better understand sequential data. A popular choice type of recurrent neural network is the long short-term memory (LSTM) network which allows for information to loop backwards in the network.</description>
    </item>
    
    <item>
      <title>Lag A Time Feature</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/lag_a_time_feature/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/lag_a_time_feature/</guid>
      <description>Preliminaries # Load library import pandas as pd Create Date Data # Create data frame df = pd.DataFrame() # Create data df[&amp;#39;dates&amp;#39;] = pd.date_range(&amp;#39;1/1/2001&amp;#39;, periods=5, freq=&amp;#39;D&amp;#39;) df[&amp;#39;stock_price&amp;#39;] = [1.1,2.2,3.3,4.4,5.5] Lag Time Data By One Row # Lagged values by one row df[&amp;#39;previous_days_stock_price&amp;#39;] = df[&amp;#39;stock_price&amp;#39;].shift(1) # Show data frame df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    dates stock_price previous_days_stock_price     0 2001-01-01 1.</description>
    </item>
    
    <item>
      <title>Lambda Functions</title>
      <link>https://chrisalbon.com/python/basics/lambda_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/lambda_functions/</guid>
      <description> In Python, it is possible to string lambda functions together.
Create a series, called pipeline, that contains three mini functions pipeline = [lambda x: x **2 - 1 + 5, lambda x: x **20 - 2 + 3, lambda x: x **200 - 1 + 4] For each item in pipeline, run the lambda function with x = 3 for f in pipeline: print(f(3)) 13 3486784402 265613988875874769338781322035779626829233452653394495974574961739092490901302182994384699044004  </description>
    </item>
    
    <item>
      <title>Lasso Regression</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/lasso_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/lasso_regression/</guid>
      <description>Preliminaries # Load library from sklearn.linear_model import Lasso from sklearn.datasets import load_boston from sklearn.preprocessing import StandardScaler Load Boston Housing Dataset # Load data boston = load_boston() X = boston.data y = boston.target Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Fit Ridge Regression The hyperparameter, $\alpha$, lets us control how much we penalize the coefficients, with higher values of $\alpha$ creating simpler modelers. The ideal value of $\alpha$ should be tuned like any other hyperparameter.</description>
    </item>
    
    <item>
      <title>Linear Regression</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/linear_regression_scikitlearn/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/linear_regression_scikitlearn/</guid>
      <description>Sources: scikit-learn, DrawMyData.
The purpose of this tutorial is to give a brief introduction into the logic of statistical model building used in machine learning. If you want to read more about the theory behind this tutorial, check out An Introduction To Statistical Learning.
Let us get started.
Preliminary import pandas as pd from sklearn import linear_model import random import numpy as np %matplotlib inline Load Data With those libraries added, let us load the dataset (the dataset is avaliable in his site&amp;rsquo;s GitHub repo).</description>
    </item>
    
    <item>
      <title>Linear Regression Using Scikit-Learn</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/linear_regression_using_scikit-learn/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/linear_regression_using_scikit-learn/</guid>
      <description>Preliminaries # Load libraries from sklearn.linear_model import LinearRegression from sklearn.datasets import load_boston import warnings # Suppress Warning warnings.filterwarnings(action=&amp;#34;ignore&amp;#34;, module=&amp;#34;scipy&amp;#34;, message=&amp;#34;^internal gelsd&amp;#34;) Load Boston Housing Dataset # Load data boston = load_boston() X = boston.data y = boston.target Fit A Linear Regression # Create linear regression regr = LinearRegression() # Fit the linear regression model = regr.fit(X, y) View Intercept Term # View the intercept model.intercept_ 36.491103280361038  View Coefficients # View the feature coefficients model.</description>
    </item>
    
    <item>
      <title>List Unique Values In A pandas Column</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_list_unique_values_in_column/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_list_unique_values_in_column/</guid>
      <description>Special thanks to Bob Haffner for pointing out a better way of doing it.
Preliminaries # Import modules import pandas as pd # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create an example dataframe # Create an example dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3]} df = pd.</description>
    </item>
    
    <item>
      <title>Load A JSON File Into Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/load_json_file_into_pandas/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/load_json_file_into_pandas/</guid>
      <description> Preliminaries # Load library import pandas as pd Load JSON File # Create URL to JSON file (alternatively this can be a filepath) url = &amp;#39;https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json&amp;#39; # Load the first sheet of the JSON file into a data frame df = pd.read_json(url, orient=&amp;#39;columns&amp;#39;) # View the first ten rows df.head(10)   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    category datetime integer     0 0 2015-01-01 00:00:00 5   1 0 2015-01-01 00:00:01 5   10 0 2015-01-01 00:00:10 5   11 0 2015-01-01 00:00:11 5   12 0 2015-01-01 00:00:12 8   13 0 2015-01-01 00:00:13 9   14 0 2015-01-01 00:00:14 8   15 0 2015-01-01 00:00:15 8   16 0 2015-01-01 00:00:16 2   17 0 2015-01-01 00:00:17 1     </description>
    </item>
    
    <item>
      <title>Load An Excel File Into Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/load_excel_file_into_pandas/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/load_excel_file_into_pandas/</guid>
      <description> Preliminaries # Load library import pandas as pd Load Excel File # Create URL to Excel file (alternatively this can be a filepath) url = &amp;#39;https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.xlsx&amp;#39; # Load the first sheet of the Excel file into a data frame df = pd.read_excel(url, sheetname=0, header=1) # View the first ten rows df.head(10)   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    5 2015-01-01 00:00:00 0     0 5 2015-01-01 00:00:01 0   1 9 2015-01-01 00:00:02 0   2 6 2015-01-01 00:00:03 0   3 6 2015-01-01 00:00:04 0   4 9 2015-01-01 00:00:05 0   5 7 2015-01-01 00:00:06 0   6 1 2015-01-01 00:00:07 0   7 6 2015-01-01 00:00:08 0   8 9 2015-01-01 00:00:09 0   9 5 2015-01-01 00:00:10 0     </description>
    </item>
    
    <item>
      <title>Load Excel Spreadsheet As pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_load_xls/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_load_xls/</guid>
      <description># import modules import pandas as pd# Import the excel file and call it xls_file xls_file = pd.ExcelFile(&amp;#39;../data/example.xls&amp;#39;) xls_file &amp;lt;pandas.io.excel.ExcelFile at 0x111912be0&amp;gt;  # View the excel file&amp;#39;s sheet names xls_file.sheet_names [&#39;Sheet1&#39;]  # Load the xls file&amp;#39;s Sheet1 as a dataframe df = xls_file.parse(&amp;#39;Sheet1&amp;#39;) df    year deaths_attacker deaths_defender soldiers_attacker soldiers_defender wounded_attacker wounded_defender     0 1945 425 423 2532 37235 41 14   1 1956 242 264 6346 2523 214 1424   2 1964 323 1231 3341 2133 131 131   3 1969 223 23 6732 1245 12 12   4 1971 783 23 12563 2671 123 34   5 1981 436 42 2356 7832 124 124   6 1982 324 124 253 2622 264 1124   7 1992 3321 631 5277 3331 311 1431   8 1999 262 232 2732 2522 132 122   9 2004 843 213 6278 26773 623 2563     </description>
    </item>
    
    <item>
      <title>Load Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/load_images/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/load_images/</guid>
      <description>Preliminaries # Load library import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) # Show image plt.imshow(image, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() Load Image As RGB # Load image in color image_bgr = cv2.imread(&amp;#39;images/plane.jpg&amp;#39;, cv2.IMREAD_COLOR) # Convert to RGB image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) # Show image plt.imshow(image_rgb), plt.axis(&amp;#34;off&amp;#34;) plt.show() View Image Data # Show image data image array([[140, 136, 146, .</description>
    </item>
    
    <item>
      <title>Loading A CSV Into pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_importing_csv/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_importing_csv/</guid>
      <description>import modules import pandas as pd import numpy as np Create dataframe (that we will be importing) raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#34;.&amp;#34;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, &amp;#34;.&amp;#34;, &amp;#34;.&amp;#34;], &amp;#39;postTestScore&amp;#39;: [&amp;#34;25,000&amp;#34;, &amp;#34;94,000&amp;#34;, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df   .dataframe thead tr:only-child th { text-align: right; } .</description>
    </item>
    
    <item>
      <title>Loading Features From Dictionaries</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_features_from_dictionaries/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_features_from_dictionaries/</guid>
      <description>Preliminaries from sklearn.feature_extraction import DictVectorizer Create A Dictionary staff = [{&amp;#39;name&amp;#39;: &amp;#39;Steve Miller&amp;#39;, &amp;#39;age&amp;#39;: 33.}, {&amp;#39;name&amp;#39;: &amp;#39;Lyndon Jones&amp;#39;, &amp;#39;age&amp;#39;: 12.}, {&amp;#39;name&amp;#39;: &amp;#39;Baxter Morth&amp;#39;, &amp;#39;age&amp;#39;: 18.}] Convert Dictionary To Feature Matrix # Create an object for our dictionary vectorizer vec = DictVectorizer()# Fit then transform the staff dictionary with vec, then output an array vec.fit_transform(staff).toarray() array([[ 33., 0., 0., 1.], [ 12., 0., 1., 0.], [ 18., 1., 0., 0.]])  View Feature Names # Get Feature Names vec.</description>
    </item>
    
    <item>
      <title>Loading scikit-learn&#39;s Boston Housing Dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_boston_housing_dataset/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_boston_housing_dataset/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets import matplotlib.pyplot as plt  Load Boston Housing Dataset The Boston housing dataset is a famous dataset from the 1970s. It contains 506 observations on housing prices around Boston. It is often used in regression examples and contains 15 features.
# Load digits dataset boston = datasets.load_boston() # Create feature matrix X = boston.data # Create target vector y = boston.target # View the first observation&amp;#39;s feature values X[0] array([ 6.</description>
    </item>
    
    <item>
      <title>Loading scikit-learn&#39;s Digits Dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_digits-dataset/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_digits-dataset/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets import matplotlib.pyplot as plt  Load Digits Dataset Digits is a dataset of handwritten digits. Each feature is the intensity of one pixel of an 8 x 8 image.
# Load digits dataset digits = datasets.load_digits() # Create feature matrix X = digits.data # Create target vector y = digits.target # View the first observation&amp;#39;s feature values X[0] array([ 0., 0., 5.</description>
    </item>
    
    <item>
      <title>Loading scikit-learn&#39;s Iris Dataset</title>
      <link>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_iris_dataset/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/loading_scikit-learns_iris_dataset/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets import matplotlib.pyplot as plt  Load Iris Dataset The Iris flower dataset is one of the most famous databases for classification. It contains three classes (i.e. three species of flowers) with 50 observations per class.
# Load digits dataset iris = datasets.load_iris() # Create feature matrix X = iris.data # Create target vector y = iris.target # View the first observation&amp;#39;s feature values X[0] array([ 5.</description>
    </item>
    
    <item>
      <title>Logical Operations</title>
      <link>https://chrisalbon.com/python/basics/logical_operations/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/logical_operations/</guid>
      <description>Create some simulated variables x = 6y = 9z = 12 x or y x or y 6  x and y x and y 9  not x not x False  x is equal to y x == y False  x is not equal to y x != y True  One is less than two 1 &amp;lt; 2 True  Two is less than or equal to four 2 &amp;lt;= 4 True  Three is equal to five 3 == 5 False  Three is not equal to four 3 !</description>
    </item>
    
    <item>
      <title>Logistic Regression</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression/</guid>
      <description>Despite having &amp;ldquo;regression&amp;rdquo; in its name, a logistic regression is actually a widely used binary classifier (i.e. the target vector can only take two values). In a logistic regression, a linear model (e.g. $\beta_{0}+\beta_{1}x$) is included in a logistic (also called sigmoid) function, ${\frac{1}{1+e^{-z}}}$, such that:
$$P(y_i=1 \mid X)={\frac{1}{1+e^{-(\beta_{0}+\beta_{1}x)}}}$$
where $P(y_i=1 \mid X)$ is the probability of the $i$th observation&amp;rsquo;s target value, $y_i$, being class 1, $X$ is the training data, $\beta_0$ and $\beta_1$ are the parameters to be learned, and $e$ is Euler&amp;rsquo;s number.</description>
    </item>
    
    <item>
      <title>Logistic Regression On Very Large Data</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_on_very_large_data/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_on_very_large_data/</guid>
      <description>scikit-learn&amp;rsquo;s LogisticRegression offers a number of techniques for training a logistic regression, called solvers. Most of the time scikit-learn will select the best solver automatically for us or warn us that you cannot do some thing with that solver. However, there is one particular case we should be aware of.
While an exact explanation is beyond the bounds of this book, stochastic average gradient descent allows us to train a model much faster than other solvers when our data is very large.</description>
    </item>
    
    <item>
      <title>Logistic Regression With L1 Regularization</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_with_l1_regularization/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/logistic_regression_with_l1_regularization/</guid>
      <description>L1 regularization (also called least absolute deviations) is a powerful tool in data science. There are many tutorials out there explaining L1 regularization and I will not try to do that here. Instead, this tutorial is show the effect of the regularization parameter C on the coefficients and model accuracy.
Preliminaries import numpy as np from sklearn.linear_model import LogisticRegression from sklearn import datasets from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler Create The Data The dataset used in this tutorial is the famous iris dataset.</description>
    </item>
    
    <item>
      <title>Long To Wide Format</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_long_to_wide/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_long_to_wide/</guid>
      <description>import modules import pandas as pd Create &amp;ldquo;long&amp;rdquo; dataframe raw_data = {&amp;#39;patient&amp;#39;: [1, 1, 1, 2, 2], &amp;#39;obs&amp;#39;: [1, 2, 3, 1, 2], &amp;#39;treatment&amp;#39;: [0, 1, 0, 1, 0], &amp;#39;score&amp;#39;: [6252, 24243, 2345, 2342, 23525]} df = pd.DataFrame(raw_data, columns = [&amp;#39;patient&amp;#39;, &amp;#39;obs&amp;#39;, &amp;#39;treatment&amp;#39;, &amp;#39;score&amp;#39;]) df    patient obs treatment score     0 1 1 0 6252   1 1 2 1 24243   2 1 3 0 2345   3 2 1 1 2342   4 2 2 0 23525     Make a &amp;ldquo;wide&amp;rdquo; data Now we will create a &amp;ldquo;wide&amp;rdquo; dataframe with the rows by patient number, the columns being by observation number, and the cell values being the score values.</description>
    </item>
    
    <item>
      <title>Loop A Collection</title>
      <link>https://chrisalbon.com/scala/basics/loop_a_collection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/loop_a_collection/</guid>
      <description> Create A Vector Collection val vector = Vector(&amp;#34;Male&amp;#34;, 2, true) Loop Over The Collection // For each item in the collection, print the class type of the element vector.foreach((i: Any) =&amp;gt; println(i, i.getClass.getSimpleName)) (Male,String) (2,Integer) (true,Boolean)  // For each item in the collection vector.foreach { // If one of these, print &amp;#34;Man&amp;#34;  case &amp;#34;Male&amp;#34; | &amp;#34;M&amp;#34; | &amp;#34;Man&amp;#34; | &amp;#34;Gentleman&amp;#34; | &amp;#34;Boy&amp;#34; =&amp;gt; println(&amp;#34;Man&amp;#34;) // For everything else, print &amp;#34;Something Else&amp;#34;  case _ =&amp;gt; println(&amp;#34;Something Else&amp;#34;) } Man Something Else Something Else  </description>
    </item>
    
    <item>
      <title>Looping Over Two Lists</title>
      <link>https://chrisalbon.com/python/basics/looping_over_two_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/looping_over_two_lists/</guid>
      <description># Create a list of length 3: armies = [&amp;#39;Red Army&amp;#39;, &amp;#39;Blue Army&amp;#39;, &amp;#39;Green Army&amp;#39;] # Create a list of length 4: units = [&amp;#39;Red Infantry&amp;#39;, &amp;#39;Blue Armor&amp;#39;,&amp;#39;Green Artillery&amp;#39;,&amp;#39;Orange Aircraft&amp;#39;]# For each element in the first list, for army, unit in zip(armies, units): # Display the corresponding index element of the second list: print(army, &amp;#39;has the following options:&amp;#39;, unit) Red Army has the following options: Red Infantry Blue Army has the following options: Blue Armor Green Army has the following options: Green Artillery  Notice that the fourth item of the second list, orange aircraft, did not display.</description>
    </item>
    
    <item>
      <title>Lower Case Column Names In Pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_lowercase_column_names/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_lowercase_column_names/</guid>
      <description>Preliminaries # Import modules import pandas as pd # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create an example dataframe # Create an example dataframe data = {&amp;#39;NAME&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;YEAR&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;REPORTS&amp;#39;: [4, 24, 31, 2, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df    NAME REPORTS YEAR     Cochice Jason 4 2012   Pima Molly 24 2012   Santa Cruz Tina 31 2013   Maricopa Jake 2 2014   Yuma Amy 3 2014     Lowercase column values # Map the lowering function to all column names df.</description>
    </item>
    
    <item>
      <title>Make New Columns Using Functions</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_make_new_columns_using_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_make_new_columns_using_functions/</guid>
      <description># Import modules import pandas as pd# Example dataframe raw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;,&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;], &amp;#39;name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;, &amp;#39;Jacon&amp;#39;, &amp;#39;Ryaner&amp;#39;, &amp;#39;Sone&amp;#39;, &amp;#39;Sloan&amp;#39;, &amp;#39;Piger&amp;#39;, &amp;#39;Riani&amp;#39;, &amp;#39;Ali&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70, 25, 94, 57, 62, 70, 62, 70]} df = pd.</description>
    </item>
    
    <item>
      <title>Make Numbers Pretty</title>
      <link>https://chrisalbon.com/scala/basics/make_numbers_pretty/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/make_numbers_pretty/</guid>
      <description>Load The NumberFormat Library // Make value that is assigned to an instance of numberformat val make_pretty = java.text.NumberFormat.getInstance Make An Integer Pretty // Format 10000 to 10,000 make_pretty.format(10000) Make A Float Pretty // Format to 10000.1928 to 10,000.193 make_pretty.format(10000.1928) 10,000.193  Load The NumberFortmat Library Set For European Numbers // Set the locale to germany val germany = new java.util.Locale(&amp;#34;de&amp;#34;, &amp;#34;DE&amp;#34;) // Make value that is assigned to an instance of numberformat set to germany val make_pretty_de = java.</description>
    </item>
    
    <item>
      <title>Make Simulated Data For Classification</title>
      <link>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_classification/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_classification/</guid>
      <description>Preliminaries from sklearn.datasets import make_classification import pandas as pd Create Simulated Data # Create a simulated feature matrix and output vector with 100 samples, features, output = make_classification(n_samples = 100, # ten features n_features = 10, # five features that actually predict the output&amp;#39;s classes n_informative = 5, # five features that are random and unrelated to the output&amp;#39;s classes n_redundant = 5, # three output classes n_classes = 3, # with 20% of observations in the first class, 30% in the second class, # and 50% in the third class.</description>
    </item>
    
    <item>
      <title>Make Simulated Data For Clustering</title>
      <link>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_clustering/</guid>
      <description>Preliminaries from sklearn.datasets import make_blobs import matplotlib.pyplot as plt Make Data # Make the features (X) and output (y) with 200 samples, X, y = make_blobs(n_samples = 200, # two feature variables, n_features = 2, # three clusters, centers = 3, # with .5 cluster standard deviation, cluster_std = 0.5, # shuffled, shuffle = True) View Data # Create a scatterplot of the first and second features plt.scatter(X[:,0], X[:,1]) # Show the scatterplot plt.</description>
    </item>
    
    <item>
      <title>Make Simulated Data For Regression</title>
      <link>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/make_simulated_data_for_regression/</guid>
      <description>Preliminaries import pandas as pd from sklearn.datasets import make_regression Create Simulated Data # Generate fetures, outputs, and true coefficient of 100 samples, features, output, coef = make_regression(n_samples = 100, # three features n_features = 3, # where only two features are useful, n_informative = 2, # a single target value per observation n_targets = 1, # 0.0 standard deviation of the guassian noise noise = 0.0, # show the true coefficient used to generated the data coef = True) View Simulated Data # View the features of the first five rows pd.</description>
    </item>
    
    <item>
      <title>Making A Matplotlib Scatterplot From A Pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_scatterplot_from_pandas/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_scatterplot_from_pandas/</guid>
      <description>import modules %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;female&amp;#39;: [0, 1, 1, 0, 1], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;female&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df   .</description>
    </item>
    
    <item>
      <title>Map External Values To Dataframe Values in pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_map_values_to_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_map_values_to_values/</guid>
      <description>import modules import pandas as pd Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;city&amp;#39;: [&amp;#39;San Francisco&amp;#39;, &amp;#39;Baltimore&amp;#39;, &amp;#39;Miami&amp;#39;, &amp;#39;Douglas&amp;#39;, &amp;#39;Boston&amp;#39;]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;city&amp;#39;]) df    first_name last_name age city     0 Jason Miller 42 San Francisco   1 Molly Jacobson 52 Baltimore   2 Tina Ali 36 Miami   3 Jake Milner 24 Douglas   4 Amy Cooze 73 Boston     Create a dictionary of values city_to_state = { &amp;#39;San Francisco&amp;#39; : &amp;#39;California&amp;#39;, &amp;#39;Baltimore&amp;#39; : &amp;#39;Maryland&amp;#39;, &amp;#39;Miami&amp;#39; : &amp;#39;Florida&amp;#39;, &amp;#39;Douglas&amp;#39; : &amp;#39;Arizona&amp;#39;, &amp;#39;Boston&amp;#39; : &amp;#39;Massachusetts&amp;#39;} Map the values of the city_to_state dictionary to the values in the city variable df[&amp;#39;state&amp;#39;] = df[&amp;#39;city&amp;#39;].</description>
    </item>
    
    <item>
      <title>Mapping A Function To A Collection</title>
      <link>https://chrisalbon.com/scala/basics/mapping_a_function_to_a_collection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/mapping_a_function_to_a_collection/</guid>
      <description>Preliminaries import scala.collection.mutable.ArrayBuffer Create Collection // Create an array of strings var birds = ArrayBuffer(&amp;#34;Hawk&amp;#34;, &amp;#34;Condor&amp;#34;, &amp;#34;Eagle&amp;#34;, &amp;#34;Pigeon&amp;#34;) Create Function // Create a function that returns the length of a string val getLength = (i: String) =&amp;gt; i.length Map The Function To The Collection // Map the function to the array birds.map(getLength) ArrayBuffer(4, 6, 5, 6)  Map An Anonymous Function To The Collection // Map the anonymous function to the collection birds.</description>
    </item>
    
    <item>
      <title>Match A Symbol</title>
      <link>https://chrisalbon.com/regex/patterns/match_a_symbol/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_a_symbol/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;$100&amp;#39; Apply regex # Find all instances of the exact match &amp;#39;$&amp;#39; re.findall(r&amp;#39;\$&amp;#39;, text) [&#39;$&#39;]  </description>
    </item>
    
    <item>
      <title>Match A Unicode Character</title>
      <link>https://chrisalbon.com/regex/patterns/match_a_unicode_character/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_a_unicode_character/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;Microsoft.&amp;#39; Apply regex # Find any unicode character for a trademark re.findall(r&amp;#39;\u2122&amp;#39;, text) [&#39;&#39;]  </description>
    </item>
    
    <item>
      <title>Match A Word</title>
      <link>https://chrisalbon.com/regex/patterns/match_a_word/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_a_word/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find any word of three letters re.findall(r&amp;#39;\b...\b&amp;#39;, text) [&#39;The&#39;, &#39;fox&#39;, &#39;the&#39;]  </description>
    </item>
    
    <item>
      <title>Match Any Character</title>
      <link>https://chrisalbon.com/regex/patterns/match_any_character/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_any_character/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find anything with a &amp;#39;T&amp;#39; and then the next two characters re.findall(r&amp;#39;T..&amp;#39;, text) [&#39;The&#39;]  </description>
    </item>
    
    <item>
      <title>Match Any Of A List Of Characters</title>
      <link>https://chrisalbon.com/regex/patterns/match_any_of_a_list_of_symbols/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_any_of_a_list_of_symbols/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find all instances of any vowel re.findall(r&amp;#39;[aeiou]&amp;#39;, text) [&#39;e&#39;, &#39;u&#39;, &#39;i&#39;, &#39;o&#39;, &#39;o&#39;, &#39;u&#39;, &#39;e&#39;, &#39;o&#39;, &#39;e&#39;, &#39;e&#39;, &#39;a&#39;, &#39;o&#39;, &#39;e&#39;, &#39;a&#39;]  </description>
    </item>
    
    <item>
      <title>Match Any Of A Series Of Options</title>
      <link>https://chrisalbon.com/regex/patterns/match_any_of_series_of_characters/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_any_of_series_of_characters/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find any of fox, snake, or bear re.findall(r&amp;#39;fox|snake|bear&amp;#39;, text) [&#39;fox&#39;, &#39;bear&#39;]  </description>
    </item>
    
    <item>
      <title>Match Any Of A Series Of Words</title>
      <link>https://chrisalbon.com/regex/patterns/match_any_of_series_of_words/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_any_of_series_of_words/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find any of fox, snake, or bear re.findall(r&amp;#39;\b(fox|snake|bear)\b&amp;#39;, text) [&#39;fox&#39;, &#39;bear&#39;]  </description>
    </item>
    
    <item>
      <title>Match Dates</title>
      <link>https://chrisalbon.com/regex/patterns/match_dates/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_dates/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;My birthday is 09/15/1983. My brother\&amp;#39;s birthday is 01/01/01. My other two brothers have birthdays of 9/3/2001 and 09/1/83.&amp;#39; Apply regex # Find any text that fits the regex re.findall(r&amp;#39;\b[0-3]?[0-9]/[0-3]?[0-9]/(?:[0-9]{2})?[0-9]{2}\b&amp;#39;, text) [&#39;09/15/1983&#39;, &#39;01/01/01&#39;, &#39;9/3/2001&#39;, &#39;09/1/83&#39;]  </description>
    </item>
    
    <item>
      <title>Match Email Addresses</title>
      <link>https://chrisalbon.com/regex/patterns/match_email_addresses/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_email_addresses/</guid>
      <description>Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;My email is chris@hotmail.com, thanks! No, I am at bob@data.ninja.&amp;#39; Apply regex # Find all email addresses re.findall(r&amp;#39;[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\.[a-zA-Z0-9]+&amp;#39;, text) # Explanation: # This regex has three parts # [a-zA-Z0-9_.+-]+ Matches a word (the username) of any length # @[a-zA-Z0-9-]+ Matches a word (the domain name) of any length # \.</description>
    </item>
    
    <item>
      <title>Match Exact Text</title>
      <link>https://chrisalbon.com/regex/patterns/match_exact_text/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_exact_text/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Apply regex # Find all instances of the exact match &amp;#39;The&amp;#39; re.findall(r&amp;#39;The&amp;#39;, text) [&#39;The&#39;]  </description>
    </item>
    
    <item>
      <title>Match Integers Of Any Length</title>
      <link>https://chrisalbon.com/regex/patterns/match_integers_of_any_length/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_integers_of_any_length/</guid>
      <description>Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;21 scouts and 3 tanks fought against 4,003 protestors.&amp;#39; Apply regex # Find any character block that is a integer of any length re.findall(r&amp;#39;[1-9](?:\d{0,2})(?:,\d{3})*(?:\.\d*[1-9])?|0?\.\d*[1-9]|0&amp;#39;, text) [&#39;21&#39;, &#39;3&#39;, &#39;4,003&#39;]  Explanation from Justin Morgan
[1-9](?:\d{0,2}) #A sequence of 1-3 numerals not starting with 0 (?:,\d{3})* #Any number of three-digit groups, each preceded by a comma (?</description>
    </item>
    
    <item>
      <title>Match Text Between HTML Tags</title>
      <link>https://chrisalbon.com/regex/patterns/match_text_between_html_tags/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_text_between_html_tags/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;&amp;lt;p&amp;gt;The quick brown fox.&amp;lt;/p&amp;gt;&amp;lt;p&amp;gt;The lazy brown bear.&amp;lt;/p&amp;gt;&amp;#39; Apply regex # Find any text between &amp;#39;&amp;lt;p&amp;gt;&amp;#39; and &amp;#39;&amp;lt;/p&amp;gt;&amp;#39; re.findall(r&amp;#39;&amp;lt;p&amp;gt;(.*?)&amp;lt;/p&amp;gt;&amp;#39;, text) [&#39;The quick brown fox.&#39;, &#39;The lazy brown bear.&#39;]  </description>
    </item>
    
    <item>
      <title>Match Times</title>
      <link>https://chrisalbon.com/regex/patterns/match_times/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_times/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;Chris: 12:34am. Steve: 16:30&amp;#39; Apply regex # Find any text that fits the regex re.findall(r&amp;#39;([0-1]\d:[0-5]\d)\s*(?:AM|PM)?&amp;#39;, text) [&#39;12:34&#39;, &#39;16:30&#39;]  </description>
    </item>
    
    <item>
      <title>Match URLs</title>
      <link>https://chrisalbon.com/regex/patterns/match_urls/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_urls/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;My blog is http://www.chrisalbon.com and not http://chrisalbon.com&amp;#39; Apply regex # Find any ISBN-10 or ISBN-13 number re.findall(r&amp;#39;(http|ftp|https):\/\/([\w\-_]+(?:(?:\.[\w\-_]+)+))([\w\-\.,@?^=%&amp;amp;amp;:/~\+#]*[\w\-\@?^=%&amp;amp;amp;/~\+#])?&amp;#39;, text) [(&#39;http&#39;, &#39;www.chrisalbon.com&#39;, &#39;&#39;), (&#39;http&#39;, &#39;chrisalbon.com&#39;, &#39;&#39;)]  </description>
    </item>
    
    <item>
      <title>Match US Phone Numbers</title>
      <link>https://chrisalbon.com/regex/patterns/match_us_phone_numbers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_us_phone_numbers/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;My phone number is 415-333-3922. His phone number is 4239389283&amp;#39; Apply regex # Find any text that fits the regex re.findall(r&amp;#39;\(?([2-9][0-8][0-9])\)?[-.]?([2-9][0-9]{2})[-.]?([0-9]{4})&amp;#39;, text) [(&#39;415&#39;, &#39;333&#39;, &#39;3922&#39;), (&#39;423&#39;, &#39;938&#39;, &#39;9283&#39;)]  </description>
    </item>
    
    <item>
      <title>Match US and UK Spellings</title>
      <link>https://chrisalbon.com/regex/patterns/match_us_uk_spellings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_us_uk_spellings/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;It\s center and not centre.&amp;#39; Apply regex # Find any ISBN-10 or ISBN-13 number re.findall(r&amp;#39;\bcent(?:er|re)\b&amp;#39;, text) [&#39;center&#39;, &#39;centre&#39;]  </description>
    </item>
    
    <item>
      <title>Match Words With A Certain Ending</title>
      <link>https://chrisalbon.com/regex/patterns/match_words_with_certain_ending/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_words_with_certain_ending/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;Capitalism, Communism, Neorealism, Liberalism&amp;#39; Apply regex # Find any word ending in &amp;#39;ism&amp;#39; re.findall(r&amp;#39;\b\w*ism\b&amp;#39;, text) # Specific: # \b - start of the word # \w* - a word of any length # ism\b - with &amp;#39;ism&amp;#39;at the end [&#39;Capitalism&#39;, &#39;Communism&#39;, &#39;Neorealism&#39;, &#39;Liberalism&#39;]  </description>
    </item>
    
    <item>
      <title>Match ZIP Codes</title>
      <link>https://chrisalbon.com/regex/patterns/match_zip_codes/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/regex/patterns/match_zip_codes/</guid>
      <description> Preliminaries # Load regex package import re Create some text # Create a variable containing a text string text = &amp;#39;3829 South Ave Street, Pheonix, AZ 34923&amp;#39; Apply regex # Find any ISBN-10 or ISBN-13 number re.findall(r&amp;#39;[0-9]{5}(?:-[0-9]{4})?&amp;#39;, text) [&#39;34923&#39;]  </description>
    </item>
    
    <item>
      <title>Matching Conditions</title>
      <link>https://chrisalbon.com/scala/basics/matching_conditions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/matching_conditions/</guid>
      <description> Create A String // Create some strings val text1 = &amp;#34;Man&amp;#34; val text2 = &amp;#34;F&amp;#34; val text3 = &amp;#34;Dog&amp;#34; Create A Function That Uses A Match Expression // Define a function that takes in a string, and matches it def findGender(word: String) = word match { // If any of these words, return &amp;#34;Woman&amp;#34;  case &amp;#34;Female&amp;#34; | &amp;#34;F&amp;#34; | &amp;#34;Woman&amp;#34; | &amp;#34;Lady&amp;#34; | &amp;#34;Girl&amp;#34; =&amp;gt; &amp;#34;Woman&amp;#34; // If any of these words, return &amp;#34;Man&amp;#34;  case &amp;#34;Male&amp;#34; | &amp;#34;M&amp;#34; | &amp;#34;Man&amp;#34; | &amp;#34;Gentleman&amp;#34; | &amp;#34;Boy&amp;#34; =&amp;gt; &amp;#34;Man&amp;#34; // If anything else, return &amp;#34;Unknown&amp;#34;  case _ =&amp;gt; &amp;#34;Unknown&amp;#34; } Apply The Function To The Strings findGender(text1) Man  findGender(text2) Woman  findGender(text3) Unknown  </description>
    </item>
    
    <item>
      <title>Mathematical Operations</title>
      <link>https://chrisalbon.com/python/basics/math_operations/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/math_operations/</guid>
      <description>Import the math module import math Display the value of pi. math.pi 3.141592653589793  Display the value of e. math.e 2.718281828459045  Sine, cosine, and tangent math.sin(2 * math.pi / 180) 0.03489949670250097  Exponent 2 ** 4, pow(2, 4) (16, 16)  Absolute value abs(-20) 20  Summation sum((1, 2, 3, 4)) 10  Minimum min(3, 9, 10, 12) 3  Maximum max(3, 5, 10, 15) 15  Floor math.</description>
    </item>
    
    <item>
      <title>Matplotlib, A Simple Example</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_simple_example/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_simple_example/</guid>
      <description> Tell Jupyter to load matplotlib and display all visuals created inline (that is, on this page) %matplotlib inline Import matplotlib&amp;rsquo;s pyplot module import matplotlib.pyplot as pyplot Create a simple plot pyplot.plot([1.6, 2.7]) [&amp;lt;matplotlib.lines.Line2D at 0x10c4e7978&amp;gt;]  </description>
    </item>
    
    <item>
      <title>Meanshift Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/meanshift_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/meanshift_clustering/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.cluster import MeanShift Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Conduct Meanshift Clustering MeanShift has two important parameters we should be aware of. First, bandwidth sets radius of the area (i.e. kernel) an observation uses to determine the direction to shift.</description>
    </item>
    
    <item>
      <title>Mine Twitter&#39;s Stream For Hashtags Or Words</title>
      <link>https://chrisalbon.com/python/other/mine_a_twitter_hashtags_and_words/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/other/mine_a_twitter_hashtags_and_words/</guid>
      <description>This is a script which monitor&amp;rsquo;s Twitter for tweets containing certain hashtags, words, or phrases. When one of those appears, it saves that tweet, and the user&amp;rsquo;s information to a csv file. A similar version of this script is available on GitHub here. The main difference between the code presented here and the repo is that here I am added extensive comments in the code explaining what is happening. Also, the code below runs as a Jupyter notebook.</description>
    </item>
    
    <item>
      <title>Mini-Batch k-Means Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/minibatch_k-means_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/minibatch_k-means_clustering/</guid>
      <description>Mini-batch k-means works similarly to the k-means algorithm discussed in the last recipe. Without going into too much detail, the difference is that in mini-batch k-means the most computationally costly step is conducted on only a random sample of observations as opposed to all observations. This approach can significantly reduce the time required for the algorithm to find convergence (i.e. fit the data) with only a small cost in quality.</description>
    </item>
    
    <item>
      <title>Missing Data In pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_missing_data/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_missing_data/</guid>
      <description>import modules import pandas as pd import numpy as np Create dataframe with missing values raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, np.nan, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, np.nan, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, np.nan, 36, 24, 73], &amp;#39;sex&amp;#39;: [&amp;#39;m&amp;#39;, np.nan, &amp;#39;f&amp;#39;, &amp;#39;m&amp;#39;, &amp;#39;f&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, np.nan, np.nan, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, np.nan, np.nan, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;sex&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age sex preTestScore postTestScore     0 Jason Miller 42.</description>
    </item>
    
    <item>
      <title>Mocking Functions</title>
      <link>https://chrisalbon.com/python/basics/mocking_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/mocking_functions/</guid>
      <description>Preliminaries import unittest import mock from math import exp The Scenario Imagine we have a function that takes in some external API or database and we want to test that function, but with fake (or mocked) inputs. The Python mock library lets us do that.
For this tutorial pretend that math.exp is some expensive operation (e.g. database query, API call, etc) that costs \$10,000 every time we use it. To test it without paying \$10,000, we can create mock_function which imitates the behavior of math.</description>
    </item>
    
    <item>
      <title>Model Selection Using Grid Search</title>
      <link>https://chrisalbon.com/machine_learning/model_selection/model_selection_using_grid_search/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_selection/model_selection_using_grid_search/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn import datasets from sklearn.linear_model import LogisticRegression from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import GridSearchCV from sklearn.pipeline import Pipeline # Set random seed np.random.seed(0) Load Iris Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Pipeline With Model Selection Search Space Notice that we include both multiple possible learning algorithms and multiple possible hyperparameter values to search over.</description>
    </item>
    
    <item>
      <title>Monitor A Website For Changes With Python</title>
      <link>https://chrisalbon.com/python/web_scraping/monitor_a_website/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/web_scraping/monitor_a_website/</guid>
      <description>In this snippet, we create a continous loop that, at set times, scrapes a website, checks to see if it contains some text and if so, emails me. Specifically I used this script to find when Venture Beat had published an article about my company.
It should be noted that there are more efficient ways of setting scripts to run at certain times, notable cron. However, this is a quick and dirty solution.</description>
    </item>
    
    <item>
      <title>Moving Averages In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_moving_average/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_moving_average/</guid>
      <description>Import Modules # Import pandas import pandas as pd Create Dataframe # Create data data = {&amp;#39;score&amp;#39;: [1,1,1,2,2,2,3,3,3]} # Create dataframe df = pd.DataFrame(data) # View dataframe df   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    score     0 1   1 1   2 1   3 2   4 2   5 2   6 3   7 3   8 3     Calculate Rolling Mean # Calculate the moving average.</description>
    </item>
    
    <item>
      <title>Multinomial Logistic Regression</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/multinomial_logistic_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/multinomial_logistic_regression/</guid>
      <description>In multinomial logistic regression (MLR) the logistic function we saw in Recipe 15.1 is replaced with a softmax function:
$$P(y_i=k \mid X)={\frac {e^{\beta_{k}x_{i}}}{{\sum_{j=1}^{K}}e^{\beta_{j}x_{i}}}}$$
where $P(y_i=k \mid X)$ is the probability the $i$th observation&amp;rsquo;s target value, $y_i$, is class $k$, and $K$ is the total number of classes. One practical advantage of the MLR is that its predicted probabilities using the predict_proba method are more reliable (i.e. better calibrated).
Preliminaries # Load libraries from sklearn.</description>
    </item>
    
    <item>
      <title>Multinomial Naive Bayes Classifier</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/multinomial_naive_bayes_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/multinomial_naive_bayes_classifier/</guid>
      <description>Multinomial naive Bayes works similar to Gaussian naive Bayes, however the features are assumed to be multinomially distributed. In practice, this means that this classifier is commonly used when we have discrete data (e.g. movie ratings ranging 1 and 5).
Preliminaries # Load libraries import numpy as np from sklearn.naive_bayes import MultinomialNB from sklearn.feature_extraction.text import CountVectorizer Create Text Data # Create text text_data = np.array([&amp;#39;I love Brazil. Brazil!&amp;#39;, &amp;#39;Brazil is best&amp;#39;, &amp;#39;Germany beats both&amp;#39;]) Create Bag Of Words # Create bag of words count = CountVectorizer() bag_of_words = count.</description>
    </item>
    
    <item>
      <title>Mutable Maps</title>
      <link>https://chrisalbon.com/scala/basics/mutable_maps/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/mutable_maps/</guid>
      <description>Create A Mutable Map val army = collection.mutable.Map( &amp;#34;Tank&amp;#34; -&amp;gt; &amp;#34;A-1 Abrams&amp;#34;, &amp;#34;Aircraft&amp;#34; -&amp;gt; &amp;#34;F35&amp;#34;, &amp;#34;Ship&amp;#34; -&amp;gt; &amp;#34;Nimitz Class&amp;#34; ) Add An Element // Add an element army += (&amp;#34;APC&amp;#34; -&amp;gt; &amp;#34;Bradley IFC&amp;#34;) // Add an element (alternative) army.put(&amp;#34;Weapon&amp;#34;, &amp;#34;M60&amp;#34;) None  Add Multiple Elements // Add two elements army += (&amp;#34;Helicopter&amp;#34; -&amp;gt; &amp;#34;Apache&amp;#34;, &amp;#34;Missile&amp;#34; -&amp;gt; &amp;#34;Sidewinder&amp;#34;) Map(Weapon -&amp;gt; M60, APC -&amp;gt; Bradley IFC, Missile -&amp;gt; Sidewinder, Tank -&amp;gt; A-1 Abrams, Aircraft -&amp;gt; F35, Helicopter -&amp;gt; Apache, Ship -&amp;gt; Nimitz Class)  Remove An Element // Remove an element army -= &amp;#34;Ship&amp;#34; // Remove an element (alternative) army.</description>
    </item>
    
    <item>
      <title>N Dimension Arrays</title>
      <link>https://chrisalbon.com/scala/basics/n_dimension_arrays/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/n_dimension_arrays/</guid>
      <description> Create 2 x 2 Array // Set the number of rows and columns val rows = 2 val columns = 2 // Create an array of integers that is 2x2 val matrix = Array.ofDim[Int](rows, columns)// View array matrix Array(Array(0, 0), Array(0, 0))  Add Values To Array // First row, first column matrix(0)(0) = 1 // First row, second column matrix(0)(1) = 0 // Second row, first column matrix(1)(0) = 0 // Second row, second column matrix(1)(1) = 1// View array matrix Array(Array(1, 0), Array(0, 1))  </description>
    </item>
    
    <item>
      <title>Naive Bayes Classifier From Scratch</title>
      <link>https://chrisalbon.com/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/naive_bayes/naive_bayes_classifier_from_scratch/</guid>
      <description>Naive bayes is simple classifier known for doing well when only a small number of observations is available. In this tutorial we will create a gaussian naive bayes classifier from scratch and use it to predict the class of a previously unseen data point. This tutorial is based on an example on Wikipedia&amp;rsquo;s naive bayes classifier page, I have implemented it in Python and tweaked some notation to improve explanation.</description>
    </item>
    
    <item>
      <title>Nested Cross Validation</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/nested_cross_validation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/nested_cross_validation/</guid>
      <description>Often we want to tune the parameters of a model (for example, C in a support vector machine). That is, we want to find the value of a parameter that minimizes our loss function. The best way to do this is cross validation:
 Set the parameter you want to tune to some value. Split your data into K &amp;lsquo;folds&amp;rsquo; (sections). Train your model using K-1 folds using the parameter value.</description>
    </item>
    
    <item>
      <title>Nested For Loops Using List Comprehension</title>
      <link>https://chrisalbon.com/python/basics/nested_for_loops_using_list_comprehension/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/nested_for_loops_using_list_comprehension/</guid>
      <description># Create two lists squads = [&amp;#34;1st Squad&amp;#34;, &amp;#39;2nd Squad&amp;#39;, &amp;#39;3rd Squad&amp;#39;] regiments = [&amp;#34;51st Regiment&amp;#34;, &amp;#39;15th Regiment&amp;#39;, &amp;#39;12th Regiment&amp;#39;]# Create a tuple for each regiment in regiments, for each squad in sqauds [(regiment, squad) for regiment in regiments for squad in squads ] [(&#39;51st Regiment&#39;, &#39;1st Squad&#39;), (&#39;51st Regiment&#39;, &#39;2nd Squad&#39;), (&#39;51st Regiment&#39;, &#39;3rd Squad&#39;), (&#39;15th Regiment&#39;, &#39;1st Squad&#39;), (&#39;15th Regiment&#39;, &#39;2nd Squad&#39;), (&#39;15th Regiment&#39;, &#39;3rd Squad&#39;), (&#39;12th Regiment&#39;, &#39;1st Squad&#39;), (&#39;12th Regiment&#39;, &#39;2nd Squad&#39;), (&#39;12th Regiment&#39;, &#39;3rd Squad&#39;)]  </description>
    </item>
    
    <item>
      <title>Nesting Lists</title>
      <link>https://chrisalbon.com/python/basics/nesting_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/nesting_lists/</guid>
      <description># Create a list of three nested lists, each with three items state_regions = [[&amp;#39;California&amp;#39;, &amp;#39;Oregon&amp;#39;, &amp;#39;Washington&amp;#39;], [&amp;#39;Texas&amp;#39;,&amp;#39;Georgia&amp;#39;,&amp;#39;Alabama&amp;#39;], [&amp;#39;Maine&amp;#39;,&amp;#39;Vermont&amp;#39;,&amp;#39;New York&amp;#39;]]# View the list state_regions [[&#39;California&#39;, &#39;Oregon&#39;, &#39;Washington&#39;], [&#39;Texas&#39;, &#39;Georgia&#39;, &#39;Alabama&#39;], [&#39;Maine&#39;, &#39;Vermont&#39;, &#39;New York&#39;]]  # Print the second list&amp;#39;s third item state_regions[1][2] &#39;Alabama&#39;  </description>
    </item>
    
    <item>
      <title>Neural Network Early Stopping</title>
      <link>https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/neural_network_early_stopping/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers from keras.callbacks import EarlyStopping, ModelCheckpoint # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Text Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.</description>
    </item>
    
    <item>
      <title>Neural Network Weight Regularization</title>
      <link>https://chrisalbon.com/deep_learning/keras/neural_network_weight_regularization/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/neural_network_weight_regularization/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers from keras import regularizers # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Text Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Normalize A Column In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_normalize_column/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_normalize_column/</guid>
      <description>Preliminaries # Import required modules import pandas as pd from sklearn import preprocessing # Set charts to view inline %matplotlib inline Create Unnormalized Data # Create an example dataframe with a column of unnormalized data data = {&amp;#39;score&amp;#39;: [234,24,14,27,-74,46,73,-18,59,160]} df = pd.DataFrame(data) df  .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    score     0 234   1 24   2 14   3 27   4 -74   5 46   6 73   7 -18   8 59   9 160     # View the unnormalized data df[&amp;#39;score&amp;#39;].</description>
    </item>
    
    <item>
      <title>Normalizing Observations</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/normalizing_observations/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/normalizing_observations/</guid>
      <description>Preliminaries # Load libraries from sklearn.preprocessing import Normalizer import numpy as np Create Feature Matrix # Create feature matrix X = np.array([[0.5, 0.5], [1.1, 3.4], [1.5, 20.2], [1.63, 34.4], [10.9, 3.3]]) Normalize Observations Normalizer rescales the values on individual observations to have unit norm (the sum of their lengths is one).
# Create normalizer normalizer = Normalizer(norm=&amp;#39;l2&amp;#39;) # Transform feature matrix normalizer.transform(X) array([[ 0.70710678, 0.70710678], [ 0.30782029, 0.95144452], [ 0.</description>
    </item>
    
    <item>
      <title>Numpy Array Basics</title>
      <link>https://chrisalbon.com/python/basics/numpy_array_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/numpy_array_basics/</guid>
      <description># Import modules import numpy as np# Create a list battle_deaths = [3246, 326, 2754, 2547, 2457, 3456] battle_deaths [3246, 326, 2754, 2547, 2457, 3456]  # Create an array from numpy deaths = np.array(battle_deaths) deaths array([3246, 326, 2754, 2547, 2457, 3456])  # Create an array of zeros defectors = np.zeros(6) defectors array([ 0., 0., 0., 0., 0., 0.])  # Create a range from 0 to 100 zero_to_99 = np.</description>
    </item>
    
    <item>
      <title>One Vs. Rest Logistic Regression</title>
      <link>https://chrisalbon.com/machine_learning/logistic_regression/one-vs-rest_logistic_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/logistic_regression/one-vs-rest_logistic_regression/</guid>
      <description>On their own, logistic regressions are only binary classifiers, meaning they cannot handle target vectors with more than two classes. However, there are clever extensions to logistic regression to do just that. In one-vs-rest logistic regression (OVR) a separate model is trained for each class predicted whether an observation is that class or not (thus making it a binary classification problem). It assumes that each classification problem (e.g. class 0 or not) is independent.</description>
    </item>
    
    <item>
      <title>One-Hot Encode Features With Multiple Labels</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/one-hot_encode_features_with_multiple_labels/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/one-hot_encode_features_with_multiple_labels/</guid>
      <description>Preliminaries # Load libraries from sklearn.preprocessing import MultiLabelBinarizer import numpy as np Create Data # Create NumPy array y = [(&amp;#39;Texas&amp;#39;, &amp;#39;Florida&amp;#39;), (&amp;#39;California&amp;#39;, &amp;#39;Alabama&amp;#39;), (&amp;#39;Texas&amp;#39;, &amp;#39;Florida&amp;#39;), (&amp;#39;Delware&amp;#39;, &amp;#39;Florida&amp;#39;), (&amp;#39;Texas&amp;#39;, &amp;#39;Alabama&amp;#39;)] One-hot Encode Data # Create MultiLabelBinarizer object one_hot = MultiLabelBinarizer() # One-hot encode data one_hot.fit_transform(y) array([[0, 0, 0, 1, 1], [1, 1, 0, 0, 0], [0, 0, 0, 1, 1], [0, 0, 1, 1, 0], [1, 0, 0, 0, 1]])  View Column Headers # View classes one_hot.</description>
    </item>
    
    <item>
      <title>One-Hot Encode Nominal Categorical Features</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/one-hot_encode_nominal_categorical_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/one-hot_encode_nominal_categorical_features/</guid>
      <description>Preliminaries # Load libraries import numpy as np import pandas as pd from sklearn.preprocessing import OneHotEncoder Create Data With One Class Label # Create NumPy array x = np.array([[&amp;#39;Texas&amp;#39;], [&amp;#39;California&amp;#39;], [&amp;#39;Texas&amp;#39;], [&amp;#39;Delaware&amp;#39;], [&amp;#39;Texas&amp;#39;]]) One-hot Encode Data (Method 1) # Create LabelBinzarizer object one_hot = OneHotEncoder() # One-hot encode data one_hot.fit_transform(x) &amp;lt;5x3 sparse matrix of type &#39;&amp;lt;class &#39;numpy.float64&#39;&amp;gt;&#39; with 5 stored elements in Compressed Sparse Row format&amp;gt;  View Column Headers # View classes one_hot.</description>
    </item>
    
    <item>
      <title>Parallel Processing</title>
      <link>https://chrisalbon.com/python/basics/parallel_processing/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/parallel_processing/</guid>
      <description>This tutorial is inspired by Chris Kiehl&amp;rsquo;s great post on multiprocessing.
Preliminaries from multiprocessing import Pool from multiprocessing.dummy import Pool as ThreadPool  Create Some Data # Create a list of some data data = range(29999) Create An Operation To Execute On The Data # Create a function that takes a data point def some_function(datum): # and returns the datum raised to the power of itself return datum**datum Traditional Approach %%time # Create an empty for the results results = [] # For each value in the data for datum in data: # Append the output of the function when applied to that datum results.</description>
    </item>
    
    <item>
      <title>Parse HTML</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/parse_html/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/parse_html/</guid>
      <description> Preliminaries # Load library from bs4 import BeautifulSoup Create HTML # Create some HTML code html = &amp;#34;&amp;lt;div class=&amp;#39;full_name&amp;#39;&amp;gt;&amp;lt;span style=&amp;#39;font-weight:bold&amp;#39;&amp;gt;Masego&amp;lt;/span&amp;gt; Azra&amp;lt;/div&amp;gt;&amp;#34; Parse HTML # Parse html soup = BeautifulSoup(html, &amp;#34;lxml&amp;#34;) # Find the div with the class &amp;#34;full_name&amp;#34;, show text soup.find(&amp;#34;div&amp;#34;, { &amp;#34;class&amp;#34; : &amp;#34;full_name&amp;#34; }).text &#39;Masego Azra&#39;  </description>
    </item>
    
    <item>
      <title>Partial Function Applications</title>
      <link>https://chrisalbon.com/python/basics/partial_function_applications/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/partial_function_applications/</guid>
      <description> Partial function application allows us to create &amp;ldquo;functions&amp;rdquo; from other functions with pre-filled arguments. This can be very useful when we want to pipe the output of one function into a function requiring two functions.
Preliminaries from functools import partial Create A Function def multiply(x, y): return x * y Create A Function With Y Pre-Filled double = partial(multiply, y=2) Run The Partial Function double(3) 6  </description>
    </item>
    
    <item>
      <title>Partial Functions</title>
      <link>https://chrisalbon.com/scala/basics/partial_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/partial_functions/</guid>
      <description> isDefinedAt determines which inputs are accepted. apply is the actual operation.
Create A Partial Function // Create a new partial function that inputs a integer and outputs a string val dayOfTheWeek = new PartialFunction[Int, String] { // Create an array with the days of the week  val days = Array(&amp;#34;Monday&amp;#34;, &amp;#34;Tuesday&amp;#34;, &amp;#34;Wednesday&amp;#34;, &amp;#34;Thursday&amp;#34;, &amp;#34;Friday&amp;#34;, &amp;#34;Saturday&amp;#34;, &amp;#34;Sunday&amp;#34;) // Only accept input integers that are between 0 and 6  def isDefinedAt(i: Int) = i &amp;gt; 0 &amp;amp;&amp;amp; i &amp;lt; 6 // If accepted, return the correct day of the week string  def apply(i: Int) = days(i-1) } Run The Partial Function dayOfTheWeek(2) Tuesday  </description>
    </item>
    
    <item>
      <title>Pearsons Correlation Coefficient</title>
      <link>https://chrisalbon.com/statistics/frequentist/pearsons_correlation_coefficient/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/pearsons_correlation_coefficient/</guid>
      <description>Based on this StackOverflow answer by cbare.
Preliminaries import statistics as stats Create Data x = [1,2,3,4,5,6,7,8,9] y = [2,1,2,4.5,7,6.5,6,9,9.5] Calculate Pearson&amp;rsquo;s Correlation Coefficient There are a number of equivalent expression ways to calculate Pearson&amp;rsquo;s correlation coefficient (also called Pearson&amp;rsquo;s r). Here is one.
$$r={\frac {1}{n-1}}\sum_{i=1}^{n}\left({\frac {x_{i}-{\bar {x}}}{s_{x}}}\right)\left({\frac {y_{i}-{\bar {y}}}{s_{y}}}\right)$$
where $s_{x}$ and $s_{y}$ are the sample standard deviation for $x$ and $y$, and $\left({\frac {x_{i}-{\bar {x}}}{s_{x}}}\right)$ is the standard score for $x$ and $y$.</description>
    </item>
    
    <item>
      <title>Perceptron In Scikit</title>
      <link>https://chrisalbon.com/machine_learning/basics/perceptron_in_scikit-learn/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/perceptron_in_scikit-learn/</guid>
      <description>A perceptron learner was one of the earliest machine learning techniques and still from the foundation of many modern neural networks. In this tutorial we use a perceptron learner to classify the famous iris dataset. This tutorial was inspired by Python Machine Learning by Sebastian Raschka.
Preliminaries # Load required libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.linear_model import Perceptron from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score import numpy as np Load The Iris Data # Load the iris dataset iris = datasets.</description>
    </item>
    
    <item>
      <title>Pie Chart In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_pie_chart/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_pie_chart/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt Create dataframe raw_data = {&amp;#39;officer_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;jan_arrests&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;feb_arrests&amp;#39;: [25, 94, 57, 62, 70], &amp;#39;march_arrests&amp;#39;: [5, 43, 23, 23, 51]} df = pd.DataFrame(raw_data, columns = [&amp;#39;officer_name&amp;#39;, &amp;#39;jan_arrests&amp;#39;, &amp;#39;feb_arrests&amp;#39;, &amp;#39;march_arrests&amp;#39;]) df    officer_name jan_arrests feb_arrests march_arrests     0 Jason 4 25 5   1 Molly 24 94 43   2 Tina 31 57 23   3 Jake 2 62 23   4 Amy 3 70 51     # Create a column with the total arrests for each officer df[&amp;#39;total_arrests&amp;#39;] = df[&amp;#39;jan_arrests&amp;#39;] + df[&amp;#39;feb_arrests&amp;#39;] + df[&amp;#39;march_arrests&amp;#39;] df    officer_name jan_arrests feb_arrests march_arrests total_arrests     0 Jason 4 25 5 34   1 Molly 24 94 43 161   2 Tina 31 57 23 111   3 Jake 2 62 23 87   4 Amy 3 70 51 124     Make plot # Create a list of colors (from iWantHue) colors = [&amp;#34;#E13F29&amp;#34;, &amp;#34;#D69A80&amp;#34;, &amp;#34;#D63B59&amp;#34;, &amp;#34;#AE5552&amp;#34;, &amp;#34;#CB5C3B&amp;#34;, &amp;#34;#EB8076&amp;#34;, &amp;#34;#96624E&amp;#34;] # Create a pie chart plt.</description>
    </item>
    
    <item>
      <title>Pipelines With Parameter Optimization</title>
      <link>https://chrisalbon.com/machine_learning/model_selection/pipelines_with_parameter_optimization/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_selection/pipelines_with_parameter_optimization/</guid>
      <description>Preliminaries # Import required packages import numpy as np from sklearn import linear_model, decomposition, datasets from sklearn.pipeline import Pipeline from sklearn.model_selection import GridSearchCV, cross_val_score from sklearn.preprocessing import StandardScaler Load Data # Load the breast cancer data dataset = datasets.load_breast_cancer() # Create X from the dataset&amp;#39;s features X = dataset.data # Create y from the dataset&amp;#39;s output y = dataset.target Create Pipelines # Create an scaler object sc = StandardScaler() # Create a pca object pca = decomposition.</description>
    </item>
    
    <item>
      <title>Pivot Tables In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_pivot_tables/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_pivot_tables/</guid>
      <description>import modules import pandas as pd Create dataframe raw_data = {&amp;#39;regiment&amp;#39;: [&amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Nighthawks&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Dragoons&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;, &amp;#39;Scouts&amp;#39;], &amp;#39;company&amp;#39;: [&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;,&amp;#39;1st&amp;#39;, &amp;#39;1st&amp;#39;, &amp;#39;2nd&amp;#39;, &amp;#39;2nd&amp;#39;], &amp;#39;TestScore&amp;#39;: [4, 24, 31, 2, 3, 4, 24, 31, 2, 3, 2, 3]} df = pd.DataFrame(raw_data, columns = [&amp;#39;regiment&amp;#39;, &amp;#39;company&amp;#39;, &amp;#39;TestScore&amp;#39;]) df    regiment company TestScore     0 Nighthawks 1st 4   1 Nighthawks 1st 24   2 Nighthawks 2nd 31   3 Nighthawks 2nd 2   4 Dragoons 1st 3   5 Dragoons 1st 4   6 Dragoons 2nd 24   7 Dragoons 2nd 31   8 Scouts 1st 2   9 Scouts 1st 3   10 Scouts 2nd 2   11 Scouts 2nd 3     Create a pivot table of group means, by company and regiment pd.</description>
    </item>
    
    <item>
      <title>Plot The Learning Curve</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_learning_curve/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_learning_curve/</guid>
      <description>Preliminaries # Load libraries import numpy as np import matplotlib.pyplot as plt from sklearn.ensemble import RandomForestClassifier from sklearn.datasets import load_digits from sklearn.model_selection import learning_curve Load Digits Dataset # Load data digits = load_digits() # Create feature matrix and target vector X, y = digits.data, digits.target Plot Learning Curve # Create CV training and test scores for various training set sizes train_sizes, train_scores, test_scores = learning_curve(RandomForestClassifier(), X, y, # Number of folds in cross-validation cv=10, # Evaluation metric scoring=&amp;#39;accuracy&amp;#39;, # Use all computer cores n_jobs=-1, # 50 different sizes of the training set train_sizes=np.</description>
    </item>
    
    <item>
      <title>Plot The Receiving Operating Characteristic Curve</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_receiving_operating_characteristic_curve/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_receiving_operating_characteristic_curve/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import make_classification from sklearn.linear_model import LogisticRegression from sklearn.metrics import roc_curve, roc_auc_score from sklearn.model_selection import train_test_split import matplotlib.pyplot as plt Generate Features And Target # Create feature matrix and target vector X, y = make_classification(n_samples=10000, n_features=10, n_classes=2, n_informative=3, random_state=3) Split Data Intro Training And Test Sets # Split into training and test sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1) Training Binary Classifier # Create classifier clf = LogisticRegression() # Train model clf.</description>
    </item>
    
    <item>
      <title>Plot The Support Vector Classifiers Hyperplane</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/plot_support_vector_classifier_hyperplane/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/plot_support_vector_classifier_hyperplane/</guid>
      <description>Preliminaries # Load libraries from sklearn.svm import LinearSVC from sklearn import datasets from sklearn.preprocessing import StandardScaler import numpy as np from matplotlib import pyplot as plt Load Iris Flower Data # Load data with only two classes and two features iris = datasets.load_iris() X = iris.data[:100,:2] y = iris.target[:100] Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Train Support Vector Classifier # Create support vector classifier svc = LinearSVC(C=1.</description>
    </item>
    
    <item>
      <title>Plot The Validation Curve</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_validation_curve/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/plot_the_validation_curve/</guid>
      <description>Preliminaries # Load libraries import matplotlib.pyplot as plt import numpy as np from sklearn.datasets import load_digits from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import validation_curve Load Digits Dataset # Load data digits = load_digits() # Create feature matrix and target vector X, y = digits.data, digits.target Plot Validation Curve # Create range of values for parameter param_range = np.arange(1, 250, 2) # Calculate accuracy on training and test set using range of parameter values train_scores, test_scores = validation_curve(RandomForestClassifier(), X, y, param_name=&amp;#34;n_estimators&amp;#34;, param_range=param_range, cv=3, scoring=&amp;#34;accuracy&amp;#34;, n_jobs=-1) # Calculate mean and standard deviation for training set scores train_mean = np.</description>
    </item>
    
    <item>
      <title>Precision</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/precision/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/precision/</guid>
      <description>Preliminaries # Load libraries from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification Generate Features And Target Data # Generate features matrix and target vector X, y = make_classification(n_samples = 10000, n_features = 3, n_informative = 3, n_redundant = 0, n_classes = 2, random_state = 1) Create Logistic Regression # Create logistic regression logit = LogisticRegression() Cross-Validate Model Using Precision # Cross-validate model using precision cross_val_score(logit, X, y, scoring=&amp;#34;precision&amp;#34;) array([ 0.</description>
    </item>
    
    <item>
      <title>Preprocessing Categorical Features</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/preprocessing_categorical_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/preprocessing_categorical_features/</guid>
      <description>Often, machine learning methods (e.g. logistic regression, SVM with a linear kernel, etc) will require that categorical variables be converted into dummy variables (also called OneHot encoding). For example, a single feature Fruit would be converted into three features, Apples, Oranges, and Bananas, one for each category in the categorical feature.
There are common ways to preprocess categorical features: using pandas or scikit-learn.
Preliminaries from sklearn import preprocessing from sklearn.</description>
    </item>
    
    <item>
      <title>Preprocessing Data For Neural Networks</title>
      <link>https://chrisalbon.com/deep_learning/keras/preprocessing_data_for_neural_networks/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/preprocessing_data_for_neural_networks/</guid>
      <description>Typically, a neural network&amp;rsquo;s parameters are initialized (i.e. created) as small random numbers. Neural networks often behave poorly when the feature values much larger than parameter values. Furthermore, since an observation&amp;rsquo;s feature values will are combined as they pass through individual units, it is important that all features have the same scale.
For these reasons, it is best practice (although not always necessary, for example when we have all binary features) to standardize each feature such that the feature&amp;rsquo;s values have the mean of 0 and the standard deviation of 1.</description>
    </item>
    
    <item>
      <title>Preprocessing Iris Data</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/preprocessing_iris_data/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/preprocessing_iris_data/</guid>
      <description>Preliminaries from sklearn import datasets import numpy as np from sklearn.cross_validation import train_test_split from sklearn.preprocessing import StandardScaler Load Data # Load the iris data iris = datasets.load_iris() # Create a variable for the feature data X = iris.data # Create a variable for the target data y = iris.target Split Data For Cross Validation # Random split the data into four new datasets, training features, training outcome, test features,  # and test outcome.</description>
    </item>
    
    <item>
      <title>Priority Queues</title>
      <link>https://chrisalbon.com/python/basics/priority_queues/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/priority_queues/</guid>
      <description>Preliminaries import heapq Create A Priority Queue Object # Create a priority queue abstract base class class priority_queue: # Initialize the instance def __init__(self): # Create a list to use as the queue self._queue = [] # Create an index to use as ordering self._index = 0 # Create a function to add a task to the queue def add_task(self, item, priority): # Push the arguments to the _queue using a heap heapq.</description>
    </item>
    
    <item>
      <title>Probability Mass Functions</title>
      <link>https://chrisalbon.com/statistics/frequentist/probability_mass_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/probability_mass_functions/</guid>
      <description>Preliminaries # Load libraries import matplotlib.pyplot as plt Create Data # Create some random integer data data = [3,2,3,4,2,3,5,2,2,3,3,5,2,2,5,6,2,2,2,3,6,6,2,4,3,2,3] Create A Count Of Values # Create a dictionary to store the counts count = {} # For each value in the data for observation in data: # An a key, value pair, with the observation being the key # and the value being +1 count[observation] = count.get(observation, 0) + 1 Normalize The Count To Between 0 and 1 # Calculate the number of observations n = len(data) # Create a dictionary probability_mass_function = {} # For each unique value, for unique_value, count in count.</description>
    </item>
    
    <item>
      <title>Queues And Stacks</title>
      <link>https://chrisalbon.com/python/basics/queues_and_stacks/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/queues_and_stacks/</guid>
      <description>Preliminaries from collections import deque Make A Queue # Option 1: Make a queue queue = deque(range(10)) # Option 2: Make a queue that, if full, discards any item at the  # opposite end to where you added an item. queue = deque(range(10), maxlen=10) Manipulate Queue # Append an item to the right queue.append(&amp;#39;A&amp;#39;) # View queue queue deque([1, 2, 3, 4, 5, 6, 7, 8, 9, &#39;A&#39;])  # Append an item to the left queue.</description>
    </item>
    
    <item>
      <title>Quickly Change A Column Of Strings In Pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_change_column_of_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_change_column_of_strings/</guid>
      <description>Often I need or want to change the case of all items in a column of strings (e.g. BRAZIL to Brazil, etc.). There are many ways to accomplish this but I have settled on this one as the easiest and quickest.
# Import pandas import pandas as pd # Create a list of first names first_names = pd.Series([&amp;#39;Steve Murrey&amp;#39;, &amp;#39;Jane Fonda&amp;#39;, &amp;#39;Sara McGully&amp;#39;, &amp;#39;Mary Jane&amp;#39;])# print the column first_names 0 Steve Murrey 1 Jane Fonda 2 Sara McGully 3 Mary Jane dtype: object  # print the column with lower case first_names.</description>
    </item>
    
    <item>
      <title>Radius-Based Nearest Neighbor Classifier</title>
      <link>https://chrisalbon.com/machine_learning/nearest_neighbors/radius_based_nearest_neighbor_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/nearest_neighbors/radius_based_nearest_neighbor_classifier/</guid>
      <description>Preliminaries # Load libraries from sklearn.neighbors import RadiusNeighborsClassifier from sklearn.preprocessing import StandardScaler from sklearn import datasets Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data y = iris.target Standardize Features # Create standardizer standardizer = StandardScaler() # Standardize features X_std = standardizer.fit_transform(X) Fit A Radius-Based Nearest Neighbor Classifier In scikit-learn RadiusNeighborsClassifier is very similar to KNeighborsClassifier with the exception of two parameters. First, in RadiusNeighborsClassifier we need to specify the radius of the fixed area used to determine if an observation is a neighbor using radius.</description>
    </item>
    
    <item>
      <title>Random Forest Classifier</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier/</guid>
      <description>Preliminaries # Load libraries from sklearn.ensemble import RandomForestClassifier from sklearn import datasets Load Iris Data # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Random Forest Classifier # Create random forest classifer object that uses entropy clf = RandomForestClassifier(criterion=&amp;#39;entropy&amp;#39;, random_state=0, n_jobs=-1) Train Random Forest Classifier # Train model model = clf.fit(X, y) Predict Previously Unseen Observation # Make new observation observation = [[ 5, 4, 3, 2]] # Predict observation&amp;#39;s class  model.</description>
    </item>
    
    <item>
      <title>Random Forest Classifier Example</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/</guid>
      <description>This tutorial is based on Yhat&amp;rsquo;s 2013 tutorial on Random Forests in Python. If you want a good summary of the theory and uses of random forests, I suggest you check out their guide. In the tutorial below, I annotate, correct, and expand on a short code example of random forests they present at the end of the article. Specifically, I 1) update the code so it runs in the latest version of pandas and Python, 2) write detailed comments explaining what is happening in each step, and 3) expand the code in a number of ways.</description>
    </item>
    
    <item>
      <title>Random Forest Regression</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_regressor/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_regressor/</guid>
      <description> Preliminaries # Load libraries from sklearn.ensemble import RandomForestRegressor from sklearn import datasets Load Boston Housing Data # Load data with only two features boston = datasets.load_boston() X = boston.data[:,0:2] y = boston.target Create Random Forest Regressor # Create decision tree classifer object regr = RandomForestRegressor(random_state=0, n_jobs=-1) Train Random Forest Regressor # Train model model = regr.fit(X, y)</description>
    </item>
    
    <item>
      <title>Random Integer Between Two Values</title>
      <link>https://chrisalbon.com/scala/basics/random_integer_between_two_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/random_integer_between_two_values/</guid>
      <description>Load Random // Create a value that is the random package val random = new scala.util.Random Create A Start And End // Create a start and end value pair val start = -10 val end = 10 Generate Random Integer Between The Start And End Values // Then generate a random integer between 0 and the different between end and start + 1 //(to make it inclusive), then shift the value into the desired range by added the start value start + random.</description>
    </item>
    
    <item>
      <title>Random Sampling Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_sampling_dataframe/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_sampling_dataframe/</guid>
      <description>import modules import pandas as pd import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 4 25   1 Molly Jacobson 52 24 94   2 Tina Ali 36 31 57   3 Jake Milner 24 2 62   4 Amy Cooze 73 3 70     Select a random subset of 2 without replacement df.</description>
    </item>
    
    <item>
      <title>Ranking Rows Of Pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_ranking_rows/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_ranking_rows/</guid>
      <description># import modules import pandas as pd# Create dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;coverage&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df   coverage name reports year     Cochice  25  Jason  4  2012   Pima  94  Molly  24  2012   Santa Cruz  57  Tina  31  2013   Maricopa  62  Jake  2  2014   Yuma  70  Amy  3  2014    5 rows  4 columns</description>
    </item>
    
    <item>
      <title>Recall</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/recall/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/recall/</guid>
      <description>Preliminaries # Load libraries from sklearn.model_selection import cross_val_score from sklearn.linear_model import LogisticRegression from sklearn.datasets import make_classification Generate Features And Target Data # Generate features matrix and target vector X, y = make_classification(n_samples = 10000, n_features = 3, n_informative = 3, n_redundant = 0, n_classes = 2, random_state = 1) Create Logistic Regression # Create logistic regression logit = LogisticRegression() Cross-Validate Model Using Recall # Cross-validate model using precision cross_val_score(logit, X, y, scoring=&amp;#34;recall&amp;#34;) array([ 0.</description>
    </item>
    
    <item>
      <title>Recursive Feature Elimination</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/recursive_feature_elimination/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/recursive_feature_elimination/</guid>
      <description>Preliminaries # Load libraries from sklearn.datasets import make_regression from sklearn.feature_selection import RFECV from sklearn import datasets, linear_model import warnings # Suppress an annoying but harmless warning warnings.filterwarnings(action=&amp;#34;ignore&amp;#34;, module=&amp;#34;scipy&amp;#34;, message=&amp;#34;^internal gelsd&amp;#34;) Create Data # Generate features matrix, target vector, and the true coefficients X, y = make_regression(n_samples = 10000, n_features = 100, n_informative = 2, random_state = 1) Create Linear Model # Create a linear regression ols = linear_model.LinearRegression() Conduct Recursive Feature Elimination # Create recursive feature eliminator that scores features by mean squared errors rfecv = RFECV(estimator=ols, step=1, scoring=&amp;#39;neg_mean_squared_error&amp;#39;) # Fit recursive feature eliminator  rfecv.</description>
    </item>
    
    <item>
      <title>Recursive Functions</title>
      <link>https://chrisalbon.com/python/basics/recursive_functions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/recursive_functions/</guid>
      <description> Simple factorial print(5*4*3*2*1) 120  Recursive function The tell-tale sign of a recursive function is a function that calls itself
# Create a function inputing n, that, def factorial(n): # if n is less than or equal to 1, if n &amp;lt;= 1: # return n, return n # if not, return n multiplied by the output # of the factorial function of one less than n return n*factorial(n-1) # run the function factorial(5) 120  </description>
    </item>
    
    <item>
      <title>Regular Expression Basics</title>
      <link>https://chrisalbon.com/python/data_wrangling/regular_expressions_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/regular_expressions_basics/</guid>
      <description>Import the regex (re) package import re Import sys import sys Create a simple text string. text = &amp;#39;The quick brown fox jumped over the lazy black bear.&amp;#39; Create a pattern to match three_letter_word = &amp;#39;\w{3}&amp;#39; Convert the string into a regex object pattern_re = re.compile(three_letter_word); pattern_re re.compile(r&#39;\w{3}&#39;, re.UNICODE)  Does a three letter word appear in text? re_search = re.search(&amp;#39;..own&amp;#39;, text) If the search query is at all true, if re_search: # Print the search results print(re_search.</description>
    </item>
    
    <item>
      <title>Regular Expression By Example</title>
      <link>https://chrisalbon.com/python/data_wrangling/regex_by_example/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/regex_by_example/</guid>
      <description># Import regex import re# Create some data text = &amp;#39;A flock of 120 quick brown foxes jumped over 30 lazy brown, bears.&amp;#39; ^ Matches beginning of line. re.findall(&amp;#39;^A&amp;#39;, text) [&#39;A&#39;]  $ Matches end of line. re.findall(&amp;#39;bears.$&amp;#39;, text) [&#39;bears.&#39;]  . Matches any single character except newline. re.findall(&amp;#39;f..es&amp;#39;, text) [&#39;foxes&#39;]  [...] Matches any single character in brackets. # Find all vowels re.findall(&amp;#39;[aeiou]&amp;#39;, text) [&#39;o&#39;, &#39;o&#39;, &#39;u&#39;, &#39;i&#39;, &#39;o&#39;, &#39;o&#39;, &#39;e&#39;, &#39;u&#39;, &#39;e&#39;, &#39;o&#39;, &#39;e&#39;, &#39;a&#39;, &#39;o&#39;, &#39;e&#39;, &#39;a&#39;]  [# ^.</description>
    </item>
    
    <item>
      <title>Reindexing pandas Series And Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_reindexing/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_reindexing/</guid>
      <description>Series # Import Modules import pandas as pd import numpy as np# Create a pandas series of the risk of fire in Southern Arizona brushFireRisk = pd.Series([34, 23, 12, 23], index = [&amp;#39;Bisbee&amp;#39;, &amp;#39;Douglas&amp;#39;, &amp;#39;Sierra Vista&amp;#39;, &amp;#39;Tombstone&amp;#39;]) brushFireRisk Bisbee 34 Douglas 23 Sierra Vista 12 Tombstone 23 dtype: int64  # Reindex the series and create a new series variable brushFireRiskReindexed = brushFireRisk.reindex([&amp;#39;Tombstone&amp;#39;, &amp;#39;Douglas&amp;#39;, &amp;#39;Bisbee&amp;#39;, &amp;#39;Sierra Vista&amp;#39;, &amp;#39;Barley&amp;#39;, &amp;#39;Tucson&amp;#39;]) brushFireRiskReindexed Tombstone 23.</description>
    </item>
    
    <item>
      <title>Remove Backgrounds</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/remove_backgrounds/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/remove_backgrounds/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image # Load image image_bgr = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;) Convert To RGB # Convert to RGB image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB) Draw Rectangle Around Foreground # Rectange values: start x, start y, width, height rectangle = (0, 56, 256, 150) Apply GrabCut # Create initial mask mask = np.zeros(image_rgb.shape[:2], np.uint8) # Create temporary arrays used by grabCut bgdModel = np.</description>
    </item>
    
    <item>
      <title>Remove Punctuation</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/remove_punctuation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/remove_punctuation/</guid>
      <description> Preliminaries # Load libraries import string import numpy as np Create Text Data # Create text text_data = [&amp;#39;Hi!!!! I. Love. This. Song....&amp;#39;, &amp;#39;10000% Agree!!!! #LoveIT&amp;#39;, &amp;#39;Right?!?!&amp;#39;] Remove Punctuation # Create function using string.punctuation to remove all punctuation def remove_punctuation(sentence: str) -&amp;gt; str: return sentence.translate(str.maketrans(&amp;#39;&amp;#39;, &amp;#39;&amp;#39;, string.punctuation)) # Apply function [remove_punctuation(sentence) for sentence in text_data] [&#39;Hi I Love This Song&#39;, &#39;10000 Agree LoveIT&#39;, &#39;Right&#39;]  </description>
    </item>
    
    <item>
      <title>Remove Stop Words</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/remove_stop_words/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/remove_stop_words/</guid>
      <description> Preliminaries # Load library from nltk.corpus import stopwords # You will have to download the set of stop words the first time import nltk nltk.download(&amp;#39;stopwords&amp;#39;) [nltk_data] Downloading package stopwords to [nltk_data] /Users/chrisalbon/nltk_data... [nltk_data] Package stopwords is already up-to-date! True  Create Word Tokens # Create word tokens tokenized_words = [&amp;#39;i&amp;#39;, &amp;#39;am&amp;#39;, &amp;#39;going&amp;#39;, &amp;#39;to&amp;#39;, &amp;#39;go&amp;#39;, &amp;#39;to&amp;#39;, &amp;#39;the&amp;#39;, &amp;#39;store&amp;#39;, &amp;#39;and&amp;#39;, &amp;#39;park&amp;#39;] Load Stop Words # Load stop words stop_words = stopwords.words(&amp;#39;english&amp;#39;) # Show stop words stop_words[:5] [&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;]  Remove Stop Words # Remove stop words [word for word in tokenized_words if word not in stop_words] [&#39;going&#39;, &#39;go&#39;, &#39;store&#39;, &#39;park&#39;]  </description>
    </item>
    
    <item>
      <title>Rename Column Headers In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_rename_column_headers/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_rename_column_headers/</guid>
      <description>Originally from rgalbo on StackOverflow.
Preliminaries # Import required modules import pandas as pd Create example data # Create a values as dictionary of lists raw_data = {&amp;#39;0&amp;#39;: [&amp;#39;first_name&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;1&amp;#39;: [&amp;#39;last_name&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;2&amp;#39;: [&amp;#39;age&amp;#39;, 52, 36, 24, 73], &amp;#39;3&amp;#39;: [&amp;#39;preTestScore&amp;#39;, 24, 31, 2, 3]} # Create a dataframe df = pd.DataFrame(raw_data) # View a dataframe df    0 1 2 3     0 first_name last_name age preTestScore   1 Molly Jacobson 52 24   2 Tina Ali 36 31   3 Jake Milner 24 2   4 Amy Cooze 73 3     Replace the header value with the first row&amp;rsquo;s values # Create a new variable called &amp;#39;header&amp;#39; from the first row of the dataset header = df.</description>
    </item>
    
    <item>
      <title>Rename Multiple pandas Dataframe Column Names</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_rename_multiple_columns/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_rename_multiple_columns/</guid>
      <description>Preliminaries # Import modules import pandas as pd # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create an example dataframe # Create an example dataframe data = {&amp;#39;Commander&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;Date&amp;#39;: [&amp;#39;2012, 02, 08&amp;#39;, &amp;#39;2012, 02, 08&amp;#39;, &amp;#39;2012, 02, 08&amp;#39;, &amp;#39;2012, 02, 08&amp;#39;, &amp;#39;2012, 02, 08&amp;#39;], &amp;#39;Score&amp;#39;: [4, 24, 31, 2, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df    Commander Date Score     Cochice Jason 2012, 02, 08 4   Pima Molly 2012, 02, 08 24   Santa Cruz Tina 2012, 02, 08 31   Maricopa Jake 2012, 02, 08 2   Yuma Amy 2012, 02, 08 3     Rename Column Names df.</description>
    </item>
    
    <item>
      <title>Replace Characters</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/replace_characters/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/replace_characters/</guid>
      <description>Preliminaries # Import library import re Create Text # Create text text_data = [&amp;#39;Interrobang. By Aishwarya Henriette&amp;#39;, &amp;#39;Parking And Going. By Karl Gautier&amp;#39;, &amp;#39;Today Is The night. By Jarek Prakash&amp;#39;] Replace Character (Method 1) # Remove periods remove_periods = [string.replace(&amp;#39;.&amp;#39;, &amp;#39;&amp;#39;) for string in text_data] # Show text remove_periods [&#39;Interrobang By Aishwarya Henriette&#39;, &#39;Parking And Going By Karl Gautier&#39;, &#39;Today Is The night By Jarek Prakash&#39;]  Replace Character (Method 2) # Create function def replace_letters_with_X(string: str) -&amp;gt; str: return re.</description>
    </item>
    
    <item>
      <title>Replacing Parts Of Strings</title>
      <link>https://chrisalbon.com/scala/basics/replacing_parts_of_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/replacing_parts_of_strings/</guid>
      <description>Create A String // Create a string value val text: String = &amp;#34;Lt. Steve Miller will be leading the attack.&amp;#34; Create A Regex Pattern // Create a regex pattern for a name val find_steve = &amp;#34;Steve Miller&amp;#34;.r Replace Anything That Matches That Pattern With Something Else // Replace all instances of the pattern with a different name find_steve.replaceAllIn(text, &amp;#34;Peter Jackson&amp;#34;) Lt. Peter Jackson will be leading the attack.  Replace First Match // Replace first instance of the pattern with a different name find_steve.</description>
    </item>
    
    <item>
      <title>Replacing Values In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_replace_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_replace_values/</guid>
      <description>import modules import pandas as pd import numpy as np Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [-999, -999, -999, 2, 1], &amp;#39;postTestScore&amp;#39;: [2, 2, -999, 2, -999]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 -999 2   1 Molly Jacobson 52 -999 2   2 Tina Ali 36 -999 -999   3 Jake Milner 24 2 2   4 Amy Cooze 73 1 -999     Replace all values of -999 with NAN df.</description>
    </item>
    
    <item>
      <title>Rescale A Feature</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/rescale_a_feature/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/rescale_a_feature/</guid>
      <description> 
Preliminaries # Load libraries from sklearn import preprocessing import numpy as np Create Feature # Create feature x = np.array([[-500.5], [-100.1], [0], [100.1], [900.9]]) Rescale Feature Using Min-Max # Create scaler minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1)) # Scale feature x_scale = minmax_scale.fit_transform(x) # Show feature x_scale array([[ 0. ], [ 0.28571429], [ 0.35714286], [ 0.42857143], [ 1. ]])  </description>
    </item>
    
    <item>
      <title>Reshape An Array</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/reshape_an_array/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/reshape_an_array/</guid>
      <description> Preliminaries # Load library import numpy as np Create Array # Create a 4x3 matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]) Reshape Array # Reshape matrix into 2x6 matrix matrix.reshape(2, 6) array([[ 1, 2, 3, 4, 5, 6], [ 7, 8, 9, 10, 11, 12]])  </description>
    </item>
    
    <item>
      <title>Ridge Regression</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/ridge_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/ridge_regression/</guid>
      <description>Preliminaries # Load libraries from sklearn.linear_model import Ridge from sklearn.datasets import load_boston from sklearn.preprocessing import StandardScaler Load Boston Housing Dataset # Load data boston = load_boston() X = boston.data y = boston.target Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Fit Ridge Regression The hyperparameter, $\alpha$, lets us control how much we penalize the coefficients, with higher values of $\alpha$ creating simpler modelers. The ideal value of $\alpha$ should be tuned like any other hyperparameter.</description>
    </item>
    
    <item>
      <title>Rolling Time Window</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/rolling_time_windows/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/rolling_time_windows/</guid>
      <description>Preliminaries # Load library import pandas as pd Create Date Data # Create datetimes time_index = pd.date_range(&amp;#39;01/01/2010&amp;#39;, periods=5, freq=&amp;#39;M&amp;#39;) # Create data frame, set index df = pd.DataFrame(index=time_index) # Create feature df[&amp;#39;Stock_Price&amp;#39;] = [1,2,3,4,5] Create A Rolling Time Window Of Two Rows # Calculate rolling mean df.rolling(window=2).mean()   .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }    Stock_Price     2010-01-31 NaN   2010-02-28 1.</description>
    </item>
    
    <item>
      <title>Run Project Jupyter Notebooks On Amazon EC2</title>
      <link>https://chrisalbon.com/aws/basics/run_project_jupyter_on_amazon_ec2/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/aws/basics/run_project_jupyter_on_amazon_ec2/</guid>
      <description>This is tutorial on running Project Jupyter Notebook on an Amazon EC2 instance. It is based on a tutorial by Piyush Agarwal which did not work for me immediately, but I tweaked a few things and got it working.
Note: This is not a beginner&amp;rsquo;s tutorial. I don&amp;rsquo;t explain some of the steps fully and don&amp;rsquo;t explain some concepts. There are other tutorials out there for that.
Create an AWS account An EC2 instance requires an AWS account.</description>
    </item>
    
    <item>
      <title>SVC Parameters When Using RBF Kernel</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/svc_parameters_using_rbf_kernel/</guid>
      <description>In this tutorial we will visually explore the effects of the two parameters from the support vector classifier (SVC) when using the radial basis function kernel (RBF). This tutorial draws heavily on the code used in Sebastian Raschka&amp;rsquo;s book Python Machine Learning.
Preliminaries # Import packages to visualize the classifer from matplotlib.colors import ListedColormap import matplotlib.pyplot as plt import warnings # Import packages to do the classifying import numpy as np from sklearn.</description>
    </item>
    
    <item>
      <title>Save Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/save_images/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/save_images/</guid>
      <description> Preliminaries # Load library import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) # Show image plt.imshow(image, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() Save Image # Save image cv2.imwrite(&amp;#39;images/plane_new.jpg&amp;#39;, image) True  </description>
    </item>
    
    <item>
      <title>Save Model Training Progress</title>
      <link>https://chrisalbon.com/deep_learning/keras/save_model_training_progress/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/save_model_training_progress/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers from keras.callbacks import ModelCheckpoint # Set random seed np.random.seed(0) Load IMDB Movie Review Data # Set the number of features we want number_of_features = 1000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Saving A pandas Dataframe As A CSV</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_saving_dataframe_as_csv/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_saving_dataframe_as_csv/</guid>
      <description>import modules import pandas as pd Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 4 25   1 Molly Jacobson 52 24 94   2 Tina Ali 36 31 57   3 Jake Milner 24 2 62   4 Amy Cooze 73 3 70     Save the dataframe called &amp;ldquo;df&amp;rdquo; as csv Note: I&amp;rsquo;ve commented out this line of code so it does not run.</description>
    </item>
    
    <item>
      <title>Saving Machine Learning Models</title>
      <link>https://chrisalbon.com/machine_learning/basics/saving_machine_learning_models/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/basics/saving_machine_learning_models/</guid>
      <description>In scikit there are two main ways to save a model for future use: a pickle string and a pickled model as a file.
Preliminaries from sklearn.linear_model import LogisticRegression from sklearn import datasets import pickle from sklearn.externals import joblib Load Data # Load the iris data iris = datasets.load_iris() # Create a matrix, X, of features and a vector, y. X, y = iris.data, iris.target Train Model # Train a naive logistic regression model clf = LogisticRegression(random_state=0) clf.</description>
    </item>
    
    <item>
      <title>Scatterplot In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_simple_scatterplot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_simple_scatterplot/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt import numpy as np # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create dataframe df = pd.read_csv(&amp;#39;https://raw.githubusercontent.com/chrisalbon/war_of_the_five_kings_dataset/master/5kings_battles_v1.csv&amp;#39;) df.head()    name year battle_number attacker_king defender_king attacker_1 attacker_2 attacker_3 attacker_4 defender_1 defender_2 defender_3 defender_4 attacker_outcome battle_type major_death major_capture attacker_size defender_size attacker_commander defender_commander summer location region note     0 Battle of the Golden Tooth 298 1 Joffrey/Tommen Baratheon Robb Stark Lannister NaN NaN NaN Tully NaN NaN NaN win pitched battle 1.</description>
    </item>
    
    <item>
      <title>Scheduling Jobs In The Future</title>
      <link>https://chrisalbon.com/python/basics/schedule_run_in_the_future/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/schedule_run_in_the_future/</guid>
      <description># Import required modules import sched import time # setup the scheduler with our time settings s = sched.scheduler(time.time, time.sleep)# Create a function we want to run in the future. def print_time(): print(&amp;#34;Executive Order 66&amp;#34;)# Create a function for the delay def print_some_times(): # Create a scheduled job that will run # the function called &amp;#39;print_time&amp;#39; # after 10 seconds, and with priority 1. s.enter(10, 1, print_time) # Run the scheduler s.</description>
    </item>
    
    <item>
      <title>Search A Map</title>
      <link>https://chrisalbon.com/scala/basics/search_a_map/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/search_a_map/</guid>
      <description> Create A Map // Create an immutable map with three key value pairs val staff = Map(&amp;#34;CEO&amp;#34; -&amp;gt; &amp;#34;Judith Jackson&amp;#34;, &amp;#34;CFO&amp;#34; -&amp;gt; &amp;#34;Sally Shields&amp;#34;, &amp;#34;CTO&amp;#34; -&amp;gt; &amp;#34;Steven Miller&amp;#34;) Test If Key Exists // Test if key exists staff.contains(&amp;#34;CTO&amp;#34;) true  Test If Value Exists // Test is any value exists which contains part of a string staff.valuesIterator.exists(_.contains(&amp;#34;Miller&amp;#34;)) true  </description>
    </item>
    
    <item>
      <title>Search A pandas Column For A Value</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_search_column_for_value/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_search_column_for_value/</guid>
      <description># Import modules import pandas as pdraw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Jason&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Miller&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 42, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 4, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 25, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 4 25   1 Jason Miller 42 4 25   2 Tina Ali 36 31 57   3 Jake Milner 24 2 62   4 Amy Cooze 73 3 70     Find where a value exists in a column # View preTestscore where postTestscore is greater than 50 df[&amp;#39;preTestScore&amp;#39;].</description>
    </item>
    
    <item>
      <title>Search Strings</title>
      <link>https://chrisalbon.com/scala/basics/search_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/search_strings/</guid>
      <description>Create A String // Create a value called text that is a string val text: String = &amp;#34;This is a sentence that we want to split along every space&amp;#34; Array(This, is, a, sentence, that, we, want, to, split, along, every, space)  Split Up A String By Commas // Create a value called csv_row that is a string and contains one row of data val csv_row: String = &amp;#34;Billy, Miller, 22, Baker, High School&amp;#34; // Split up that row by commas csv_row.</description>
    </item>
    
    <item>
      <title>Search Strings Using Regex</title>
      <link>https://chrisalbon.com/scala/basics/search_strings_with_regex/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/search_strings_with_regex/</guid>
      <description>Create A String // Create a string value val attack_order : String = &amp;#34;Our 382 troops will attack their east flank at dawn. They have 28 troops there.&amp;#34; Create A Regex Pattern // Create a value that is a regex pattern val find_numbers = &amp;#34;[0-9]+&amp;#34;.r Find First Match // Apply the regex to find the first match, output the result, otherwise output &amp;#34;None&amp;#34; find_numbers.findFirstIn(attack_order).getOrElse(&amp;#34;None&amp;#34;) 382  Find All Matches // Apply the regex to find all matches and output to an array find_numbers.</description>
    </item>
    
    <item>
      <title>Select Date And Time Ranges</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/select_date_and_time_ranges/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_dates_and_times/select_date_and_time_ranges/</guid>
      <description>Preliminaries # Load library import pandas as pd Create pandas Series Time Data # Create data frame df = pd.DataFrame() # Create datetimes df[&amp;#39;date&amp;#39;] = pd.date_range(&amp;#39;1/1/2001&amp;#39;, periods=100000, freq=&amp;#39;H&amp;#39;) Select Time Range (Method 1) Use this method if your data frame is not indexed by time.
# Select observations between two datetimes df[(df[&amp;#39;date&amp;#39;] &amp;gt; &amp;#39;2002-1-1 01:00:00&amp;#39;) &amp;amp; (df[&amp;#39;date&amp;#39;] &amp;lt;= &amp;#39;2002-1-1 04:00:00&amp;#39;)]   .dataframe thead tr:only-child th { text-align: right; } .</description>
    </item>
    
    <item>
      <title>Select Important Features In Random Forest</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/select_important_features_in_random_forest/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/select_important_features_in_random_forest/</guid>
      <description>Preliminaries # Load libraries from sklearn.ensemble import RandomForestClassifier from sklearn import datasets from sklearn.feature_selection import SelectFromModel Load Iris Flower Data # Load data iris = datasets.load_iris() X = iris.data y = iris.target Create Random Forest Classifier # Create random forest classifier clf = RandomForestClassifier(random_state=0, n_jobs=-1) Select Features With Importance Greater Than Threshold The higher the number, the more important the feature (all importance scores sum to one). By plotting these values we can add interpretability to our random forest models.</description>
    </item>
    
    <item>
      <title>Select Random Element From A List</title>
      <link>https://chrisalbon.com/python/basics/select_random_element_from_list/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/select_random_element_from_list/</guid>
      <description> Preliminaries from random import choice Create List # Make a list of crew members crew_members = [&amp;#39;Steve&amp;#39;, &amp;#39;Stacy&amp;#39;, &amp;#39;Miller&amp;#39;, &amp;#39;Chris&amp;#39;, &amp;#39;Bill&amp;#39;, &amp;#39;Jack&amp;#39;] Select Random Item From List # Choose a random crew member choice(crew_members) &#39;Stacy&#39;  </description>
    </item>
    
    <item>
      <title>Select Rows When Columns Contain Certain Values</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_when_column_has_certain_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_when_column_has_certain_values/</guid>
      <description>Preliminaries # Import modules import pandas as pd # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create an example dataframe # Create an example dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df    name reports year     Cochice Jason 4 2012   Pima Molly 24 2012   Santa Cruz Tina 31 2013   Maricopa Jake 2 2014   Yuma Amy 3 2014     Grab rows based on column values value_list = [&amp;#39;Tina&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Jason&amp;#39;]#Grab DataFrame rows where column has certain values df[df.</description>
    </item>
    
    <item>
      <title>Select Rows With A Certain Value</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_containing_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_containing_values/</guid>
      <description>import pandas as pd# Create an example dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;], &amp;#39;country&amp;#39;: [[&amp;#39;Syria&amp;#39;, &amp;#39;Lebanon&amp;#39;],[&amp;#39;Spain&amp;#39;, &amp;#39;Morocco&amp;#39;]]} df = pd.DataFrame(data) df    country name     0 [Syria, Lebanon] Jason   1 [Spain, Morocco] Molly     df[df[&amp;#39;country&amp;#39;].map(lambda country: &amp;#39;Syria&amp;#39; in country)]    country name     0 [Syria, Lebanon] Jason     </description>
    </item>
    
    <item>
      <title>Select Rows With Multiple Filters</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_multiple_filters/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_select_rows_multiple_filters/</guid>
      <description># import pandas as pd import pandas as pd# Create an example dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;, &amp;#39;E&amp;#39;], &amp;#39;score&amp;#39;: [1,2,3,4,5]} df = pd.DataFrame(data) df    name score     0 A 1   1 B 2   2 C 3   3 D 4   4 E 5     # Select rows of the dataframe where df.</description>
    </item>
    
    <item>
      <title>Selecting Elements In An Array</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/selecting_elements_in_an_array/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/selecting_elements_in_an_array/</guid>
      <description> Preliminaries # Load library import numpy as np Create Vector # Create row vector vector = np.array([1, 2, 3, 4, 5, 6]) Select Element # Select second element vector[1] 2  Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Select Element # Select second row, second column matrix[1,1] 5  Create Tensor # Create matrix tensor = np.array([ [[[1, 1], [1, 1]], [[2, 2], [2, 2]]], [[[3, 3], [3, 3]], [[4, 4], [4, 4]]] ]) Select Element # Select second element of each of the three dimensions tensor[1,1,1] array([4, 4])  </description>
    </item>
    
    <item>
      <title>Selecting Items In A List With Filters</title>
      <link>https://chrisalbon.com/python/basics/filter_items_in_list_with_filter/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/filter_items_in_list_with_filter/</guid>
      <description># Create an list of items denoting the number of soldiers in each regiment, view the list regimentSize = (5345, 6436, 3453, 2352, 5212, 6232, 2124, 3425, 1200, 1000, 1211); regimentSize (5345, 6436, 3453, 2352, 5212, 6232, 2124, 3425, 1200, 1000, 1211)  One-line Method This line of code does the same thing as the multiline method below, it is just more compact (but also more complicated to understand.</description>
    </item>
    
    <item>
      <title>Selecting The Best Alpha Value In Ridge Regression</title>
      <link>https://chrisalbon.com/machine_learning/linear_regression/selecting_best_alpha_value_in_ridge_regression/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/linear_regression/selecting_best_alpha_value_in_ridge_regression/</guid>
      <description>Preliminaries # Load libraries from sklearn.linear_model import RidgeCV from sklearn.datasets import load_boston from sklearn.preprocessing import StandardScaler Load Boston Housing Dataset # Load data boston = load_boston() X = boston.data y = boston.target Standardize Features Note: Because in linear regression the value of the coefficients is partially determined by the scale of the feature, and in regularized models all coefficients are summed together, we must make sure to standardize the feature prior to training.</description>
    </item>
    
    <item>
      <title>Selecting The Best Number Of Components For LDA</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_lda/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_lda/</guid>
      <description>In scikit-learn, LDA is implemented using LinearDiscriminantAnalysis includes a parameter, n_components indicating the number of features we want returned. To figure out what argument value to use with n_components (e.g. how many parameters to keep), we can take advantage of the fact that explained_variance_ratio_ tells us the variance explained by each outputted feature and is a sorted array.
Specifically, we can run LinearDiscriminantAnalysis with n_components set to None to return ratio of variance explained by every component feature, then calculate how many components are required to get above some threshold of variance explained (often 0.</description>
    </item>
    
    <item>
      <title>Selecting The Best Number Of Components For TSVD</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_tsvd/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/select_best_number_of_components_in_tsvd/</guid>
      <description>Preliminaries # Load libraries from sklearn.preprocessing import StandardScaler from sklearn.decomposition import TruncatedSVD from scipy.sparse import csr_matrix from sklearn import datasets import numpy as np Load Digits Data And Make Sparse # Load the data digits = datasets.load_digits() # Standardize the feature matrix X = StandardScaler().fit_transform(digits.data) # Make sparse matrix X_sparse = csr_matrix(X) Run Truncated Singular Value Decomposition # Create and run an TSVD with one less than number of features tsvd = TruncatedSVD(n_components=X_sparse.</description>
    </item>
    
    <item>
      <title>Selecting pandas DataFrame Rows Based On Conditions</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_selecting_rows_on_conditions/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_selecting_rows_on_conditions/</guid>
      <description>Preliminaries # Import modules import pandas as pd import numpy as np# Create a dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, np.nan, np.nan, np.nan], &amp;#39;nationality&amp;#39;: [&amp;#39;USA&amp;#39;, &amp;#39;USA&amp;#39;, &amp;#39;France&amp;#39;, &amp;#39;UK&amp;#39;, &amp;#39;UK&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;nationality&amp;#39;, &amp;#39;age&amp;#39;]) df    first_name nationality age     0 Jason USA 42   1 Molly USA 52   2 NaN France 36   3 NaN UK 24   4 NaN UK 70     Method 1: Using Boolean Variables # Create variable with TRUE if nationality is USA american = df[&amp;#39;nationality&amp;#39;] == &amp;#34;USA&amp;#34; # Create variable with TRUE if age is greater than 50 elderly = df[&amp;#39;age&amp;#39;] &amp;gt; 50 # Select all cases where nationality is USA and age is greater than 50 df[american &amp;amp; elderly]    first_name nationality age     1 Molly USA 52     Method 2: Using variable attributes # Select all cases where the first name is not missing and nationality is USA  df[df[&amp;#39;first_name&amp;#39;].</description>
    </item>
    
    <item>
      <title>Selection Sort</title>
      <link>https://chrisalbon.com/computer_science/algorithms/selection_sort/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/computer_science/algorithms/selection_sort/</guid>
      <description>This might not be the most efficient implementation of the selection sort algorithm. However, it is the one that closely matches how the algorithm is explained:
 Pick up the first card (if this was a deck of cards). Compare the card in your hand to each other card in turn If a smaller card is found, swap the cards (so the smaller card is now in your hand). When you get to the last card, put the card in your hand into a separate pile.</description>
    </item>
    
    <item>
      <title>Set Operations On Sequences</title>
      <link>https://chrisalbon.com/scala/basics/set_operations_on_sequences/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/set_operations_on_sequences/</guid>
      <description>Preliminaries import scala.collection.mutable.ArrayBuffer Create Two Array Sequences // Create two arrays of ages val student_ages = ArrayBuffer(42,25,28,38,58,63,23,458,2569,584,25,25) val teacher_ages = ArrayBuffer(23,25,25,38,58,32,23,23,125,23,23,21,26) Concatenate Two Sequences // Join two sequences end to end student_ages ++ teacher_ages ArrayBuffer(42, 25, 28, 38, 58, 63, 23, 458, 2569, 584, 25, 25, 23, 25, 25, 38, 58, 32, 23, 23, 125, 23, 23, 21, 26)  Intersection (Shared Elements) Of Two Sequences // Create the interaction of two sequences teacher_ages.</description>
    </item>
    
    <item>
      <title>Set The Color Of A Matplotlib Plot</title>
      <link>https://chrisalbon.com/python/basics/set_the_color_of_a_matplotlib/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/set_the_color_of_a_matplotlib/</guid>
      <description>Import numpy and matplotlib.pyplot %matplotlib inline import numpy as np import matplotlib.pyplot as plt Create some simulated data. n = 100 r = 2 * np.random.rand(n) theta = 2 * np.pi * np.random.rand(n) area = 200 * r**2 * np.random.rand(n) colors = theta Create a scatterplot using the a colormap. Full list of colormaps: http://wiki.scipy.org/Cookbook/Matplotlib/Show_colormaps
c = plt.scatter(theta, r, c=colors, s=area, cmap=plt.cm.RdYlGn) c1 = plt.scatter(theta, r, c=colors, s=area, cmap=plt.cm.Blues) c2 = plt.</description>
    </item>
    
    <item>
      <title>Sharpen Images</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/sharpen_images/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/sharpen_images/</guid>
      <description> Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load Image As Greyscale # Load image as grayscale image = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_GRAYSCALE) Sharpen Image # Create kernel kernel = np.array([[0, -1, 0], [-1, 5,-1], [0, -1, 0]]) # Sharpen image image_sharp = cv2.filter2D(image, -1, kernel) View Image # Show image plt.imshow(image_sharp, cmap=&amp;#39;gray&amp;#39;), plt.axis(&amp;#34;off&amp;#34;) plt.show() </description>
    </item>
    
    <item>
      <title>Shi-Tomasi Corner Detector</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/ski-tomasi_corner_detector/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/ski-tomasi_corner_detector/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load image # Load images image_bgr = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;) image_gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY) Define Corner Parameters # Number of corners to detect corners_to_detect = 10 minimum_quality_score = 0.05 minimum_distance = 25 Detect Corners # Detect corners corners = cv2.goodFeaturesToTrack(image_gray, corners_to_detect, minimum_quality_score, minimum_distance) corners = np.float32(corners) Mark Corners # Draw white circle at each corner for corner in corners: x, y = corner[0] cv2.</description>
    </item>
    
    <item>
      <title>Simple Clustering With SciPy</title>
      <link>https://chrisalbon.com/python/other/scipy_simple_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/other/scipy_simple_clustering/</guid>
      <description>Import modules import numpy as np %matplotlib inline import matplotlib.pyplot as plt from scipy.cluster import vq Create coordinates for battles for each year of the war # create 100 coordinate pairs (i.e. two values), then add 5 to all of them year_1 = np.random.randn(100, 2) + 5 # create 30 coordinatee pairs (i.e. two values), then subtract 5 to all of them year_2 = np.random.randn(30, 2) - 5 # create 50 coordinatee pairs (i.</description>
    </item>
    
    <item>
      <title>Simple Example Dataframes In pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_examples/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_dataframe_examples/</guid>
      <description>import modules import pandas as pd Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;age&amp;#39;: [42, 52, 36, 24, 73], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name age preTestScore postTestScore     0 Jason Miller 42 4 25   1 Molly Jacobson 52 24 94   2 Tina Ali 36 31 57   3 Jake Milner 24 2 62   4 Amy Cooze 73 3 70     Create 2nd dataframe raw_data_2 = {&amp;#39;first_name&amp;#39;: [&amp;#39;Sarah&amp;#39;, &amp;#39;Gueniva&amp;#39;, &amp;#39;Know&amp;#39;, &amp;#39;Sara&amp;#39;, &amp;#39;Cat&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Mornig&amp;#39;, &amp;#39;Jaker&amp;#39;, &amp;#39;Alom&amp;#39;, &amp;#39;Ormon&amp;#39;, &amp;#39;Koozer&amp;#39;], &amp;#39;age&amp;#39;: [53, 26, 72, 73, 24], &amp;#39;preTestScore&amp;#39;: [13, 52, 72, 26, 26], &amp;#39;postTestScore&amp;#39;: [82, 52, 56, 234, 254]} df_2 = pd.</description>
    </item>
    
    <item>
      <title>Simple Unit Test</title>
      <link>https://chrisalbon.com/python/testing/simple_unit_test/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/testing/simple_unit_test/</guid>
      <description>Preliminaries import unittest import sys Create Function To Be Tested def multiply(x, y): return x * y Create Test Note: It is standard practice to name a unit test test_ + &amp;lt;function being tested&amp;gt;. This naming standard allows for automated test using some libraries.
# Create a test case class TestMultiply(unittest.TestCase): # Create the unit test def test_multiply_two_integers_together(self): # Test if 4 equals the output of multiply(2,2) self.assertEqual(4, multiply(2,2)) Run Test # Run the unit test (and don&amp;#39;t shut down the Jupyter Notebook) unittest.</description>
    </item>
    
    <item>
      <title>Sort A List Of Names By Last Name</title>
      <link>https://chrisalbon.com/python/basics/sort_a_list_by_last_name/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/sort_a_list_by_last_name/</guid>
      <description>Create a list of names commander_names = [&amp;#34;Alan Brooke&amp;#34;, &amp;#34;George Marshall&amp;#34;, &amp;#34;Frank Jack Fletcher&amp;#34;, &amp;#34;Conrad Helfrich&amp;#34;, &amp;#34;Albert Kesselring&amp;#34;]  Sort Alphabetically By Last Name To complete the sort, we will combine three operations:
 lambda x: x.split(&amp;quot; &amp;quot;), which is a function that takes a string x and breaks it up along each blank space. This outputs a list. [-1], which takes the last element of a list. sorted(), which sorts a list.</description>
    </item>
    
    <item>
      <title>Sort A List Of Strings By Length</title>
      <link>https://chrisalbon.com/python/basics/sort_a_list_of_strings_by_length/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/sort_a_list_of_strings_by_length/</guid>
      <description> Create a list of names commander_names = [&amp;#34;Alan Brooke&amp;#34;, &amp;#34;George Marshall&amp;#34;, &amp;#34;Frank Jack Fletcher&amp;#34;, &amp;#34;Conrad Helfrich&amp;#34;, &amp;#34;Albert Kesselring&amp;#34;]  Sort Alphabetically By Length To complete the sort, we will combine two operations:
 lambda x: len(x), which returns the length of each string. sorted(), which sorts a list.  # Sort a variable called &amp;#39;commander_names&amp;#39; by the length of each string sorted(commander_names, key=lambda x: len(x)) [&#39;Alan Brooke&#39;, &#39;George Marshall&#39;, &#39;Conrad Helfrich&#39;, &#39;Albert Kesselring&#39;, &#39;Frank Jack Fletcher&#39;]  </description>
    </item>
    
    <item>
      <title>Sorting Rows In pandas Dataframes</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_sorting_rows_dataframe/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_sorting_rows_dataframe/</guid>
      <description>import modules import pandas as pd Create dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [1, 2, 1, 2, 3], &amp;#39;coverage&amp;#39;: [2, 2, 3, 3, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df    coverage name reports year     Cochice 2 Jason 1 2012   Pima 2 Molly 2 2012   Santa Cruz 3 Tina 1 2013   Maricopa 3 Jake 2 2014   Yuma 3 Amy 3 2014     Sort the dataframe&amp;rsquo;s rows by reports, in descending order df.</description>
    </item>
    
    <item>
      <title>Sorting Sequences</title>
      <link>https://chrisalbon.com/scala/basics/sorting_sequences/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/sorting_sequences/</guid>
      <description>Create Two Vectors // Create two vectors val ages = Vector(23,42,12,34) val lastName = Vector(&amp;#34;Jackson&amp;#34;, &amp;#34;Dillan&amp;#34;, &amp;#34;Bower&amp;#34;, &amp;#34;Stein&amp;#34;) Sort Alphabetically // View the sequence alphabetically lastName.sorted Vector(Bower, Dillan, Jackson, Stein)  Sort Ascending // View the sequence in ascending order ages.sorted Vector(12, 23, 34, 42)  Sort Descending // View the sequence sorted using i &amp;gt; j ages.sortWith(_ &amp;gt; _) Vector(42, 34, 23, 12)  Sort By Length // Voew the sequence sorted by descending length lastName.</description>
    </item>
    
    <item>
      <title>Spearmans Rank Correlation</title>
      <link>https://chrisalbon.com/statistics/frequentist/spearmans_rank_correlation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/spearmans_rank_correlation/</guid>
      <description>Preliminaries import numpy as np import pandas as pd import scipy.stats Create Data # Create two lists of random values x = [1,2,3,4,5,6,7,8,9] y = [2,1,2,4.5,7,6.5,6,9,9.5] Calculate Spearman&amp;rsquo;s Rank Correlation Spearman&amp;rsquo;s rank correlation is the Pearson&amp;rsquo;s correlation coefficient of the ranked version of the variables.
# Create a function that takes in x&amp;#39;s and y&amp;#39;s def spearmans_rank_correlation(xs, ys): # Calculate the rank of x&amp;#39;s xranks = pd.Series(xs).rank() # Caclulate the ranking of the y&amp;#39;s yranks = pd.</description>
    </item>
    
    <item>
      <title>Split Data Into Training And Test Sets</title>
      <link>https://chrisalbon.com/machine_learning/model_evaluation/split_data_into_training_and_test_sets/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/model_evaluation/split_data_into_training_and_test_sets/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split Load Digits Dataset # Load the digits dataset digits = datasets.load_digits() # Create the features matrix X = digits.data # Create the target vector y = digits.target Split Into Training And Test Sets # Create training and test sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1) Fit Standardizer To Training Set # Create standardizer standardizer = StandardScaler() # Fit standardizer to training set standardizer.</description>
    </item>
    
    <item>
      <title>Split Lat/Long Coordinate Variables Into Separate Variables</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_split_lat_and_long_into_variables/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_split_lat_and_long_into_variables/</guid>
      <description>Preliminaries import pandas as pd import numpy as np Create an example dataframe raw_data = {&amp;#39;geo&amp;#39;: [&amp;#39;40.0024, -105.4102&amp;#39;, &amp;#39;40.0068, -105.266&amp;#39;, &amp;#39;39.9318, -105.2813&amp;#39;, np.nan]} df = pd.DataFrame(raw_data, columns = [&amp;#39;geo&amp;#39;]) df    geo     0 40.0024, -105.4102   1 40.0068, -105.266   2 39.9318, -105.2813   3 NaN     Split the geo variable into separate lat and lon variables # Create two lists for the loop results to be placed lat = [] lon = [] # For each row in a varible, for row in df[&amp;#39;geo&amp;#39;]: # Try to, try: # Split the row by comma and append # everything before the comma to lat lat.</description>
    </item>
    
    <item>
      <title>Split Strings</title>
      <link>https://chrisalbon.com/scala/basics/split_strings/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/split_strings/</guid>
      <description>Split Up A String By Spaces // Create a value called text that is a string val text: String = &amp;#34;This is a sentence that we want to split along every space&amp;#34; // Split up the value along every space text.split(&amp;#34; &amp;#34;) Array(This, is, a, sentence, that, we, want, to, split, along, every, space)  Split Up A String By Commas // Create a value called csv_row that is a string and contains one row of data val csv_row: String = &amp;#34;Billy, Miller, 22, Baker, High School&amp;#34; // Split up that row by commas csv_row.</description>
    </item>
    
    <item>
      <title>Stacked Percentage Bar Plot In MatPlotLib</title>
      <link>https://chrisalbon.com/python/data_visualization/matplotlib_percentage_stacked_bar_plot/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_visualization/matplotlib_percentage_stacked_bar_plot/</guid>
      <description>Preliminaries %matplotlib inline import pandas as pd import matplotlib.pyplot as plt Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;pre_score&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;mid_score&amp;#39;: [25, 94, 57, 62, 70], &amp;#39;post_score&amp;#39;: [5, 43, 23, 23, 51]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;pre_score&amp;#39;, &amp;#39;mid_score&amp;#39;, &amp;#39;post_score&amp;#39;]) df    first_name pre_score mid_score post_score     0 Jason 4 25 5   1 Molly 24 94 43   2 Tina 31 57 23   3 Jake 2 62 23   4 Amy 3 70 51     Make plot # Create a figure with a single subplot f, ax = plt.</description>
    </item>
    
    <item>
      <title>Standardize A Feature</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_structured_data/standardize_a_feature/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_structured_data/standardize_a_feature/</guid>
      <description> 
Preliminaries # Load libraries from sklearn import preprocessing import numpy as np Create Feature # Create feature x = np.array([[-500.5], [-100.1], [0], [100.1], [900.9]]) Standardize Feature # Create scaler scaler = preprocessing.StandardScaler() # Transform the feature standardized = scaler.fit_transform(x) # Show feature standardized array([[-1.26687088], [-0.39316683], [-0.17474081], [ 0.0436852 ], [ 1.79109332]])  </description>
    </item>
    
    <item>
      <title>Stemming Words</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/stemming_words/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/stemming_words/</guid>
      <description> 
Preliminaries # Load library from nltk.stem.porter import PorterStemmer Create Text Data # Create word tokens tokenized_words = [&amp;#39;i&amp;#39;, &amp;#39;am&amp;#39;, &amp;#39;humbled&amp;#39;, &amp;#39;by&amp;#39;, &amp;#39;this&amp;#39;, &amp;#39;traditional&amp;#39;, &amp;#39;meeting&amp;#39;] Stem Words Stemming reduces a word to its stem by identifying and removing affixes (e.g. gerunds) while keeping the root meaning of the word. NLTK&amp;rsquo;s PorterStemmer implements the widely used Porter stemming algorithm.
# Create stemmer porter = PorterStemmer() # Apply stemmer [porter.stem(word) for word in tokenized_words] [&#39;i&#39;, &#39;am&#39;, &#39;humbl&#39;, &#39;by&#39;, &#39;thi&#39;, &#39;tradit&#39;, &#39;meet&#39;]  </description>
    </item>
    
    <item>
      <title>Store API Credentials For Open Source Projects</title>
      <link>https://chrisalbon.com/python/basics/store_api_credentials_for_open_source_projects/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/store_api_credentials_for_open_source_projects/</guid>
      <description>One issue which repeated comes up is how to manage private API credentials when the project is available on GitHub. This is the method I use for my own projects. I store all credentials in a JSON file and tell gitignore to not upload that file. Then when I am running that code locally, load the API credentials from the JSON file.
Preliminaries import json Step 1: Create a JSON with the API credentials credentials = {&amp;#39;access_secret&amp;#39;: &amp;#39;392n39d93&amp;#39;, &amp;#39;access_token&amp;#39;: &amp;#39;sdf424f&amp;#39;, &amp;#39;consumer_key&amp;#39;: &amp;#39;sdf3223&amp;#39;, &amp;#39;consumer_secret&amp;#39;: &amp;#39;dsf2344&amp;#39;}with open(&amp;#39;credentials.</description>
    </item>
    
    <item>
      <title>Streaming Data Pipeline</title>
      <link>https://chrisalbon.com/python/data_wrangling/streaming_data_pipeline/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/streaming_data_pipeline/</guid>
      <description> Create Some Raw Data raw_data = [1,2,3,4,5,6,7,8,9,10] Create Data Processing Functions # Define a generator that yields input+6 def add_6(numbers): for x in numbers: output = x+6 yield output # Define a generator that yields input-2 def subtract_2(numbers): for x in numbers: output = x-2 yield output # Define a generator that yields input*100  def multiply_by_100(numbers): for x in numbers: output = x*100 yield output Create Data Pipeline # Step 1 of the pipeline step1 = add_6(raw_data) # Step 2 of the pipeline step2 = subtract_2(step1) # Step 3 of the pipeline pipeline = multiply_by_100(step2) Send First Two Pieces Of Raw Data Through Pipeline # First element of the raw data next(pipeline) 500  # Second element of the raw data next(pipeline) 600  Send All Raw Data Through Pipeline # Process all data for raw_data in pipeline: print(raw_data) 700 800 900 1000 1100 1200 1300 1400  </description>
    </item>
    
    <item>
      <title>String Formatting</title>
      <link>https://chrisalbon.com/python/basics/string_formatting/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/string_formatting/</guid>
      <description> Import the sys module import sys Print a string with 1 digit and one string. &amp;#39;This is %d%sbird!&amp;#39; % (1, &amp;#39;dead&amp;#39;) &#39;This is 1 dead bird!&#39;  Print a dictionary based string &amp;#39;%(number)dmore %(food)s&amp;#39; % {&amp;#39;number&amp;#39; : 1, &amp;#39;food&amp;#39; : &amp;#39;burger&amp;#39;} &#39;1 more burger&#39;  Print a string about my laptop. &amp;#39;My {1[kind]} runs {0.platform}&amp;#39;.format(sys, {&amp;#39;kind&amp;#39;: &amp;#39;laptop&amp;#39;}) &#39;My laptop runs darwin&#39;  String Formatting Codes  %s string %r repr string %c character (integer or string) %d decimal %i integer %x hex integer %X same as X but with uppercase %e floating point lowercase %E floating point uppercase %f floating point decimal lowercase %F floating point decimal uppercase %g floating point e or f %G floating point E or F %% literal %  </description>
    </item>
    
    <item>
      <title>String Indexing</title>
      <link>https://chrisalbon.com/python/basics/string_indexing/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/string_indexing/</guid>
      <description>Create a string string = &amp;#39;Strings are defined as ordered collections of characters.&amp;#39; Print the entire string string[:] &#39;Strings are defined as ordered collections of characters.&#39;  Print the first three characters string[0:3] &#39;Str&#39;  Print the first three characters string[:3] &#39;Str&#39;  Print the last three characters string[-3:] &#39;rs.&#39;  Print the third to fifth character string[2:5] &#39;rin&#39;  Print the first to the tenth character, skipping every other character string[0:10:2] &#39;Srnsa&#39;  Print the string in reverse string[::-1] &#39;.</description>
    </item>
    
    <item>
      <title>String Munging In Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_string_munging/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_string_munging/</guid>
      <description>import modules import pandas as pd import numpy as np import re as re Create dataframe raw_data = {&amp;#39;first_name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;last_name&amp;#39;: [&amp;#39;Miller&amp;#39;, &amp;#39;Jacobson&amp;#39;, &amp;#39;Ali&amp;#39;, &amp;#39;Milner&amp;#39;, &amp;#39;Cooze&amp;#39;], &amp;#39;email&amp;#39;: [&amp;#39;jas203@gmail.com&amp;#39;, &amp;#39;momomolly@gmail.com&amp;#39;, np.NAN, &amp;#39;battler@milner.com&amp;#39;, &amp;#39;Ames1234@yahoo.com&amp;#39;], &amp;#39;preTestScore&amp;#39;: [4, 24, 31, 2, 3], &amp;#39;postTestScore&amp;#39;: [25, 94, 57, 62, 70]} df = pd.DataFrame(raw_data, columns = [&amp;#39;first_name&amp;#39;, &amp;#39;last_name&amp;#39;, &amp;#39;email&amp;#39;, &amp;#39;preTestScore&amp;#39;, &amp;#39;postTestScore&amp;#39;]) df    first_name last_name email preTestScore postTestScore     0 Jason Miller jas203@gmail.</description>
    </item>
    
    <item>
      <title>String Operations</title>
      <link>https://chrisalbon.com/python/basics/string_operations/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/string_operations/</guid>
      <description>Python 3 has three string types
 str() is for unicode bytes() is for binary data bytesarray() mutable variable of bytes  Create some simulated text. string = &amp;#39;The quick brown fox jumped over the lazy brown bear.&amp;#39; Capitalize the first letter. string_capitalized = string.capitalize() string_capitalized &#39;The quick brown fox jumped over the lazy brown bear.&#39;  Center the string with periods on either side, for a total of 79 characters string_centered = string.</description>
    </item>
    
    <item>
      <title>Strip Whitespace</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/strip_whitespace/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/strip_whitespace/</guid>
      <description> Create Text # Create text text_data = [&amp;#39; Interrobang. By Aishwarya Henriette &amp;#39;, &amp;#39;Parking And Going. By Karl Gautier&amp;#39;, &amp;#39; Today Is The night. By Jarek Prakash &amp;#39;] Remove Whitespace # Strip whitespaces strip_whitespace = [string.strip() for string in text_data] # Show text strip_whitespace [&#39;Interrobang. By Aishwarya Henriette&#39;, &#39;Parking And Going. By Karl Gautier&#39;, &#39;Today Is The night. By Jarek Prakash&#39;]  </description>
    </item>
    
    <item>
      <title>Support Vector Classifier</title>
      <link>https://chrisalbon.com/machine_learning/support_vector_machines/support_vector_classifier/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/support_vector_machines/support_vector_classifier/</guid>
      <description>There is a balance between SVC maximizing the margin of the hyperplane and minimizing the misclassification. In SVC, the later is controlled with the hyperparameter $C$, the penalty imposed on errors. C is a parameter of the SVC learner and is the penalty for misclassifying a data point. When C is small, the classifier is okay with misclassified data points (high bias but low variance). When C is large, the classifier is heavily penalized for misclassified data and therefore bends over backwards avoid any misclassified data points (low bias but high variance).</description>
    </item>
    
    <item>
      <title>Swapping Variable Values</title>
      <link>https://chrisalbon.com/python/basics/swapping_variable_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/swapping_variable_values/</guid>
      <description> Setup the originally variables and their values one = 1 two = 2 View the original variables &amp;#39;one =&amp;#39;, one, &amp;#39;two =&amp;#39;, two (&#39;one =&#39;, 1, &#39;two =&#39;, 2)  Swap the values one, two = two, one View the swapped values, notice how the values for each variable have changed &amp;#39;one =&amp;#39;, one, &amp;#39;two =&amp;#39;, two (&#39;one =&#39;, 2, &#39;two =&#39;, 1)  </description>
    </item>
    
    <item>
      <title>T-Tests</title>
      <link>https://chrisalbon.com/statistics/frequentist/t-tests/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/t-tests/</guid>
      <description>Preliminaries from scipy import stats import numpy as np Create Data # Create a list of 20 observations drawn from a random distribution  # with mean 1 and a standard deviation of 1.5 x = np.random.normal(1, 1.5, 20) # Create a list of 20 observations drawn from a random distribution  # with mean 0 and a standard deviation of 1.5 y = np.random.normal(0, 1.5, 20) One Sample Two-Sided T-Test Imagine the one sample T-test and drawing a (normally shaped) hill centered at 1 and &amp;ldquo;spread&amp;rdquo; out with a standard deviation of 1.</description>
    </item>
    
    <item>
      <title>Tag Parts Of Speech</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/tag_parts_of_speech/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/tag_parts_of_speech/</guid>
      <description>Preliminaries # Load libraries from nltk import pos_tag from nltk import word_tokenize Create Text Data # Create text text_data = &amp;#34;Chris loved outdoor running&amp;#34; Tag Parts Of Speech # Use pre-trained part of speech tagger text_tagged = pos_tag(word_tokenize(text_data)) # Show parts of speech text_tagged [(&#39;Chris&#39;, &#39;NNP&#39;), (&#39;loved&#39;, &#39;VBD&#39;), (&#39;outdoor&#39;, &#39;RP&#39;), (&#39;running&#39;, &#39;VBG&#39;)]  Common Penn Treebank Parts Of Speech Tags The output is a list of tuples with the word and the tag of the part of speech.</description>
    </item>
    
    <item>
      <title>Term Frequency Inverse Document Frequency</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/tf-idf/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/tf-idf/</guid>
      <description>Preliminaries # Load libraries import numpy as np from sklearn.feature_extraction.text import TfidfVectorizer import pandas as pd Create Text Data # Create text text_data = np.array([&amp;#39;I love Brazil. Brazil!&amp;#39;, &amp;#39;Sweden is best&amp;#39;, &amp;#39;Germany beats both&amp;#39;]) Create Feature Matrix # Create the tf-idf feature matrix tfidf = TfidfVectorizer() feature_matrix = tfidf.fit_transform(text_data) # Show tf-idf feature matrix feature_matrix.toarray() array([[ 0. , 0. , 0. , 0.89442719, 0. , 0. , 0.4472136 , 0.</description>
    </item>
    
    <item>
      <title>Test Code Speed</title>
      <link>https://chrisalbon.com/python/testing/test_code_speed/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/testing/test_code_speed/</guid>
      <description>Preliminaries import cProfile Create A Slow Function def slow_function(): total = 0.0 for i, _ in enumerate(range(10000)): for j, _ in enumerate(range(1, 10000)): total += (i * j) return total Test The Speed Of The Function cProfile.run(&amp;#39;slow_function()&amp;#39;, sort=&amp;#39;time&amp;#39;)  4 function calls in 13.291 seconds Ordered by: internal time ncalls tottime percall cumtime percall filename:lineno(function) 1 13.291 13.291 13.291 13.291 &amp;lt;ipython-input-2-64fc1cd43878&amp;gt;:1(slow_function) 1 0.000 0.000 13.291 13.291 {built-in method builtins.exec} 1 0.</description>
    </item>
    
    <item>
      <title>Test For A Specific Exception</title>
      <link>https://chrisalbon.com/python/testing/test_for_a_specific_exception/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/testing/test_for_a_specific_exception/</guid>
      <description>Preliminaries import unittest Create A Function To Test def add(x, y): return x + y Create Test Case # Create a test case class TestAdd(unittest.TestCase): # Create the unit test def test_input_string(self): # Test To make sure a TypeError exception is raised self.assertRaises(TypeError, add(&amp;#39;Banana&amp;#39;, &amp;#39;Boat&amp;#39;)) Run Test # Run the unit test (and don&amp;#39;t shut down the Jupyter Notebook) unittest.main(argv=[&amp;#39;ignored&amp;#39;, &amp;#39;-v&amp;#39;], exit=False) test_input_string (__main__.TestAdd) ... ok ---------------------------------------------------------------------- Ran 1 test in 0.</description>
    </item>
    
    <item>
      <title>Test If Output Is Close To A Value</title>
      <link>https://chrisalbon.com/python/testing/test_if_an_output_is_close_to_a_value/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/testing/test_if_an_output_is_close_to_a_value/</guid>
      <description>Preliminaries import unittest import sys Create Function To Be Tested def add(x, y): return x + y Create Test # Create a test case class TestAdd(unittest.TestCase): # Create the unit test def test_add_two_floats_roughly_equals_11(self): # Test if add(4.48293848, 6.5023845) return roughly (to 1 place) 11 (actual product: 10.98532298) self.assertAlmostEqual(11, add(4.48293848, 6.5023845), places=1) Run Test # Run the unit test (and don&amp;#39;t shut down the Jupyter Notebook) unittest.main(argv=[&amp;#39;ignored&amp;#39;, &amp;#39;-v&amp;#39;], exit=False) test_add_two_floats_roughly_equals_11 (__main__.</description>
    </item>
    
    <item>
      <title>Testable Documentation</title>
      <link>https://chrisalbon.com/python/testing/testable_documentation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/testing/testable_documentation/</guid>
      <description>Preliminaries import doctest Create A Function To Test Note that our test cases are inside the function&amp;rsquo;s documentation. Each test case is marked by a &amp;gt;&amp;gt;&amp;gt; and the expect output is the line below.
def summation(a, b): &amp;#34;&amp;#34;&amp;#34; Takes two inputs and outputs their sum. Tests: &amp;gt;&amp;gt;&amp;gt; summation(5, 4) 9 &amp;gt;&amp;gt;&amp;gt; summation(4, 3) 7 &amp;gt;&amp;gt;&amp;gt; summation(&amp;#39;foo&amp;#39;,&amp;#39;bar&amp;#39;) &amp;#39;foobar&amp;#39; &amp;gt;&amp;gt;&amp;gt; summation(3,&amp;#39;d&amp;#39;) Traceback (most recent call last): ... TypeError: unsupported operand type(s) for +: &amp;#39;int&amp;#39; and &amp;#39;str&amp;#39; &amp;#34;&amp;#34;&amp;#34; return a + b Notice that in the last test, we are making sure the function outputs the correct error.</description>
    </item>
    
    <item>
      <title>Titanic Competition With Random Forest</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/titanic_competition_with_random_forest/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/titanic_competition_with_random_forest/</guid>
      <description>Preliminaries import pandas as pd import numpy as np from sklearn import preprocessing from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import GridSearchCV, cross_val_score import csv as csv Get The Data You can get the data on Kaggle&amp;rsquo;s site.
# Load the data train = pd.read_csv(&amp;#39;data/train.csv&amp;#39;) test = pd.read_csv(&amp;#39;data/test.csv&amp;#39;) Data Cleaning # Create a list of the features we will eventually want for our model features = [&amp;#39;Age&amp;#39;, &amp;#39;SibSp&amp;#39;,&amp;#39;Parch&amp;#39;,&amp;#39;Fare&amp;#39;,&amp;#39;male&amp;#39;,&amp;#39;embarked_Q&amp;#39;,&amp;#39;embarked_S&amp;#39;,&amp;#39;Pclass_2&amp;#39;, &amp;#39;Pclass_3&amp;#39;] Sex Here we convert the gender labels (male, female) into a dummy variable (1, 0).</description>
    </item>
    
    <item>
      <title>Tokenize Text</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_text/tokenize_text/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_text/tokenize_text/</guid>
      <description> Preliminaries # Load library from nltk.tokenize import word_tokenize, sent_tokenize Create Text Data # Create text string = &amp;#34;The science of today is the technology of tomorrow. Tomorrow is today.&amp;#34; Tokenize Words # Tokenize words word_tokenize(string) [&#39;The&#39;, &#39;science&#39;, &#39;of&#39;, &#39;today&#39;, &#39;is&#39;, &#39;the&#39;, &#39;technology&#39;, &#39;of&#39;, &#39;tomorrow&#39;, &#39;.&#39;, &#39;Tomorrow&#39;, &#39;is&#39;, &#39;today&#39;, &#39;.&#39;]  Tokenize Sentences # Tokenize sentences sent_tokenize(string) [&#39;The science of today is the technology of tomorrow.&#39;, &#39;Tomorrow is today.&#39;]  </description>
    </item>
    
    <item>
      <title>Transpose A Vector Or Matrix</title>
      <link>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/transpose_a_vector_or_matrix/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/vectors_matrices_and_arrays/transpose_a_vector_or_matrix/</guid>
      <description> Preliminaries # Load library import numpy as np Create Vector # Create vector vector = np.array([1, 2, 3, 4, 5, 6]) Create Matrix # Create matrix matrix = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) Transpose Vector # Tranpose vector vector.T array([1, 2, 3, 4, 5, 6])  Transpose Matrix # Transpose matrix matrix.T array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])  </description>
    </item>
    
    <item>
      <title>Try, Catch, Finally</title>
      <link>https://chrisalbon.com/scala/basics/try_catch_finally/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/try_catch_finally/</guid>
      <description>Create Some Operation That Will Cause An Exception &amp;#34;Sixteen&amp;#34;.toFloat Name: java.lang.NumberFormatException Message: For input string: &amp;quot;Sixteen&amp;quot; StackTrace: at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:2043) at sun.misc.FloatingDecimal.parseFloat(FloatingDecimal.java:122) at java.lang.Float.parseFloat(Float.java:451) at scala.collection.immutable.StringLike$class.toFloat(StringLike.scala:280) at scala.collection.immutable.StringOps.toFloat(StringOps.scala:29)  Try, Catch, Finally // Try try { // The bad operation  &amp;#34;Sixteen&amp;#34;.toFloat // Catch any problems } catch { // If it is an exception, print something  case e: Exception =&amp;gt; println(&amp;#34;Something went wrong&amp;#34;) } finally { // Regardless of if there is an error or not, print this  println(&amp;#34;We are finally done.</description>
    </item>
    
    <item>
      <title>Try, Except, and Finally</title>
      <link>https://chrisalbon.com/python/basics/try_except_finally/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/try_except_finally/</guid>
      <description>Create data # Create some data scores = [23,453,54,235,74,234] Try something that doesn&amp;rsquo;t work # Try to: try: # Add a list of integers and a string scores + &amp;#39;A string of characters.&amp;#39; # If you get an error, set the error as &amp;#39;e&amp;#39;, except Exception as e: # print the error, e print(&amp;#39;Error:&amp;#39;, e) # Then, finally: # print end program print(&amp;#39;End Program&amp;#39;) Error: can only concatenate list (not &amp;quot;str&amp;quot;) to list End Program  Try something that works # Try to: try: # Print scores print(&amp;#39;Worked!</description>
    </item>
    
    <item>
      <title>Tuning Neural Network Hyperparameters</title>
      <link>https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras import models from keras import layers from keras.wrappers.scikit_learn import KerasClassifier from sklearn.model_selection import GridSearchCV from sklearn.datasets import make_classification # Set random seed np.random.seed(0) Using TensorFlow backend.  Generate Target And Feature Data # Number of features number_of_features = 100 # Generate features matrix and target vector features, target = make_classification(n_samples = 10000, n_features = number_of_features, n_informative = 3, n_redundant = 0, n_classes = 2, weights = [.</description>
    </item>
    
    <item>
      <title>Unpacking A Tuple</title>
      <link>https://chrisalbon.com/python/basics/unpacking_a_tuple/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/unpacking_a_tuple/</guid>
      <description> Create List Of Tuples # Create a list of tuples where the first and second element of each  # super is the first last names, respectively soldiers = [(&amp;#39;Steve&amp;#39;, &amp;#39;Miller&amp;#39;), (&amp;#39;Stacy&amp;#39;, &amp;#39;Markov&amp;#39;), (&amp;#39;Sonya&amp;#39;, &amp;#39;Matthews&amp;#39;), (&amp;#39;Sally&amp;#39;, &amp;#39;Mako&amp;#39;)] Unpack Tuples # For the second element for each tuple in soldiers, for _, last_name in soldiers: # print the second element print(last_name) Miller Markov Matthews Mako  </description>
    </item>
    
    <item>
      <title>Unpacking Function Arguments</title>
      <link>https://chrisalbon.com/python/basics/unpacking_function_arguments/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/unpacking_function_arguments/</guid>
      <description> Create Argument Objects # Create a dictionary of arguments argument_dict = {&amp;#39;a&amp;#39;:&amp;#39;Alpha&amp;#39;, &amp;#39;b&amp;#39;:&amp;#39;Bravo&amp;#39;} # Create a list of arguments argument_list = [&amp;#39;Alpha&amp;#39;, &amp;#39;Bravo&amp;#39;] Create A Simple Function # Create a function that takes two inputs def simple_function(a, b): # and prints them combined return a + b Run the Function With Unpacked Arguments # Run the function with the unpacked argument dictionary simple_function(**argument_dict) &#39;AlphaBravo&#39;  # Run the function with the unpacked argument list simple_function(*argument_list) &#39;AlphaBravo&#39;  </description>
    </item>
    
    <item>
      <title>Use Command Line Arguments In A Function</title>
      <link>https://chrisalbon.com/python/basics/use_command_line_arguments_in_a_function/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/use_command_line_arguments_in_a_function/</guid>
      <description>Preliminary # Load library import argparse Create Python Code #!/usr/bin/env python3 # Create a function with two inputs def sum_two_values(value_one, value_two): # Add together two values _sum = value_one + value_two # Return sum return _sum # If the script is run if __name__ == &amp;#39;__main__&amp;#39;: # Create argument parser parser = argparse.ArgumentParser() # Create an argument called v1 or value_1 that is an integer parser.add_argument(&amp;#39;-v1&amp;#39;, &amp;#39;--value_1&amp;#39;, type=int, help=&amp;#39;The first value.</description>
    </item>
    
    <item>
      <title>Using Linear Discriminant Analysis For Dimensionality Reduction</title>
      <link>https://chrisalbon.com/machine_learning/feature_engineering/lda_for_dimensionality_reduction/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_engineering/lda_for_dimensionality_reduction/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.discriminant_analysis import LinearDiscriminantAnalysis Load Iris Data # Load the Iris flower dataset: iris = datasets.load_iris() X = iris.data y = iris.target Create A Linear # Create an LDA that will reduce the data down to 1 feature lda = LinearDiscriminantAnalysis(n_components=1) # run an LDA and use it to transform the features X_lda = lda.fit(X, y).transform(X) View Results # Print the number of features print(&amp;#39;Original number of features:&amp;#39;, X.</description>
    </item>
    
    <item>
      <title>Using List Comprehensions With pandas</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_list_comprehension/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_list_comprehension/</guid>
      <description>Preliminaries # Import modules import pandas as pd # Set ipython&amp;#39;s max row display pd.set_option(&amp;#39;display.max_row&amp;#39;, 1000) # Set iPython&amp;#39;s max column width to 50 pd.set_option(&amp;#39;display.max_columns&amp;#39;, 50) Create an example dataframe data = {&amp;#39;name&amp;#39;: [&amp;#39;Jason&amp;#39;, &amp;#39;Molly&amp;#39;, &amp;#39;Tina&amp;#39;, &amp;#39;Jake&amp;#39;, &amp;#39;Amy&amp;#39;], &amp;#39;year&amp;#39;: [2012, 2012, 2013, 2014, 2014], &amp;#39;reports&amp;#39;: [4, 24, 31, 2, 3]} df = pd.DataFrame(data, index = [&amp;#39;Cochice&amp;#39;, &amp;#39;Pima&amp;#39;, &amp;#39;Santa Cruz&amp;#39;, &amp;#39;Maricopa&amp;#39;, &amp;#39;Yuma&amp;#39;]) df   .dataframe thead tr:only-child th { text-align: right; } .</description>
    </item>
    
    <item>
      <title>Using Mean Color As A Feature</title>
      <link>https://chrisalbon.com/machine_learning/preprocessing_images/using_mean_color_as_a_feature/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/preprocessing_images/using_mean_color_as_a_feature/</guid>
      <description>Preliminaries # Load image import cv2 import numpy as np from matplotlib import pyplot as plt Load image # Load image as BGR image_bgr = cv2.imread(&amp;#39;images/plane_256x256.jpg&amp;#39;, cv2.IMREAD_COLOR) Calculate Mean Color Of Each Color Channel # Calculate the mean of each channel channels = cv2.mean(image_bgr) # Swap blue and red values (making it RGB, not BGR) observation = np.array([(channels[2], channels[1], channels[0])]) Show Values # Show mean channel values observation array([[ 90.</description>
    </item>
    
    <item>
      <title>Using Named Tuples To Store Data</title>
      <link>https://chrisalbon.com/python/basics/using_named_tuples_to_store_data/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/using_named_tuples_to_store_data/</guid>
      <description> Preliminaries from collections import namedtuple Create A Named Tuple Vehicle = namedtuple(&amp;#39;Vehicle&amp;#39;, &amp;#39;make model wheels manual&amp;#39;) Create An Entry forrester = Vehicle(&amp;#39;Forrester&amp;#39;, &amp;#39;Subaru&amp;#39;, 4, True) View The Data In Entry forrester.model &#39;Subaru&#39;  forrester.wheels 4  </description>
    </item>
    
    <item>
      <title>Using Seaborn To Visualize A pandas Dataframe</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_with_seaborn/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_with_seaborn/</guid>
      <description>Preliminaries import pandas as pd %matplotlib inline import random import matplotlib.pyplot as plt import seaborn as snsdf = pd.DataFrame() df[&amp;#39;x&amp;#39;] = random.sample(range(1, 100), 25) df[&amp;#39;y&amp;#39;] = random.sample(range(1, 100), 25)df.head()    x y     0 18 25   1 42 67   2 52 77   3 4 34   4 14 69     Scatterplot sns.lmplot(&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;, data=df, fit_reg=False) &amp;lt;seaborn.</description>
    </item>
    
    <item>
      <title>Variables And Values</title>
      <link>https://chrisalbon.com/scala/basics/variables_and_values/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/variables_and_values/</guid>
      <description> Values Are Immutable // Create a value called greeting that is a string with the word &amp;#34;Hello&amp;#34; val greeting: String = &amp;#34;Hello&amp;#34; // View the value greeting Hello  Variables Are Mutable // Create a variable called age that is a &amp;#34;short&amp;#34; number (between -32768 to 32767) with the number 12 var age: Short = 12 // View the variable age 12  </description>
    </item>
    
    <item>
      <title>Variance And Standard Deviation</title>
      <link>https://chrisalbon.com/statistics/frequentist/variance_and_standard_deviation/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/statistics/frequentist/variance_and_standard_deviation/</guid>
      <description>Preliminary # Import data import math Create Data # Create list of values data = [3,2,3,4,2,3,5,2,2,33,3,5,2,2,5,6,62,2,2,3,6,6,2,23,3,2,3] Calculate Population Variance Variance is a measurement of the spread of a data&amp;rsquo;s distribution. The higher the variance, the more &amp;ldquo;spread out&amp;rdquo; the data points are. Variance, commonly denoted as $S^{2}$, is calculated like this:
$$ \text{Population Variance} = S_n^{2} = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^{2}$$
$$ \text{Sample Variance} = S_{n-1}^{2} = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^{2}$$
Where $n$ is the number of observations, $\bar{x}$ is the mean of the observations, and $x_i-\bar{x}$ is an individual observation&amp;rsquo;s from the mean of the data.</description>
    </item>
    
    <item>
      <title>Variance Thresholding Binary Features</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/variance_thresholding_binary_features/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/variance_thresholding_binary_features/</guid>
      <description>Preliminaries from sklearn.feature_selection import VarianceThreshold Load Data # Create feature matrix with:  # Feature 0: 80% class 0 # Feature 1: 80% class 1 # Feature 2: 60% class 0, 40% class 1 X = [[0, 1, 0], [0, 1, 1], [0, 1, 0], [0, 1, 1], [1, 0, 0]] Conduct Variance Thresholding In binary features (i.e. Bernoulli random variables), variance is calculated as:
$$\operatorname {Var} (x)= p(1-p)$$</description>
    </item>
    
    <item>
      <title>Variance Thresholding For Feature Selection</title>
      <link>https://chrisalbon.com/machine_learning/feature_selection/variance_thresholding_for_feature_selection/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/feature_selection/variance_thresholding_for_feature_selection/</guid>
      <description>Preliminaries from sklearn import datasets from sklearn.feature_selection import VarianceThreshold Load Data # Load iris data iris = datasets.load_iris() # Create features and target X = iris.data y = iris.target Conduct Variance Thresholding # Create VarianceThreshold object with a variance with a threshold of 0.5 thresholder = VarianceThreshold(threshold=.5) # Conduct variance thresholding X_high_variance = thresholder.fit_transform(X) View high variance features # View first five rows with features with variances above threshold X_high_variance[0:5] array([[ 5.</description>
    </item>
    
    <item>
      <title>Visualize A Decision Tree</title>
      <link>https://chrisalbon.com/machine_learning/trees_and_forests/visualize_a_decision_tree/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/trees_and_forests/visualize_a_decision_tree/</guid>
      <description>Preliminaries # Load libraries from sklearn.tree import DecisionTreeClassifier from sklearn import datasets from IPython.display import Image from sklearn import tree import pydotplus Load Iris Data # Load data iris = datasets.load_iris() X = iris.data y = iris.target Train Decision Tree # Create decision tree classifer object clf = DecisionTreeClassifier(random_state=0) # Train model model = clf.fit(X, y) Visualize Decision Tree # Create DOT data dot_data = tree.export_graphviz(clf, out_file=None, feature_names=iris.feature_names, class_names=iris.target_names) # Draw graph graph = pydotplus.</description>
    </item>
    
    <item>
      <title>Visualize Loss History</title>
      <link>https://chrisalbon.com/deep_learning/keras/visualize_loss_history/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/visualize_loss_history/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers import matplotlib.pyplot as plt # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Data # Set the number of features we want number_of_features = 10000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>Visualize Neural Network Architecutre</title>
      <link>https://chrisalbon.com/deep_learning/keras/visualize_neural_network_architecture/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/visualize_neural_network_architecture/</guid>
      <description>Preliminaries # Load libraries from keras import models from keras import layers from IPython.display import SVG from keras.utils.vis_utils import model_to_dot from keras.utils import plot_model Using TensorFlow backend.  Construct Neural Network Architecture # Start neural network network = models.Sequential() # Add fully connected layer with a ReLU activation function network.add(layers.Dense(units=16, activation=&amp;#39;relu&amp;#39;, input_shape=(10,))) # Add fully connected layer with a ReLU activation function network.add(layers.Dense(units=16, activation=&amp;#39;relu&amp;#39;)) # Add fully connected layer with a sigmoid activation function network.</description>
    </item>
    
    <item>
      <title>Visualize Performance History</title>
      <link>https://chrisalbon.com/deep_learning/keras/visualize_performance_history/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/visualize_performance_history/</guid>
      <description>Preliminaries # Load libraries import numpy as np from keras.datasets import imdb from keras.preprocessing.text import Tokenizer from keras import models from keras import layers import matplotlib.pyplot as plt # Set random seed np.random.seed(0) Using TensorFlow backend.  Load Movie Review Data # Set the number of features we want number_of_features = 10000 # Load data and target vector from movie review data (train_data, train_target), (test_data, test_target) = imdb.load_data(num_words=number_of_features) # Convert movie review data to a one-hot encoded feature matrix tokenizer = Tokenizer(num_words=number_of_features) train_features = tokenizer.</description>
    </item>
    
    <item>
      <title>What Is The Probability An Economy Class Seat Is An Aisle Seat?</title>
      <link>https://chrisalbon.com/python/other/aisle_seat_probabilities/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/other/aisle_seat_probabilities/</guid>
      <description>There are two types of people in the world, aisle seaters and window seaters. I am an aisle seater, nothing is worse than limited bathroom access on a long flight. The first thing I do when I get my ticket is check to see if I have a window seat. If not, I immediately head over to the airline counter and try to get one.
Last flight, on Turkish Airlines, I ran into a curious situation.</description>
    </item>
    
    <item>
      <title>Zip Together Two Lists</title>
      <link>https://chrisalbon.com/scala/basics/zip_together_two_lists/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/scala/basics/zip_together_two_lists/</guid>
      <description> Create Two Vectors // Create two vectors val firstName = Vector(&amp;#34;Steve&amp;#34;, &amp;#34;Bob&amp;#34;, &amp;#34;Jack&amp;#34;, &amp;#34;Jill&amp;#34;) val lastName = Vector(&amp;#34;Jackson&amp;#34;, &amp;#34;Dillan&amp;#34;, &amp;#34;Bower&amp;#34;, &amp;#34;Stein&amp;#34;) Zip Together Vectors // Create a new variable that zips the sequences val fullNames = firstName zip lastName// View the zipped sequences and convert to a map fullNames Vector((Steve,Jackson), (Bob,Dillan), (Jack,Bower), (Jill,Stein))  </description>
    </item>
    
    <item>
      <title>any(), all(), max(), min(), sum()</title>
      <link>https://chrisalbon.com/python/basics/any_all_max_min_sum/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/any_all_max_min_sum/</guid>
      <description> Create Data data = [34, 54, 50, 20, 20] any() # Return true if any element is True any(data) True  all() # Return true if all elements are True all(data) True  max() # Return max value max(data) 54  min() # Return the min value min(data) 20  sum() # Return the total value sum(data) 178  </description>
    </item>
    
    <item>
      <title>argmin and argmax</title>
      <link>https://chrisalbon.com/mathematics/basics/argmin_and_argmax/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/mathematics/basics/argmin_and_argmax/</guid>
      <description>argmin and argmax are the inputs, x&amp;rsquo;s, to a function, f, that creates the smallest and largest outputs, f(x).
Preliminaries import numpy as np import pandas as pd np.random.seed(1) Define A Function, f(x) # Define a function that, def f(x): # Outputs x multiplied by a random number drawn from a normal distribution return x * np.random.normal(size=1)[0] Create Some Values Of x # Create some values of x xs = [1,2,3,4,5,6] Find The Argmin Of f(x) #Define argmin that def argmin(f, xs): # Applies f on all the x&amp;#39;s data = [f(x) for x in xs] # Finds index of the smallest output of f(x) index_of_min = data.</description>
    </item>
    
    <item>
      <title>if and if else</title>
      <link>https://chrisalbon.com/python/basics/if_and_if_else_statements/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/if_and_if_else_statements/</guid>
      <description>Create a variable with the status of the conflict.  1 if the conflict is active 0 if the conflict is not active unknown if the status of the conflict is unknwon  conflict_active = 1 If the conflict is active print a statement if conflict_active == 1: print(&amp;#39;The conflict is active.&amp;#39;) The conflict is active.  If the conflict is active print a statement, if not, print a different statement if conflict_active == 1: print(&amp;#39;The conflict is active.</description>
    </item>
    
    <item>
      <title>k-Fold Cross-Validating Neural Networks</title>
      <link>https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/deep_learning/keras/k-fold_cross-validating_neural_networks/</guid>
      <description>If we have smaller data it can be useful to benefit from k-fold cross-validation to maximize our ability to evaluate the neural network&amp;rsquo;s performance. This is possible in Keras because we can &amp;ldquo;wrap&amp;rdquo; any neural network such that it can use the evaluation features available in scikit-learn, including k-fold cross-validation. To accomplish this, we first have to create a function that returns a compiled neural network. Next we use KerasClassifier (if we have a classifier, if we have a regressor we can use KerasRegressor) to wrap the model so it can be used by scikit-learn.</description>
    </item>
    
    <item>
      <title>k-Means Clustering</title>
      <link>https://chrisalbon.com/machine_learning/clustering/k-means_clustering/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/machine_learning/clustering/k-means_clustering/</guid>
      <description>Preliminaries # Load libraries from sklearn import datasets from sklearn.preprocessing import StandardScaler from sklearn.cluster import KMeans Load Iris Flower Dataset # Load data iris = datasets.load_iris() X = iris.data Standardize Features # Standarize features scaler = StandardScaler() X_std = scaler.fit_transform(X) Conduct k-Means Clustering # Create k-mean object clt = KMeans(n_clusters=3, random_state=0, n_jobs=-1) # Train model model = clt.fit(X_std) Show Each Observation&amp;rsquo;s Cluster Membership # View predict class model.labels_ array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2], dtype=int32)  Create New Observation # Create new observation new_observation = [[0.</description>
    </item>
    
    <item>
      <title>pandas Data Structures</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_data_structures/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_data_structures/</guid>
      <description>Import modules import pandas as pd Series 101 Series are one-dimensional arrays (like R&amp;rsquo;s vectors)
Create a series of the number of floodingReports floodingReports = pd.Series([5, 6, 2, 9, 12]) floodingReports 0 5 1 6 2 2 3 9 4 12 dtype: int64  Note that the first column of numbers (0 to 4) are the index.
Set county names to be the index of the floodingReports series floodingReports = pd.</description>
    </item>
    
    <item>
      <title>pandas Time Series Basics</title>
      <link>https://chrisalbon.com/python/data_wrangling/pandas_time_series_basics/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/data_wrangling/pandas_time_series_basics/</guid>
      <description>Import modules from datetime import datetime import pandas as pd %matplotlib inline import matplotlib.pyplot as pyplot Create a dataframe data = {&amp;#39;date&amp;#39;: [&amp;#39;2014-05-01 18:47:05.069722&amp;#39;, &amp;#39;2014-05-01 18:47:05.119994&amp;#39;, &amp;#39;2014-05-02 18:47:05.178768&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.230071&amp;#39;, &amp;#39;2014-05-02 18:47:05.280592&amp;#39;, &amp;#39;2014-05-03 18:47:05.332662&amp;#39;, &amp;#39;2014-05-03 18:47:05.385109&amp;#39;, &amp;#39;2014-05-04 18:47:05.436523&amp;#39;, &amp;#39;2014-05-04 18:47:05.486877&amp;#39;], &amp;#39;battle_deaths&amp;#39;: [34, 25, 26, 15, 15, 14, 26, 25, 62, 41]} df = pd.DataFrame(data, columns = [&amp;#39;date&amp;#39;, &amp;#39;battle_deaths&amp;#39;]) print(df)  date battle_deaths 0 2014-05-01 18:47:05.069722 34 1 2014-05-01 18:47:05.</description>
    </item>
    
    <item>
      <title>repr vs. str</title>
      <link>https://chrisalbon.com/python/basics/repr_vs_str/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/repr_vs_str/</guid>
      <description>Preliminaries import datetime Create A Simple Object class Regiment(object): def __init__(self, date=datetime.datetime.now()): self.date = date def __repr__(self): return date def __str__(self): return str(date) __repr__ is for the developer. It is string representation of the object and the code needed to reproduce the object.
__str__ is the output for the end user. It prints what the user wants to see.</description>
    </item>
    
    <item>
      <title>while Statement</title>
      <link>https://chrisalbon.com/python/basics/while_statements/</link>
      <pubDate>Wed, 20 Dec 2017 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/python/basics/while_statements/</guid>
      <description>Import the random module import random Create a variable of the true number of deaths of an event deaths = 6 Create a variable that is denotes if the while loop should keep running running = True while running is True while running: # Create a variable that randomly create a integer between 0 and 10. guess = random.randint(0,10) # if guess equals deaths, if guess == deaths: # then print this print(&amp;#39;Correct!</description>
    </item>
    
    <item>
      <title>What I Learned Tracking My Time At Techstars</title>
      <link>https://chrisalbon.com/articles/what_i_learned_from_tracking_my_time_at_techstars/</link>
      <pubDate>Mon, 01 Feb 2016 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/articles/what_i_learned_from_tracking_my_time_at_techstars/</guid>
      <description>In the fall of 2015, New Knowledge, a company I cofounded with two friends was offered a slot in the 2016 class of Techstars Cloud. Like most people in tech, I had heard about Techstars, but in truth I barely knew anything specific, particularly about the day-to-day of the program. Was Techstars a permanent hackathon fueled by Soylent and Adderall? Was it three months of guest speakers and sponsored happy hours?</description>
    </item>
    
    <item>
      <title>Health System Destruction During The Mozambican Civil War</title>
      <link>https://chrisalbon.com/articles/health_system_destruction_renamo_mozambique/</link>
      <pubDate>Tue, 20 Dec 2011 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/articles/health_system_destruction_renamo_mozambique/</guid>
      <description>Mozambiques political history has been shaped by its geography. Stretched from north to south along more than 1,500 miles of coastline, the territory was first colonized by the Portuguese, who established a series of trading ports. Through these ports the colonists extracted the agricultural and commercial wealth of the territory. Under Portuguese rule, the health system in Mozambique centered on the needs of the European settler community and their economic interests.</description>
    </item>
    
    <item>
      <title>Health System Reconstruction In Post-War Kosovo</title>
      <link>https://chrisalbon.com/articles/health_system_reconstruction_post_war_kosovo/</link>
      <pubDate>Tue, 20 Dec 2011 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/articles/health_system_reconstruction_post_war_kosovo/</guid>
      <description>In 1963, Kosovo became an autonomous province of Serbia in Yugoslavia under Josip Tito. Long before then, friction had existed between the ethnically Albanian and Serbian communities living inside and around Kosovo. These tensions escalated in the 1980s as ethnic Albanians pushed for greater autonomy for Kosovo and stronger connections to neighboring Albania, while Serbians wanted to maintain strong ties with Belgrade.
Since World War II, Yugoslavias (and therefore Kosovos) health system was based on the Semashko model common in other Communist states: centralized decision making, large institutions, and the domination of hospital, curative, and specialist care (Parmelee 1985; Shuey et al.</description>
    </item>
    
    <item>
      <title>The Problem Of Rebel Mobilization</title>
      <link>https://chrisalbon.com/articles/puzzle_of_rebel_mobilization/</link>
      <pubDate>Tue, 20 Dec 2011 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/articles/puzzle_of_rebel_mobilization/</guid>
      <description>The Puzzle When looking at the destruction of health systems in civil wars, we are presented with an empirical puzzle: why do some civil wars see widespread destruction to health systems and other civil wars see far less?
During Mozambiques civil war, RENAMOs campaign against the government health system caused more than two million people to lose access to health care (Cliff and Noormahomed 1993). In Colombias civil war, FARC fighters often targeted stocks of drugs destined for the civilian population (Beyrer et al.</description>
    </item>
    
    <item>
      <title>The Structure Of Health Systems</title>
      <link>https://chrisalbon.com/articles/health_systems/</link>
      <pubDate>Tue, 20 Dec 2011 11:53:49 -0700</pubDate>
      
      <guid>https://chrisalbon.com/articles/health_systems/</guid>
      <description>While health systems vary in the role of the private sector, the priority given to primary and specialized care, the level of access enjoyed by citizens, and a host of other characteristics, most health systems (particularly in less developed states) share a basic structure based on a hierarchical organization of health care provision. Most citizens primary point of contact with health systems is usually through health posts, health clinics, and health centers.</description>
    </item>
    
  </channel>
</rss>